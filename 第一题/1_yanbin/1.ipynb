{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 线性分类\n",
    "* 不能使用现成机器学习库（比如sklearn, tensorflow, caffe, pytorch等），用numpy实现线性分类\n",
    "* 文件x_train.npy和t_train.npy给出训练数据和真值\n",
    "* 提交对于文件test所给数据的预测结果，以numpy数组的形式存储为文件t_test.npy\n",
    "* 以文本文件的形式提交分类平面的表达式\n",
    "\n",
    "数据演示如下："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(75, 2)\n",
      "(75,)\n"
     ]
    }
   ],
   "source": [
    "x_train = np.load('x_train.npy')\n",
    "y_train = np.load('t_train.npy')\n",
    "print(x_train.shape)\n",
    "print(y_train.shape)\n",
    "# plt.scatter(x_train[:, 0], x_train[:, 1], c=t_train)\n",
    "# plt.xlim([-4, 6])\n",
    "# plt.ylim([-4, 6])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x7fc1d58a70f0>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fc1dde3e5c0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.scatter(x_train[:, 0], x_train[:, 1], c=y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "样本特征的均值 [1.89985978 2.03252308]\n",
      "样本特征的标准差 [1.79901635 2.00216829]\n"
     ]
    }
   ],
   "source": [
    "x_train_mean = np.mean(x_train,axis=0)\n",
    "print('样本特征的均值',x_train_mean)\n",
    "x_train -= x_train_mean\n",
    "x_train_std = np.std(x_train,axis=0)\n",
    "print('样本特征的标准差',x_train_std)\n",
    "x_train /= x_train_std\n",
    "x_train = np.hstack([x_train, np.ones((x_train.shape[0], 1))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x7fc1d57c2390>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fc1d58556d8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.scatter(x_train[:, 0], x_train[:, 1], c=y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration 0 / 1000: loss 1.099112\n",
      "iteration 100 / 1000: loss 1.098854\n",
      "iteration 200 / 1000: loss 1.098901\n",
      "iteration 300 / 1000: loss 1.098984\n",
      "iteration 400 / 1000: loss 1.098765\n",
      "iteration 500 / 1000: loss 1.098713\n",
      "iteration 600 / 1000: loss 1.098742\n",
      "iteration 700 / 1000: loss 1.098773\n",
      "iteration 800 / 1000: loss 1.098655\n",
      "iteration 900 / 1000: loss 1.098610\n",
      "iteration 0 / 1000: loss 1.145957\n",
      "iteration 100 / 1000: loss 1.099428\n",
      "iteration 200 / 1000: loss 1.098613\n",
      "iteration 300 / 1000: loss 1.098603\n",
      "iteration 400 / 1000: loss 1.098600\n",
      "iteration 500 / 1000: loss 1.098600\n",
      "iteration 600 / 1000: loss 1.098601\n",
      "iteration 700 / 1000: loss 1.098598\n",
      "iteration 800 / 1000: loss 1.098601\n",
      "iteration 900 / 1000: loss 1.098600\n",
      "iteration 0 / 1000: loss 1.101254\n",
      "iteration 100 / 1000: loss 1.100935\n",
      "iteration 200 / 1000: loss 1.100643\n",
      "iteration 300 / 1000: loss 1.100584\n",
      "iteration 400 / 1000: loss 1.100326\n",
      "iteration 500 / 1000: loss 1.100235\n",
      "iteration 600 / 1000: loss 1.100147\n",
      "iteration 700 / 1000: loss 1.099785\n",
      "iteration 800 / 1000: loss 1.099920\n",
      "iteration 900 / 1000: loss 1.099670\n",
      "iteration 0 / 1000: loss 1.099490\n",
      "iteration 100 / 1000: loss 1.099430\n",
      "iteration 200 / 1000: loss 1.099426\n",
      "iteration 300 / 1000: loss 1.099400\n",
      "iteration 400 / 1000: loss 1.099213\n",
      "iteration 500 / 1000: loss 1.099259\n",
      "iteration 600 / 1000: loss 1.099155\n",
      "iteration 700 / 1000: loss 1.099211\n",
      "iteration 800 / 1000: loss 1.099129\n",
      "iteration 900 / 1000: loss 1.099042\n",
      "iteration 0 / 1000: loss 1.098444\n",
      "iteration 100 / 1000: loss 1.098280\n",
      "iteration 200 / 1000: loss 1.098174\n",
      "iteration 300 / 1000: loss 1.098239\n",
      "iteration 400 / 1000: loss 1.098189\n",
      "iteration 500 / 1000: loss 1.098191\n",
      "iteration 600 / 1000: loss 1.098012\n",
      "iteration 700 / 1000: loss 1.098048\n",
      "iteration 800 / 1000: loss 1.098056\n",
      "iteration 900 / 1000: loss 1.097740\n",
      "iteration 0 / 1000: loss 1.099486\n",
      "iteration 100 / 1000: loss 1.098994\n",
      "iteration 200 / 1000: loss 1.099073\n",
      "iteration 300 / 1000: loss 1.099306\n",
      "iteration 400 / 1000: loss 1.099119\n",
      "iteration 500 / 1000: loss 1.099138\n",
      "iteration 600 / 1000: loss 1.099111\n",
      "iteration 700 / 1000: loss 1.098931\n",
      "iteration 800 / 1000: loss 1.098907\n",
      "iteration 900 / 1000: loss 1.098981\n",
      "iteration 0 / 1000: loss 1.098710\n",
      "iteration 100 / 1000: loss 1.098743\n",
      "iteration 200 / 1000: loss 1.098631\n",
      "iteration 300 / 1000: loss 1.098554\n",
      "iteration 400 / 1000: loss 1.098501\n",
      "iteration 500 / 1000: loss 1.098570\n",
      "iteration 600 / 1000: loss 1.098320\n",
      "iteration 700 / 1000: loss 1.098282\n",
      "iteration 800 / 1000: loss 1.098437\n",
      "iteration 900 / 1000: loss 1.098333\n",
      "iteration 0 / 1000: loss 1.116828\n",
      "iteration 100 / 1000: loss 1.109165\n",
      "iteration 200 / 1000: loss 1.105019\n",
      "iteration 300 / 1000: loss 1.102343\n",
      "iteration 400 / 1000: loss 1.100764\n",
      "iteration 500 / 1000: loss 1.099827\n",
      "iteration 600 / 1000: loss 1.099327\n",
      "iteration 700 / 1000: loss 1.099015\n",
      "iteration 800 / 1000: loss 1.098811\n",
      "iteration 900 / 1000: loss 1.098693\n",
      "iteration 0 / 1000: loss 1.100388\n",
      "iteration 100 / 1000: loss 1.100232\n",
      "iteration 200 / 1000: loss 1.100257\n",
      "iteration 300 / 1000: loss 1.100441\n",
      "iteration 400 / 1000: loss 1.100103\n",
      "iteration 500 / 1000: loss 1.099992\n",
      "iteration 600 / 1000: loss 1.100002\n",
      "iteration 700 / 1000: loss 1.099918\n",
      "iteration 800 / 1000: loss 1.099978\n",
      "iteration 900 / 1000: loss 1.100004\n",
      "iteration 0 / 1000: loss 1.098795\n",
      "iteration 100 / 1000: loss 1.098747\n",
      "iteration 200 / 1000: loss 1.098546\n",
      "iteration 300 / 1000: loss 1.098450\n",
      "iteration 400 / 1000: loss 1.098603\n",
      "iteration 500 / 1000: loss 1.098417\n",
      "iteration 600 / 1000: loss 1.098347\n",
      "iteration 700 / 1000: loss 1.098470\n",
      "iteration 800 / 1000: loss 1.098270\n",
      "iteration 900 / 1000: loss 1.098247\n",
      "iteration 0 / 1000: loss 1.099712\n",
      "iteration 100 / 1000: loss 1.099566\n",
      "iteration 200 / 1000: loss 1.099328\n",
      "iteration 300 / 1000: loss 1.099320\n",
      "iteration 400 / 1000: loss 1.099301\n",
      "iteration 500 / 1000: loss 1.099345\n",
      "iteration 600 / 1000: loss 1.099197\n",
      "iteration 700 / 1000: loss 1.099143\n",
      "iteration 800 / 1000: loss 1.098976\n",
      "iteration 900 / 1000: loss 1.098978\n",
      "iteration 0 / 1000: loss 1.143721\n",
      "iteration 100 / 1000: loss 1.098722\n",
      "iteration 200 / 1000: loss 1.098602\n",
      "iteration 300 / 1000: loss 1.098599\n",
      "iteration 400 / 1000: loss 1.098599\n",
      "iteration 500 / 1000: loss 1.098600\n",
      "iteration 600 / 1000: loss 1.098597\n",
      "iteration 700 / 1000: loss 1.098602\n",
      "iteration 800 / 1000: loss 1.098601\n",
      "iteration 900 / 1000: loss 1.098599\n",
      "iteration 0 / 1000: loss 1.098462\n",
      "iteration 100 / 1000: loss 1.098439\n",
      "iteration 200 / 1000: loss 1.098363\n",
      "iteration 300 / 1000: loss 1.098411\n",
      "iteration 400 / 1000: loss 1.098261\n",
      "iteration 500 / 1000: loss 1.098304\n",
      "iteration 600 / 1000: loss 1.098207\n",
      "iteration 700 / 1000: loss 1.098209\n",
      "iteration 800 / 1000: loss 1.098183\n",
      "iteration 900 / 1000: loss 1.098161\n",
      "iteration 0 / 1000: loss 1.097507\n",
      "iteration 100 / 1000: loss 1.097313\n",
      "iteration 200 / 1000: loss 1.097181\n",
      "iteration 300 / 1000: loss 1.097330\n",
      "iteration 400 / 1000: loss 1.097146\n",
      "iteration 500 / 1000: loss 1.097137\n",
      "iteration 600 / 1000: loss 1.097171\n",
      "iteration 700 / 1000: loss 1.096996\n",
      "iteration 800 / 1000: loss 1.097081\n",
      "iteration 900 / 1000: loss 1.096657\n",
      "iteration 0 / 1000: loss 1.098495\n",
      "iteration 100 / 1000: loss 1.098678\n",
      "iteration 200 / 1000: loss 1.098629\n",
      "iteration 300 / 1000: loss 1.098508\n",
      "iteration 400 / 1000: loss 1.098471\n",
      "iteration 500 / 1000: loss 1.098337\n",
      "iteration 600 / 1000: loss 1.098279\n",
      "iteration 700 / 1000: loss 1.098321\n",
      "iteration 800 / 1000: loss 1.098041\n",
      "iteration 900 / 1000: loss 1.098180\n",
      "iteration 0 / 1000: loss 1.098814\n",
      "iteration 100 / 1000: loss 1.098516\n",
      "iteration 200 / 1000: loss 1.098201\n",
      "iteration 300 / 1000: loss 1.098434\n",
      "iteration 400 / 1000: loss 1.098277\n",
      "iteration 500 / 1000: loss 1.098336\n",
      "iteration 600 / 1000: loss 1.098026\n",
      "iteration 700 / 1000: loss 1.097938\n",
      "iteration 800 / 1000: loss 1.098173\n",
      "iteration 900 / 1000: loss 1.097466\n",
      "iteration 0 / 1000: loss 1.098509\n",
      "iteration 100 / 1000: loss 1.098518\n",
      "iteration 200 / 1000: loss 1.098421\n",
      "iteration 300 / 1000: loss 1.098389\n",
      "iteration 400 / 1000: loss 1.098187\n",
      "iteration 500 / 1000: loss 1.098170\n",
      "iteration 600 / 1000: loss 1.098130\n",
      "iteration 700 / 1000: loss 1.098085\n",
      "iteration 800 / 1000: loss 1.097960\n",
      "iteration 900 / 1000: loss 1.097937\n",
      "iteration 0 / 1000: loss 1.107703\n",
      "iteration 100 / 1000: loss 1.102743\n",
      "iteration 200 / 1000: loss 1.100484\n",
      "iteration 300 / 1000: loss 1.099442\n",
      "iteration 400 / 1000: loss 1.098947\n",
      "iteration 500 / 1000: loss 1.098724\n",
      "iteration 600 / 1000: loss 1.098626\n",
      "iteration 700 / 1000: loss 1.098561\n",
      "iteration 800 / 1000: loss 1.098549\n",
      "iteration 900 / 1000: loss 1.098526\n",
      "iteration 0 / 1000: loss 1.098926\n",
      "iteration 100 / 1000: loss 1.098816\n",
      "iteration 200 / 1000: loss 1.098823\n",
      "iteration 300 / 1000: loss 1.098596\n",
      "iteration 400 / 1000: loss 1.098529\n",
      "iteration 500 / 1000: loss 1.098569\n",
      "iteration 600 / 1000: loss 1.098582\n",
      "iteration 700 / 1000: loss 1.098377\n",
      "iteration 800 / 1000: loss 1.098327\n",
      "iteration 900 / 1000: loss 1.098299\n",
      "iteration 0 / 1000: loss 1.098300\n",
      "iteration 100 / 1000: loss 1.098185\n",
      "iteration 200 / 1000: loss 1.098229\n",
      "iteration 300 / 1000: loss 1.097943\n",
      "iteration 400 / 1000: loss 1.097962\n",
      "iteration 500 / 1000: loss 1.098017\n",
      "iteration 600 / 1000: loss 1.097892\n",
      "iteration 700 / 1000: loss 1.097673\n",
      "iteration 800 / 1000: loss 1.097676\n",
      "iteration 900 / 1000: loss 1.097684\n",
      "iteration 0 / 1000: loss 1.097910\n",
      "iteration 100 / 1000: loss 1.097592\n",
      "iteration 200 / 1000: loss 1.097599\n",
      "iteration 300 / 1000: loss 1.097399\n",
      "iteration 400 / 1000: loss 1.097292\n",
      "iteration 500 / 1000: loss 1.097388\n",
      "iteration 600 / 1000: loss 1.097413\n",
      "iteration 700 / 1000: loss 1.097158\n",
      "iteration 800 / 1000: loss 1.097101\n",
      "iteration 900 / 1000: loss 1.096762\n",
      "iteration 0 / 1000: loss 1.195445\n",
      "iteration 100 / 1000: loss 1.098615\n",
      "iteration 200 / 1000: loss 1.098599\n",
      "iteration 300 / 1000: loss 1.098602\n",
      "iteration 400 / 1000: loss 1.098599\n",
      "iteration 500 / 1000: loss 1.098600\n",
      "iteration 600 / 1000: loss 1.098602\n",
      "iteration 700 / 1000: loss 1.098598\n",
      "iteration 800 / 1000: loss 1.098599\n",
      "iteration 900 / 1000: loss 1.098600\n",
      "iteration 0 / 1000: loss 1.102117\n",
      "iteration 100 / 1000: loss 1.101675\n",
      "iteration 200 / 1000: loss 1.100982\n",
      "iteration 300 / 1000: loss 1.100875\n",
      "iteration 400 / 1000: loss 1.100292\n",
      "iteration 500 / 1000: loss 1.100024\n",
      "iteration 600 / 1000: loss 1.099708\n",
      "iteration 700 / 1000: loss 1.099541\n",
      "iteration 800 / 1000: loss 1.099312\n",
      "iteration 900 / 1000: loss 1.099123\n",
      "iteration 0 / 1000: loss 1.098735\n",
      "iteration 100 / 1000: loss 1.098720\n",
      "iteration 200 / 1000: loss 1.098553\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration 300 / 1000: loss 1.098508\n",
      "iteration 400 / 1000: loss 1.098263\n",
      "iteration 500 / 1000: loss 1.098150\n",
      "iteration 600 / 1000: loss 1.098164\n",
      "iteration 700 / 1000: loss 1.097933\n",
      "iteration 800 / 1000: loss 1.098164\n",
      "iteration 900 / 1000: loss 1.097938\n",
      "iteration 0 / 1000: loss 1.099088\n",
      "iteration 100 / 1000: loss 1.099176\n",
      "iteration 200 / 1000: loss 1.098838\n",
      "iteration 300 / 1000: loss 1.098726\n",
      "iteration 400 / 1000: loss 1.098761\n",
      "iteration 500 / 1000: loss 1.098614\n",
      "iteration 600 / 1000: loss 1.098475\n",
      "iteration 700 / 1000: loss 1.098397\n",
      "iteration 800 / 1000: loss 1.098329\n",
      "iteration 900 / 1000: loss 1.098274\n",
      "iteration 0 / 1000: loss 1.098662\n",
      "iteration 100 / 1000: loss 1.098521\n",
      "iteration 200 / 1000: loss 1.098384\n",
      "iteration 300 / 1000: loss 1.098272\n",
      "iteration 400 / 1000: loss 1.098160\n",
      "iteration 500 / 1000: loss 1.098113\n",
      "iteration 600 / 1000: loss 1.097966\n",
      "iteration 700 / 1000: loss 1.097972\n",
      "iteration 800 / 1000: loss 1.097984\n",
      "iteration 900 / 1000: loss 1.097830\n",
      "iteration 0 / 1000: loss 1.098525\n",
      "iteration 100 / 1000: loss 1.098468\n",
      "iteration 200 / 1000: loss 1.098459\n",
      "iteration 300 / 1000: loss 1.098147\n",
      "iteration 400 / 1000: loss 1.098036\n",
      "iteration 500 / 1000: loss 1.097953\n",
      "iteration 600 / 1000: loss 1.098051\n",
      "iteration 700 / 1000: loss 1.097946\n",
      "iteration 800 / 1000: loss 1.097706\n",
      "iteration 900 / 1000: loss 1.097597\n",
      "iteration 0 / 1000: loss 1.107179\n",
      "iteration 100 / 1000: loss 1.101301\n",
      "iteration 200 / 1000: loss 1.099444\n",
      "iteration 300 / 1000: loss 1.098822\n",
      "iteration 400 / 1000: loss 1.098617\n",
      "iteration 500 / 1000: loss 1.098545\n",
      "iteration 600 / 1000: loss 1.098516\n",
      "iteration 700 / 1000: loss 1.098520\n",
      "iteration 800 / 1000: loss 1.098532\n",
      "iteration 900 / 1000: loss 1.098534\n",
      "iteration 0 / 1000: loss 1.097997\n",
      "iteration 100 / 1000: loss 1.097599\n",
      "iteration 200 / 1000: loss 1.097801\n",
      "iteration 300 / 1000: loss 1.097716\n",
      "iteration 400 / 1000: loss 1.097765\n",
      "iteration 500 / 1000: loss 1.097546\n",
      "iteration 600 / 1000: loss 1.097273\n",
      "iteration 700 / 1000: loss 1.097548\n",
      "iteration 800 / 1000: loss 1.097045\n",
      "iteration 900 / 1000: loss 1.097143\n",
      "iteration 0 / 1000: loss 1.098586\n",
      "iteration 100 / 1000: loss 1.098380\n",
      "iteration 200 / 1000: loss 1.098523\n",
      "iteration 300 / 1000: loss 1.098265\n",
      "iteration 400 / 1000: loss 1.098136\n",
      "iteration 500 / 1000: loss 1.098104\n",
      "iteration 600 / 1000: loss 1.098111\n",
      "iteration 700 / 1000: loss 1.097741\n",
      "iteration 800 / 1000: loss 1.097789\n",
      "iteration 900 / 1000: loss 1.097514\n",
      "iteration 0 / 1000: loss 1.099031\n",
      "iteration 100 / 1000: loss 1.098941\n",
      "iteration 200 / 1000: loss 1.098833\n",
      "iteration 300 / 1000: loss 1.098501\n",
      "iteration 400 / 1000: loss 1.098471\n",
      "iteration 500 / 1000: loss 1.098417\n",
      "iteration 600 / 1000: loss 1.098178\n",
      "iteration 700 / 1000: loss 1.098012\n",
      "iteration 800 / 1000: loss 1.097723\n",
      "iteration 900 / 1000: loss 1.097527\n",
      "iteration 0 / 1000: loss 1.200744\n",
      "iteration 100 / 1000: loss 1.098600\n",
      "iteration 200 / 1000: loss 1.098602\n",
      "iteration 300 / 1000: loss 1.098600\n",
      "iteration 400 / 1000: loss 1.098599\n",
      "iteration 500 / 1000: loss 1.098602\n",
      "iteration 600 / 1000: loss 1.098600\n",
      "iteration 700 / 1000: loss 1.098600\n",
      "iteration 800 / 1000: loss 1.098602\n",
      "iteration 900 / 1000: loss 1.098600\n",
      "iteration 0 / 1000: loss 1.099604\n",
      "iteration 100 / 1000: loss 1.099129\n",
      "iteration 200 / 1000: loss 1.098900\n",
      "iteration 300 / 1000: loss 1.098524\n",
      "iteration 400 / 1000: loss 1.098824\n",
      "iteration 500 / 1000: loss 1.098395\n",
      "iteration 600 / 1000: loss 1.098195\n",
      "iteration 700 / 1000: loss 1.098304\n",
      "iteration 800 / 1000: loss 1.098323\n",
      "iteration 900 / 1000: loss 1.098102\n",
      "iteration 0 / 1000: loss 1.099897\n",
      "iteration 100 / 1000: loss 1.099787\n",
      "iteration 200 / 1000: loss 1.099528\n",
      "iteration 300 / 1000: loss 1.099698\n",
      "iteration 400 / 1000: loss 1.099513\n",
      "iteration 500 / 1000: loss 1.099234\n",
      "iteration 600 / 1000: loss 1.098711\n",
      "iteration 700 / 1000: loss 1.098592\n",
      "iteration 800 / 1000: loss 1.098475\n",
      "iteration 900 / 1000: loss 1.098498\n",
      "iteration 0 / 1000: loss 1.099120\n",
      "iteration 100 / 1000: loss 1.098990\n",
      "iteration 200 / 1000: loss 1.098727\n",
      "iteration 300 / 1000: loss 1.098705\n",
      "iteration 400 / 1000: loss 1.098586\n",
      "iteration 500 / 1000: loss 1.098480\n",
      "iteration 600 / 1000: loss 1.098404\n",
      "iteration 700 / 1000: loss 1.098008\n",
      "iteration 800 / 1000: loss 1.097882\n",
      "iteration 900 / 1000: loss 1.097781\n",
      "iteration 0 / 1000: loss 1.099463\n",
      "iteration 100 / 1000: loss 1.099456\n",
      "iteration 200 / 1000: loss 1.099176\n",
      "iteration 300 / 1000: loss 1.098980\n",
      "iteration 400 / 1000: loss 1.098590\n",
      "iteration 500 / 1000: loss 1.098651\n",
      "iteration 600 / 1000: loss 1.098570\n",
      "iteration 700 / 1000: loss 1.098718\n",
      "iteration 800 / 1000: loss 1.098418\n",
      "iteration 900 / 1000: loss 1.098045\n",
      "iteration 0 / 1000: loss 1.098862\n",
      "iteration 100 / 1000: loss 1.098748\n",
      "iteration 200 / 1000: loss 1.098405\n",
      "iteration 300 / 1000: loss 1.098378\n",
      "iteration 400 / 1000: loss 1.098139\n",
      "iteration 500 / 1000: loss 1.098092\n",
      "iteration 600 / 1000: loss 1.097934\n",
      "iteration 700 / 1000: loss 1.097744\n",
      "iteration 800 / 1000: loss 1.097541\n",
      "iteration 900 / 1000: loss 1.097427\n",
      "iteration 0 / 1000: loss 1.103172\n",
      "iteration 100 / 1000: loss 1.099384\n",
      "iteration 200 / 1000: loss 1.098705\n",
      "iteration 300 / 1000: loss 1.098526\n",
      "iteration 400 / 1000: loss 1.098520\n",
      "iteration 500 / 1000: loss 1.098517\n",
      "iteration 600 / 1000: loss 1.098512\n",
      "iteration 700 / 1000: loss 1.098513\n",
      "iteration 800 / 1000: loss 1.098525\n",
      "iteration 900 / 1000: loss 1.098511\n",
      "iteration 0 / 1000: loss 1.097700\n",
      "iteration 100 / 1000: loss 1.098020\n",
      "iteration 200 / 1000: loss 1.097738\n",
      "iteration 300 / 1000: loss 1.097562\n",
      "iteration 400 / 1000: loss 1.097711\n",
      "iteration 500 / 1000: loss 1.097539\n",
      "iteration 600 / 1000: loss 1.097112\n",
      "iteration 700 / 1000: loss 1.097145\n",
      "iteration 800 / 1000: loss 1.097089\n",
      "iteration 900 / 1000: loss 1.096541\n",
      "iteration 0 / 1000: loss 1.098894\n",
      "iteration 100 / 1000: loss 1.098867\n",
      "iteration 200 / 1000: loss 1.098642\n",
      "iteration 300 / 1000: loss 1.098631\n",
      "iteration 400 / 1000: loss 1.098297\n",
      "iteration 500 / 1000: loss 1.098053\n",
      "iteration 600 / 1000: loss 1.097919\n",
      "iteration 700 / 1000: loss 1.098054\n",
      "iteration 800 / 1000: loss 1.097653\n",
      "iteration 900 / 1000: loss 1.097615\n",
      "iteration 0 / 1000: loss 1.098333\n",
      "iteration 100 / 1000: loss 1.098017\n",
      "iteration 200 / 1000: loss 1.097793\n",
      "iteration 300 / 1000: loss 1.097427\n",
      "iteration 400 / 1000: loss 1.097163\n",
      "iteration 500 / 1000: loss 1.097039\n",
      "iteration 600 / 1000: loss 1.096800\n",
      "iteration 700 / 1000: loss 1.096516\n",
      "iteration 800 / 1000: loss 1.096422\n",
      "iteration 900 / 1000: loss 1.096267\n",
      "iteration 0 / 1000: loss 1.178266\n",
      "iteration 100 / 1000: loss 1.098600\n",
      "iteration 200 / 1000: loss 1.098601\n",
      "iteration 300 / 1000: loss 1.098599\n",
      "iteration 400 / 1000: loss 1.098597\n",
      "iteration 500 / 1000: loss 1.098601\n",
      "iteration 600 / 1000: loss 1.098599\n",
      "iteration 700 / 1000: loss 1.098601\n",
      "iteration 800 / 1000: loss 1.098602\n",
      "iteration 900 / 1000: loss 1.098601\n",
      "iteration 0 / 1000: loss 1.100948\n",
      "iteration 100 / 1000: loss 1.100239\n",
      "iteration 200 / 1000: loss 1.099609\n",
      "iteration 300 / 1000: loss 1.099155\n",
      "iteration 400 / 1000: loss 1.098777\n",
      "iteration 500 / 1000: loss 1.098635\n",
      "iteration 600 / 1000: loss 1.098329\n",
      "iteration 700 / 1000: loss 1.098132\n",
      "iteration 800 / 1000: loss 1.098162\n",
      "iteration 900 / 1000: loss 1.098019\n",
      "iteration 0 / 1000: loss 1.100233\n",
      "iteration 100 / 1000: loss 1.099908\n",
      "iteration 200 / 1000: loss 1.099818\n",
      "iteration 300 / 1000: loss 1.099443\n",
      "iteration 400 / 1000: loss 1.099371\n",
      "iteration 500 / 1000: loss 1.099045\n",
      "iteration 600 / 1000: loss 1.098885\n",
      "iteration 700 / 1000: loss 1.098591\n",
      "iteration 800 / 1000: loss 1.098332\n",
      "iteration 900 / 1000: loss 1.098198\n",
      "iteration 0 / 1000: loss 1.098416\n",
      "iteration 100 / 1000: loss 1.098185\n",
      "iteration 200 / 1000: loss 1.097970\n",
      "iteration 300 / 1000: loss 1.097672\n",
      "iteration 400 / 1000: loss 1.097566\n",
      "iteration 500 / 1000: loss 1.097396\n",
      "iteration 600 / 1000: loss 1.097115\n",
      "iteration 700 / 1000: loss 1.096866\n",
      "iteration 800 / 1000: loss 1.096632\n",
      "iteration 900 / 1000: loss 1.096500\n",
      "iteration 0 / 1000: loss 1.098765\n",
      "iteration 100 / 1000: loss 1.098505\n",
      "iteration 200 / 1000: loss 1.098666\n",
      "iteration 300 / 1000: loss 1.098391\n",
      "iteration 400 / 1000: loss 1.097876\n",
      "iteration 500 / 1000: loss 1.097752\n",
      "iteration 600 / 1000: loss 1.097523\n",
      "iteration 700 / 1000: loss 1.097515\n",
      "iteration 800 / 1000: loss 1.097133\n",
      "iteration 900 / 1000: loss 1.096917\n",
      "iteration 0 / 1000: loss 1.098328\n",
      "iteration 100 / 1000: loss 1.098176\n",
      "iteration 200 / 1000: loss 1.097852\n",
      "iteration 300 / 1000: loss 1.097742\n",
      "iteration 400 / 1000: loss 1.097428\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration 500 / 1000: loss 1.097466\n",
      "iteration 600 / 1000: loss 1.097123\n",
      "iteration 700 / 1000: loss 1.096962\n",
      "iteration 800 / 1000: loss 1.096410\n",
      "iteration 900 / 1000: loss 1.096384\n",
      "iteration 0 / 1000: loss 1.122683\n",
      "iteration 100 / 1000: loss 1.100614\n",
      "iteration 200 / 1000: loss 1.098712\n",
      "iteration 300 / 1000: loss 1.098533\n",
      "iteration 400 / 1000: loss 1.098528\n",
      "iteration 500 / 1000: loss 1.098515\n",
      "iteration 600 / 1000: loss 1.098502\n",
      "iteration 700 / 1000: loss 1.098525\n",
      "iteration 800 / 1000: loss 1.098515\n",
      "iteration 900 / 1000: loss 1.098506\n",
      "iteration 0 / 1000: loss 1.098453\n",
      "iteration 100 / 1000: loss 1.098534\n",
      "iteration 200 / 1000: loss 1.098136\n",
      "iteration 300 / 1000: loss 1.097967\n",
      "iteration 400 / 1000: loss 1.097540\n",
      "iteration 500 / 1000: loss 1.097585\n",
      "iteration 600 / 1000: loss 1.097372\n",
      "iteration 700 / 1000: loss 1.096948\n",
      "iteration 800 / 1000: loss 1.096858\n",
      "iteration 900 / 1000: loss 1.097317\n",
      "iteration 0 / 1000: loss 1.099405\n",
      "iteration 100 / 1000: loss 1.099211\n",
      "iteration 200 / 1000: loss 1.098925\n",
      "iteration 300 / 1000: loss 1.098751\n",
      "iteration 400 / 1000: loss 1.098495\n",
      "iteration 500 / 1000: loss 1.098303\n",
      "iteration 600 / 1000: loss 1.098059\n",
      "iteration 700 / 1000: loss 1.097792\n",
      "iteration 800 / 1000: loss 1.097595\n",
      "iteration 900 / 1000: loss 1.097287\n",
      "iteration 0 / 1000: loss 1.098038\n",
      "iteration 100 / 1000: loss 1.097793\n",
      "iteration 200 / 1000: loss 1.097276\n",
      "iteration 300 / 1000: loss 1.096764\n",
      "iteration 400 / 1000: loss 1.096763\n",
      "iteration 500 / 1000: loss 1.096386\n",
      "iteration 600 / 1000: loss 1.096271\n",
      "iteration 700 / 1000: loss 1.095587\n",
      "iteration 800 / 1000: loss 1.095186\n",
      "iteration 900 / 1000: loss 1.095121\n",
      "iteration 0 / 1000: loss 1.142941\n",
      "iteration 100 / 1000: loss 1.098602\n",
      "iteration 200 / 1000: loss 1.098597\n",
      "iteration 300 / 1000: loss 1.098602\n",
      "iteration 400 / 1000: loss 1.098603\n",
      "iteration 500 / 1000: loss 1.098601\n",
      "iteration 600 / 1000: loss 1.098599\n",
      "iteration 700 / 1000: loss 1.098600\n",
      "iteration 800 / 1000: loss 1.098597\n",
      "iteration 900 / 1000: loss 1.098599\n",
      "iteration 0 / 1000: loss 1.099232\n",
      "iteration 100 / 1000: loss 1.098730\n",
      "iteration 200 / 1000: loss 1.098427\n",
      "iteration 300 / 1000: loss 1.098270\n",
      "iteration 400 / 1000: loss 1.098034\n",
      "iteration 500 / 1000: loss 1.098082\n",
      "iteration 600 / 1000: loss 1.097925\n",
      "iteration 700 / 1000: loss 1.097887\n",
      "iteration 800 / 1000: loss 1.097870\n",
      "iteration 900 / 1000: loss 1.097824\n",
      "iteration 0 / 1000: loss 1.098580\n",
      "iteration 100 / 1000: loss 1.098248\n",
      "iteration 200 / 1000: loss 1.097892\n",
      "iteration 300 / 1000: loss 1.097320\n",
      "iteration 400 / 1000: loss 1.097446\n",
      "iteration 500 / 1000: loss 1.097193\n",
      "iteration 600 / 1000: loss 1.096507\n",
      "iteration 700 / 1000: loss 1.096283\n",
      "iteration 800 / 1000: loss 1.095747\n",
      "iteration 900 / 1000: loss 1.095993\n",
      "iteration 0 / 1000: loss 1.097647\n",
      "iteration 100 / 1000: loss 1.097306\n",
      "iteration 200 / 1000: loss 1.096924\n",
      "iteration 300 / 1000: loss 1.096678\n",
      "iteration 400 / 1000: loss 1.096342\n",
      "iteration 500 / 1000: loss 1.095930\n",
      "iteration 600 / 1000: loss 1.095545\n",
      "iteration 700 / 1000: loss 1.095309\n",
      "iteration 800 / 1000: loss 1.095262\n",
      "iteration 900 / 1000: loss 1.094803\n",
      "iteration 0 / 1000: loss 1.098756\n",
      "iteration 100 / 1000: loss 1.098461\n",
      "iteration 200 / 1000: loss 1.098073\n",
      "iteration 300 / 1000: loss 1.097799\n",
      "iteration 400 / 1000: loss 1.097468\n",
      "iteration 500 / 1000: loss 1.097050\n",
      "iteration 600 / 1000: loss 1.097081\n",
      "iteration 700 / 1000: loss 1.096700\n",
      "iteration 800 / 1000: loss 1.096296\n",
      "iteration 900 / 1000: loss 1.095602\n",
      "iteration 0 / 1000: loss 1.097981\n",
      "iteration 100 / 1000: loss 1.097434\n",
      "iteration 200 / 1000: loss 1.097113\n",
      "iteration 300 / 1000: loss 1.096836\n",
      "iteration 400 / 1000: loss 1.096611\n",
      "iteration 500 / 1000: loss 1.095941\n",
      "iteration 600 / 1000: loss 1.096135\n",
      "iteration 700 / 1000: loss 1.095471\n",
      "iteration 800 / 1000: loss 1.095262\n",
      "iteration 900 / 1000: loss 1.094633\n",
      "iteration 0 / 1000: loss 1.112438\n",
      "iteration 100 / 1000: loss 1.098906\n",
      "iteration 200 / 1000: loss 1.098514\n",
      "iteration 300 / 1000: loss 1.098518\n",
      "iteration 400 / 1000: loss 1.098530\n",
      "iteration 500 / 1000: loss 1.098507\n",
      "iteration 600 / 1000: loss 1.098522\n",
      "iteration 700 / 1000: loss 1.098510\n",
      "iteration 800 / 1000: loss 1.098517\n",
      "iteration 900 / 1000: loss 1.098511\n",
      "iteration 0 / 1000: loss 1.098677\n",
      "iteration 100 / 1000: loss 1.098296\n",
      "iteration 200 / 1000: loss 1.098040\n",
      "iteration 300 / 1000: loss 1.097726\n",
      "iteration 400 / 1000: loss 1.097542\n",
      "iteration 500 / 1000: loss 1.097190\n",
      "iteration 600 / 1000: loss 1.096955\n",
      "iteration 700 / 1000: loss 1.096744\n",
      "iteration 800 / 1000: loss 1.096427\n",
      "iteration 900 / 1000: loss 1.096560\n",
      "iteration 0 / 1000: loss 1.098695\n",
      "iteration 100 / 1000: loss 1.098383\n",
      "iteration 200 / 1000: loss 1.098005\n",
      "iteration 300 / 1000: loss 1.097778\n",
      "iteration 400 / 1000: loss 1.097577\n",
      "iteration 500 / 1000: loss 1.097043\n",
      "iteration 600 / 1000: loss 1.096707\n",
      "iteration 700 / 1000: loss 1.096654\n",
      "iteration 800 / 1000: loss 1.095748\n",
      "iteration 900 / 1000: loss 1.095500\n",
      "iteration 0 / 1000: loss 1.098641\n",
      "iteration 100 / 1000: loss 1.098078\n",
      "iteration 200 / 1000: loss 1.097750\n",
      "iteration 300 / 1000: loss 1.097188\n",
      "iteration 400 / 1000: loss 1.096733\n",
      "iteration 500 / 1000: loss 1.096058\n",
      "iteration 600 / 1000: loss 1.095675\n",
      "iteration 700 / 1000: loss 1.094956\n",
      "iteration 800 / 1000: loss 1.094837\n",
      "iteration 900 / 1000: loss 1.094420\n",
      "iteration 0 / 1000: loss 1.154727\n",
      "iteration 100 / 1000: loss 1.098601\n",
      "iteration 200 / 1000: loss 1.098600\n",
      "iteration 300 / 1000: loss 1.098600\n",
      "iteration 400 / 1000: loss 1.098602\n",
      "iteration 500 / 1000: loss 1.098601\n",
      "iteration 600 / 1000: loss 1.098599\n",
      "iteration 700 / 1000: loss 1.098600\n",
      "iteration 800 / 1000: loss 1.098600\n",
      "iteration 900 / 1000: loss 1.098602\n",
      "iteration 0 / 1000: loss 1.098779\n",
      "iteration 100 / 1000: loss 1.098292\n",
      "iteration 200 / 1000: loss 1.098102\n",
      "iteration 300 / 1000: loss 1.098041\n",
      "iteration 400 / 1000: loss 1.098052\n",
      "iteration 500 / 1000: loss 1.097958\n",
      "iteration 600 / 1000: loss 1.097941\n",
      "iteration 700 / 1000: loss 1.098055\n",
      "iteration 800 / 1000: loss 1.098017\n",
      "iteration 900 / 1000: loss 1.097963\n",
      "iteration 0 / 1000: loss 1.098847\n",
      "iteration 100 / 1000: loss 1.098315\n",
      "iteration 200 / 1000: loss 1.097916\n",
      "iteration 300 / 1000: loss 1.097419\n",
      "iteration 400 / 1000: loss 1.096870\n",
      "iteration 500 / 1000: loss 1.096427\n",
      "iteration 600 / 1000: loss 1.095831\n",
      "iteration 700 / 1000: loss 1.095279\n",
      "iteration 800 / 1000: loss 1.094937\n",
      "iteration 900 / 1000: loss 1.094844\n",
      "iteration 0 / 1000: loss 1.099064\n",
      "iteration 100 / 1000: loss 1.098563\n",
      "iteration 200 / 1000: loss 1.097980\n",
      "iteration 300 / 1000: loss 1.097601\n",
      "iteration 400 / 1000: loss 1.097184\n",
      "iteration 500 / 1000: loss 1.096484\n",
      "iteration 600 / 1000: loss 1.096448\n",
      "iteration 700 / 1000: loss 1.095907\n",
      "iteration 800 / 1000: loss 1.095289\n",
      "iteration 900 / 1000: loss 1.095197\n",
      "iteration 0 / 1000: loss 1.097593\n",
      "iteration 100 / 1000: loss 1.097071\n",
      "iteration 200 / 1000: loss 1.096440\n",
      "iteration 300 / 1000: loss 1.096259\n",
      "iteration 400 / 1000: loss 1.095524\n",
      "iteration 500 / 1000: loss 1.095329\n",
      "iteration 600 / 1000: loss 1.095327\n",
      "iteration 700 / 1000: loss 1.094394\n",
      "iteration 800 / 1000: loss 1.093989\n",
      "iteration 900 / 1000: loss 1.093220\n",
      "iteration 0 / 1000: loss 1.100189\n",
      "iteration 100 / 1000: loss 1.099694\n",
      "iteration 200 / 1000: loss 1.099272\n",
      "iteration 300 / 1000: loss 1.098663\n",
      "iteration 400 / 1000: loss 1.098192\n",
      "iteration 500 / 1000: loss 1.097700\n",
      "iteration 600 / 1000: loss 1.097401\n",
      "iteration 700 / 1000: loss 1.096901\n",
      "iteration 800 / 1000: loss 1.096450\n",
      "iteration 900 / 1000: loss 1.095862\n",
      "iteration 0 / 1000: loss 1.108537\n",
      "iteration 100 / 1000: loss 1.098559\n",
      "iteration 200 / 1000: loss 1.098508\n",
      "iteration 300 / 1000: loss 1.098521\n",
      "iteration 400 / 1000: loss 1.098516\n",
      "iteration 500 / 1000: loss 1.098526\n",
      "iteration 600 / 1000: loss 1.098516\n",
      "iteration 700 / 1000: loss 1.098535\n",
      "iteration 800 / 1000: loss 1.098520\n",
      "iteration 900 / 1000: loss 1.098520\n",
      "iteration 0 / 1000: loss 1.098594\n",
      "iteration 100 / 1000: loss 1.098129\n",
      "iteration 200 / 1000: loss 1.097670\n",
      "iteration 300 / 1000: loss 1.097229\n",
      "iteration 400 / 1000: loss 1.096907\n",
      "iteration 500 / 1000: loss 1.096573\n",
      "iteration 600 / 1000: loss 1.096180\n",
      "iteration 700 / 1000: loss 1.096292\n",
      "iteration 800 / 1000: loss 1.095544\n",
      "iteration 900 / 1000: loss 1.095596\n",
      "iteration 0 / 1000: loss 1.098316\n",
      "iteration 100 / 1000: loss 1.097837\n",
      "iteration 200 / 1000: loss 1.097356\n",
      "iteration 300 / 1000: loss 1.096887\n",
      "iteration 400 / 1000: loss 1.096299\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration 500 / 1000: loss 1.095815\n",
      "iteration 600 / 1000: loss 1.095445\n",
      "iteration 700 / 1000: loss 1.094918\n",
      "iteration 800 / 1000: loss 1.094460\n",
      "iteration 900 / 1000: loss 1.094138\n",
      "iteration 0 / 1000: loss 1.099098\n",
      "iteration 100 / 1000: loss 1.098311\n",
      "iteration 200 / 1000: loss 1.097538\n",
      "iteration 300 / 1000: loss 1.096835\n",
      "iteration 400 / 1000: loss 1.096258\n",
      "iteration 500 / 1000: loss 1.095608\n",
      "iteration 600 / 1000: loss 1.094891\n",
      "iteration 700 / 1000: loss 1.094096\n",
      "iteration 800 / 1000: loss 1.093817\n",
      "iteration 900 / 1000: loss 1.092485\n",
      "iteration 0 / 1000: loss 1.213154\n",
      "iteration 100 / 1000: loss 1.098599\n",
      "iteration 200 / 1000: loss 1.098600\n",
      "iteration 300 / 1000: loss 1.098602\n",
      "iteration 400 / 1000: loss 1.098601\n",
      "iteration 500 / 1000: loss 1.098599\n",
      "iteration 600 / 1000: loss 1.098598\n",
      "iteration 700 / 1000: loss 1.098600\n",
      "iteration 800 / 1000: loss 1.098601\n",
      "iteration 900 / 1000: loss 1.098599\n",
      "iteration 0 / 1000: loss 1.100323\n",
      "iteration 100 / 1000: loss 1.098811\n",
      "iteration 200 / 1000: loss 1.098291\n",
      "iteration 300 / 1000: loss 1.097987\n",
      "iteration 400 / 1000: loss 1.097935\n",
      "iteration 500 / 1000: loss 1.097962\n",
      "iteration 600 / 1000: loss 1.097884\n",
      "iteration 700 / 1000: loss 1.098046\n",
      "iteration 800 / 1000: loss 1.097832\n",
      "iteration 900 / 1000: loss 1.097947\n",
      "iteration 0 / 1000: loss 1.098921\n",
      "iteration 100 / 1000: loss 1.098107\n",
      "iteration 200 / 1000: loss 1.097496\n",
      "iteration 300 / 1000: loss 1.096854\n",
      "iteration 400 / 1000: loss 1.096083\n",
      "iteration 500 / 1000: loss 1.095978\n",
      "iteration 600 / 1000: loss 1.094584\n",
      "iteration 700 / 1000: loss 1.093904\n",
      "iteration 800 / 1000: loss 1.094033\n",
      "iteration 900 / 1000: loss 1.092402\n",
      "iteration 0 / 1000: loss 1.099833\n",
      "iteration 100 / 1000: loss 1.099183\n",
      "iteration 200 / 1000: loss 1.098324\n",
      "iteration 300 / 1000: loss 1.097754\n",
      "iteration 400 / 1000: loss 1.097197\n",
      "iteration 500 / 1000: loss 1.096242\n",
      "iteration 600 / 1000: loss 1.095305\n",
      "iteration 700 / 1000: loss 1.094530\n",
      "iteration 800 / 1000: loss 1.093862\n",
      "iteration 900 / 1000: loss 1.093453\n",
      "iteration 0 / 1000: loss 1.099342\n",
      "iteration 100 / 1000: loss 1.098581\n",
      "iteration 200 / 1000: loss 1.098004\n",
      "iteration 300 / 1000: loss 1.097102\n",
      "iteration 400 / 1000: loss 1.096507\n",
      "iteration 500 / 1000: loss 1.095700\n",
      "iteration 600 / 1000: loss 1.094448\n",
      "iteration 700 / 1000: loss 1.094526\n",
      "iteration 800 / 1000: loss 1.092868\n",
      "iteration 900 / 1000: loss 1.091938\n",
      "iteration 0 / 1000: loss 1.098176\n",
      "iteration 100 / 1000: loss 1.097621\n",
      "iteration 200 / 1000: loss 1.096723\n",
      "iteration 300 / 1000: loss 1.095941\n",
      "iteration 400 / 1000: loss 1.095307\n",
      "iteration 500 / 1000: loss 1.094885\n",
      "iteration 600 / 1000: loss 1.094413\n",
      "iteration 700 / 1000: loss 1.093063\n",
      "iteration 800 / 1000: loss 1.093864\n",
      "iteration 900 / 1000: loss 1.091973\n",
      "iteration 0 / 1000: loss 1.103191\n",
      "iteration 100 / 1000: loss 1.098498\n",
      "iteration 200 / 1000: loss 1.098535\n",
      "iteration 300 / 1000: loss 1.098515\n",
      "iteration 400 / 1000: loss 1.098523\n",
      "iteration 500 / 1000: loss 1.098526\n",
      "iteration 600 / 1000: loss 1.098532\n",
      "iteration 700 / 1000: loss 1.098524\n",
      "iteration 800 / 1000: loss 1.098531\n",
      "iteration 900 / 1000: loss 1.098510\n",
      "iteration 0 / 1000: loss 1.099137\n",
      "iteration 100 / 1000: loss 1.098605\n",
      "iteration 200 / 1000: loss 1.097946\n",
      "iteration 300 / 1000: loss 1.097259\n",
      "iteration 400 / 1000: loss 1.097116\n",
      "iteration 500 / 1000: loss 1.096599\n",
      "iteration 600 / 1000: loss 1.096312\n",
      "iteration 700 / 1000: loss 1.095369\n",
      "iteration 800 / 1000: loss 1.095257\n",
      "iteration 900 / 1000: loss 1.095043\n",
      "iteration 0 / 1000: loss 1.098654\n",
      "iteration 100 / 1000: loss 1.097975\n",
      "iteration 200 / 1000: loss 1.097309\n",
      "iteration 300 / 1000: loss 1.096484\n",
      "iteration 400 / 1000: loss 1.095850\n",
      "iteration 500 / 1000: loss 1.095012\n",
      "iteration 600 / 1000: loss 1.094217\n",
      "iteration 700 / 1000: loss 1.093396\n",
      "iteration 800 / 1000: loss 1.093113\n",
      "iteration 900 / 1000: loss 1.091453\n",
      "iteration 0 / 1000: loss 1.098334\n",
      "iteration 100 / 1000: loss 1.097218\n",
      "iteration 200 / 1000: loss 1.096188\n",
      "iteration 300 / 1000: loss 1.095259\n",
      "iteration 400 / 1000: loss 1.094159\n",
      "iteration 500 / 1000: loss 1.093417\n",
      "iteration 600 / 1000: loss 1.091230\n",
      "iteration 700 / 1000: loss 1.091085\n",
      "iteration 800 / 1000: loss 1.090556\n",
      "iteration 900 / 1000: loss 1.088094\n",
      "iteration 0 / 1000: loss 1.171346\n",
      "iteration 100 / 1000: loss 1.098600\n",
      "iteration 200 / 1000: loss 1.098600\n",
      "iteration 300 / 1000: loss 1.098602\n",
      "iteration 400 / 1000: loss 1.098601\n",
      "iteration 500 / 1000: loss 1.098600\n",
      "iteration 600 / 1000: loss 1.098599\n",
      "iteration 700 / 1000: loss 1.098599\n",
      "iteration 800 / 1000: loss 1.098601\n",
      "iteration 900 / 1000: loss 1.098598\n",
      "iteration 0 / 1000: loss 1.099253\n",
      "iteration 100 / 1000: loss 1.098234\n",
      "iteration 200 / 1000: loss 1.098002\n",
      "iteration 300 / 1000: loss 1.097941\n",
      "iteration 400 / 1000: loss 1.097881\n",
      "iteration 500 / 1000: loss 1.097842\n",
      "iteration 600 / 1000: loss 1.097749\n",
      "iteration 700 / 1000: loss 1.097973\n",
      "iteration 800 / 1000: loss 1.097481\n",
      "iteration 900 / 1000: loss 1.097964\n",
      "iteration 0 / 1000: loss 1.098441\n",
      "iteration 100 / 1000: loss 1.097330\n",
      "iteration 200 / 1000: loss 1.096374\n",
      "iteration 300 / 1000: loss 1.095463\n",
      "iteration 400 / 1000: loss 1.094204\n",
      "iteration 500 / 1000: loss 1.093477\n",
      "iteration 600 / 1000: loss 1.092678\n",
      "iteration 700 / 1000: loss 1.091073\n",
      "iteration 800 / 1000: loss 1.090388\n",
      "iteration 900 / 1000: loss 1.090203\n",
      "iteration 0 / 1000: loss 1.097966\n",
      "iteration 100 / 1000: loss 1.097172\n",
      "iteration 200 / 1000: loss 1.096173\n",
      "iteration 300 / 1000: loss 1.095030\n",
      "iteration 400 / 1000: loss 1.094280\n",
      "iteration 500 / 1000: loss 1.092903\n",
      "iteration 600 / 1000: loss 1.092402\n",
      "iteration 700 / 1000: loss 1.090833\n",
      "iteration 800 / 1000: loss 1.091046\n",
      "iteration 900 / 1000: loss 1.088414\n",
      "iteration 0 / 1000: loss 1.099201\n",
      "iteration 100 / 1000: loss 1.098249\n",
      "iteration 200 / 1000: loss 1.097266\n",
      "iteration 300 / 1000: loss 1.095911\n",
      "iteration 400 / 1000: loss 1.094956\n",
      "iteration 500 / 1000: loss 1.093614\n",
      "iteration 600 / 1000: loss 1.093280\n",
      "iteration 700 / 1000: loss 1.091772\n",
      "iteration 800 / 1000: loss 1.090590\n",
      "iteration 900 / 1000: loss 1.090497\n",
      "iteration 0 / 1000: loss 1.098863\n",
      "iteration 100 / 1000: loss 1.097835\n",
      "iteration 200 / 1000: loss 1.096851\n",
      "iteration 300 / 1000: loss 1.095742\n",
      "iteration 400 / 1000: loss 1.094162\n",
      "iteration 500 / 1000: loss 1.093585\n",
      "iteration 600 / 1000: loss 1.092228\n",
      "iteration 700 / 1000: loss 1.091248\n",
      "iteration 800 / 1000: loss 1.090467\n",
      "iteration 900 / 1000: loss 1.089863\n",
      "iteration 0 / 1000: loss 1.109300\n",
      "iteration 100 / 1000: loss 1.098523\n",
      "iteration 200 / 1000: loss 1.098508\n",
      "iteration 300 / 1000: loss 1.098528\n",
      "iteration 400 / 1000: loss 1.098521\n",
      "iteration 500 / 1000: loss 1.098526\n",
      "iteration 600 / 1000: loss 1.098510\n",
      "iteration 700 / 1000: loss 1.098490\n",
      "iteration 800 / 1000: loss 1.098514\n",
      "iteration 900 / 1000: loss 1.098531\n",
      "iteration 0 / 1000: loss 1.099017\n",
      "iteration 100 / 1000: loss 1.097967\n",
      "iteration 200 / 1000: loss 1.097346\n",
      "iteration 300 / 1000: loss 1.096404\n",
      "iteration 400 / 1000: loss 1.095660\n",
      "iteration 500 / 1000: loss 1.095439\n",
      "iteration 600 / 1000: loss 1.095111\n",
      "iteration 700 / 1000: loss 1.093830\n",
      "iteration 800 / 1000: loss 1.094955\n",
      "iteration 900 / 1000: loss 1.094518\n",
      "iteration 0 / 1000: loss 1.099523\n",
      "iteration 100 / 1000: loss 1.098468\n",
      "iteration 200 / 1000: loss 1.097364\n",
      "iteration 300 / 1000: loss 1.096526\n",
      "iteration 400 / 1000: loss 1.095662\n",
      "iteration 500 / 1000: loss 1.094309\n",
      "iteration 600 / 1000: loss 1.093240\n",
      "iteration 700 / 1000: loss 1.092015\n",
      "iteration 800 / 1000: loss 1.091370\n",
      "iteration 900 / 1000: loss 1.089787\n",
      "iteration 0 / 1000: loss 1.098176\n",
      "iteration 100 / 1000: loss 1.096809\n",
      "iteration 200 / 1000: loss 1.094908\n",
      "iteration 300 / 1000: loss 1.093629\n",
      "iteration 400 / 1000: loss 1.092383\n",
      "iteration 500 / 1000: loss 1.089999\n",
      "iteration 600 / 1000: loss 1.089870\n",
      "iteration 700 / 1000: loss 1.087529\n",
      "iteration 800 / 1000: loss 1.085587\n",
      "iteration 900 / 1000: loss 1.084069\n",
      "iteration 0 / 1000: loss 1.140520\n",
      "iteration 100 / 1000: loss 1.098599\n",
      "iteration 200 / 1000: loss 1.098602\n",
      "iteration 300 / 1000: loss 1.098600\n",
      "iteration 400 / 1000: loss 1.098599\n",
      "iteration 500 / 1000: loss 1.098600\n",
      "iteration 600 / 1000: loss 1.098600\n",
      "iteration 700 / 1000: loss 1.098600\n",
      "iteration 800 / 1000: loss 1.098600\n",
      "iteration 900 / 1000: loss 1.098601\n",
      "iteration 0 / 1000: loss 1.099699\n",
      "iteration 100 / 1000: loss 1.098106\n",
      "iteration 200 / 1000: loss 1.097899\n",
      "iteration 300 / 1000: loss 1.097942\n",
      "iteration 400 / 1000: loss 1.097882\n",
      "iteration 500 / 1000: loss 1.097932\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration 600 / 1000: loss 1.097747\n",
      "iteration 700 / 1000: loss 1.097799\n",
      "iteration 800 / 1000: loss 1.097875\n",
      "iteration 900 / 1000: loss 1.097892\n",
      "iteration 0 / 1000: loss 1.097702\n",
      "iteration 100 / 1000: loss 1.096275\n",
      "iteration 200 / 1000: loss 1.095131\n",
      "iteration 300 / 1000: loss 1.093326\n",
      "iteration 400 / 1000: loss 1.091859\n",
      "iteration 500 / 1000: loss 1.090553\n",
      "iteration 600 / 1000: loss 1.089384\n",
      "iteration 700 / 1000: loss 1.087749\n",
      "iteration 800 / 1000: loss 1.087682\n",
      "iteration 900 / 1000: loss 1.086340\n",
      "iteration 0 / 1000: loss 1.099676\n",
      "iteration 100 / 1000: loss 1.097834\n",
      "iteration 200 / 1000: loss 1.096808\n",
      "iteration 300 / 1000: loss 1.094541\n",
      "iteration 400 / 1000: loss 1.092868\n",
      "iteration 500 / 1000: loss 1.091790\n",
      "iteration 600 / 1000: loss 1.090154\n",
      "iteration 700 / 1000: loss 1.088702\n",
      "iteration 800 / 1000: loss 1.087795\n",
      "iteration 900 / 1000: loss 1.085906\n",
      "iteration 0 / 1000: loss 1.097937\n",
      "iteration 100 / 1000: loss 1.096295\n",
      "iteration 200 / 1000: loss 1.095409\n",
      "iteration 300 / 1000: loss 1.093746\n",
      "iteration 400 / 1000: loss 1.091203\n",
      "iteration 500 / 1000: loss 1.090189\n",
      "iteration 600 / 1000: loss 1.088895\n",
      "iteration 700 / 1000: loss 1.086970\n",
      "iteration 800 / 1000: loss 1.086295\n",
      "iteration 900 / 1000: loss 1.083977\n",
      "iteration 0 / 1000: loss 1.098049\n",
      "iteration 100 / 1000: loss 1.096461\n",
      "iteration 200 / 1000: loss 1.095383\n",
      "iteration 300 / 1000: loss 1.093380\n",
      "iteration 400 / 1000: loss 1.091630\n",
      "iteration 500 / 1000: loss 1.089461\n",
      "iteration 600 / 1000: loss 1.088516\n",
      "iteration 700 / 1000: loss 1.085659\n",
      "iteration 800 / 1000: loss 1.086675\n",
      "iteration 900 / 1000: loss 1.084919\n",
      "iteration 0 / 1000: loss 1.105772\n",
      "iteration 100 / 1000: loss 1.098524\n",
      "iteration 200 / 1000: loss 1.098505\n",
      "iteration 300 / 1000: loss 1.098521\n",
      "iteration 400 / 1000: loss 1.098493\n",
      "iteration 500 / 1000: loss 1.098525\n",
      "iteration 600 / 1000: loss 1.098514\n",
      "iteration 700 / 1000: loss 1.098537\n",
      "iteration 800 / 1000: loss 1.098493\n",
      "iteration 900 / 1000: loss 1.098534\n",
      "iteration 0 / 1000: loss 1.099799\n",
      "iteration 100 / 1000: loss 1.098140\n",
      "iteration 200 / 1000: loss 1.096936\n",
      "iteration 300 / 1000: loss 1.095956\n",
      "iteration 400 / 1000: loss 1.095325\n",
      "iteration 500 / 1000: loss 1.094695\n",
      "iteration 600 / 1000: loss 1.094122\n",
      "iteration 700 / 1000: loss 1.093874\n",
      "iteration 800 / 1000: loss 1.095032\n",
      "iteration 900 / 1000: loss 1.094533\n",
      "iteration 0 / 1000: loss 1.097162\n",
      "iteration 100 / 1000: loss 1.095409\n",
      "iteration 200 / 1000: loss 1.093873\n",
      "iteration 300 / 1000: loss 1.092175\n",
      "iteration 400 / 1000: loss 1.090097\n",
      "iteration 500 / 1000: loss 1.089040\n",
      "iteration 600 / 1000: loss 1.087486\n",
      "iteration 700 / 1000: loss 1.084847\n",
      "iteration 800 / 1000: loss 1.085215\n",
      "iteration 900 / 1000: loss 1.083881\n",
      "lr 1.000000e-06 reg 1.000000e-04 train accuracy: 0.333333\n",
      "lr 1.000000e-06 reg 7.742637e-04 train accuracy: 0.253333\n",
      "lr 1.000000e-06 reg 5.994843e-03 train accuracy: 0.280000\n",
      "lr 1.000000e-06 reg 4.641589e-02 train accuracy: 0.560000\n",
      "lr 1.000000e-06 reg 3.593814e-01 train accuracy: 0.573333\n",
      "lr 1.000000e-06 reg 2.782559e+00 train accuracy: 0.253333\n",
      "lr 1.000000e-06 reg 2.154435e+01 train accuracy: 0.333333\n",
      "lr 1.000000e-06 reg 1.668101e+02 train accuracy: 0.413333\n",
      "lr 1.000000e-06 reg 1.291550e+03 train accuracy: 0.480000\n",
      "lr 1.000000e-06 reg 1.000000e+04 train accuracy: 0.653333\n",
      "lr 1.467799e-06 reg 1.000000e-04 train accuracy: 0.706667\n",
      "lr 1.467799e-06 reg 7.742637e-04 train accuracy: 0.213333\n",
      "lr 1.467799e-06 reg 5.994843e-03 train accuracy: 0.333333\n",
      "lr 1.467799e-06 reg 4.641589e-02 train accuracy: 0.506667\n",
      "lr 1.467799e-06 reg 3.593814e-01 train accuracy: 0.413333\n",
      "lr 1.467799e-06 reg 2.782559e+00 train accuracy: 0.653333\n",
      "lr 1.467799e-06 reg 2.154435e+01 train accuracy: 0.573333\n",
      "lr 1.467799e-06 reg 1.668101e+02 train accuracy: 0.720000\n",
      "lr 1.467799e-06 reg 1.291550e+03 train accuracy: 0.693333\n",
      "lr 1.467799e-06 reg 1.000000e+04 train accuracy: 0.653333\n",
      "lr 2.154435e-06 reg 1.000000e-04 train accuracy: 0.506667\n",
      "lr 2.154435e-06 reg 7.742637e-04 train accuracy: 0.466667\n",
      "lr 2.154435e-06 reg 5.994843e-03 train accuracy: 0.653333\n",
      "lr 2.154435e-06 reg 4.641589e-02 train accuracy: 0.480000\n",
      "lr 2.154435e-06 reg 3.593814e-01 train accuracy: 0.226667\n",
      "lr 2.154435e-06 reg 2.782559e+00 train accuracy: 0.640000\n",
      "lr 2.154435e-06 reg 2.154435e+01 train accuracy: 0.640000\n",
      "lr 2.154435e-06 reg 1.668101e+02 train accuracy: 0.413333\n",
      "lr 2.154435e-06 reg 1.291550e+03 train accuracy: 0.653333\n",
      "lr 2.154435e-06 reg 1.000000e+04 train accuracy: 0.653333\n",
      "lr 3.162278e-06 reg 1.000000e-04 train accuracy: 0.733333\n",
      "lr 3.162278e-06 reg 7.742637e-04 train accuracy: 0.520000\n",
      "lr 3.162278e-06 reg 5.994843e-03 train accuracy: 0.453333\n",
      "lr 3.162278e-06 reg 4.641589e-02 train accuracy: 0.626667\n",
      "lr 3.162278e-06 reg 3.593814e-01 train accuracy: 0.600000\n",
      "lr 3.162278e-06 reg 2.782559e+00 train accuracy: 0.386667\n",
      "lr 3.162278e-06 reg 2.154435e+01 train accuracy: 0.440000\n",
      "lr 3.162278e-06 reg 1.668101e+02 train accuracy: 0.666667\n",
      "lr 3.162278e-06 reg 1.291550e+03 train accuracy: 0.653333\n",
      "lr 3.162278e-06 reg 1.000000e+04 train accuracy: 0.653333\n",
      "lr 4.641589e-06 reg 1.000000e-04 train accuracy: 0.653333\n",
      "lr 4.641589e-06 reg 7.742637e-04 train accuracy: 0.746667\n",
      "lr 4.641589e-06 reg 5.994843e-03 train accuracy: 0.546667\n",
      "lr 4.641589e-06 reg 4.641589e-02 train accuracy: 0.666667\n",
      "lr 4.641589e-06 reg 3.593814e-01 train accuracy: 0.706667\n",
      "lr 4.641589e-06 reg 2.782559e+00 train accuracy: 0.506667\n",
      "lr 4.641589e-06 reg 2.154435e+01 train accuracy: 0.666667\n",
      "lr 4.641589e-06 reg 1.668101e+02 train accuracy: 0.653333\n",
      "lr 4.641589e-06 reg 1.291550e+03 train accuracy: 0.653333\n",
      "lr 4.641589e-06 reg 1.000000e+04 train accuracy: 0.653333\n",
      "lr 6.812921e-06 reg 1.000000e-04 train accuracy: 0.653333\n",
      "lr 6.812921e-06 reg 7.742637e-04 train accuracy: 0.653333\n",
      "lr 6.812921e-06 reg 5.994843e-03 train accuracy: 0.653333\n",
      "lr 6.812921e-06 reg 4.641589e-02 train accuracy: 0.653333\n",
      "lr 6.812921e-06 reg 3.593814e-01 train accuracy: 0.826667\n",
      "lr 6.812921e-06 reg 2.782559e+00 train accuracy: 0.640000\n",
      "lr 6.812921e-06 reg 2.154435e+01 train accuracy: 0.680000\n",
      "lr 6.812921e-06 reg 1.668101e+02 train accuracy: 0.706667\n",
      "lr 6.812921e-06 reg 1.291550e+03 train accuracy: 0.653333\n",
      "lr 6.812921e-06 reg 1.000000e+04 train accuracy: 0.666667\n",
      "lr 1.000000e-05 reg 1.000000e-04 train accuracy: 0.706667\n",
      "lr 1.000000e-05 reg 7.742637e-04 train accuracy: 0.760000\n",
      "lr 1.000000e-05 reg 5.994843e-03 train accuracy: 0.666667\n",
      "lr 1.000000e-05 reg 4.641589e-02 train accuracy: 0.733333\n",
      "lr 1.000000e-05 reg 3.593814e-01 train accuracy: 0.680000\n",
      "lr 1.000000e-05 reg 2.782559e+00 train accuracy: 0.746667\n",
      "lr 1.000000e-05 reg 2.154435e+01 train accuracy: 0.653333\n",
      "lr 1.000000e-05 reg 1.668101e+02 train accuracy: 0.653333\n",
      "lr 1.000000e-05 reg 1.291550e+03 train accuracy: 0.666667\n",
      "lr 1.000000e-05 reg 1.000000e+04 train accuracy: 0.653333\n",
      "lr 1.467799e-05 reg 1.000000e-04 train accuracy: 0.706667\n",
      "lr 1.467799e-05 reg 7.742637e-04 train accuracy: 0.693333\n",
      "lr 1.467799e-05 reg 5.994843e-03 train accuracy: 0.680000\n",
      "lr 1.467799e-05 reg 4.641589e-02 train accuracy: 0.653333\n",
      "lr 1.467799e-05 reg 3.593814e-01 train accuracy: 0.693333\n",
      "lr 1.467799e-05 reg 2.782559e+00 train accuracy: 0.693333\n",
      "lr 1.467799e-05 reg 2.154435e+01 train accuracy: 0.653333\n",
      "lr 1.467799e-05 reg 1.668101e+02 train accuracy: 0.653333\n",
      "lr 1.467799e-05 reg 1.291550e+03 train accuracy: 0.653333\n",
      "lr 1.467799e-05 reg 1.000000e+04 train accuracy: 0.653333\n",
      "lr 2.154435e-05 reg 1.000000e-04 train accuracy: 0.653333\n",
      "lr 2.154435e-05 reg 7.742637e-04 train accuracy: 0.680000\n",
      "lr 2.154435e-05 reg 5.994843e-03 train accuracy: 0.693333\n",
      "lr 2.154435e-05 reg 4.641589e-02 train accuracy: 0.666667\n",
      "lr 2.154435e-05 reg 3.593814e-01 train accuracy: 0.653333\n",
      "lr 2.154435e-05 reg 2.782559e+00 train accuracy: 0.666667\n",
      "lr 2.154435e-05 reg 2.154435e+01 train accuracy: 0.666667\n",
      "lr 2.154435e-05 reg 1.668101e+02 train accuracy: 0.653333\n",
      "lr 2.154435e-05 reg 1.291550e+03 train accuracy: 0.653333\n",
      "lr 2.154435e-05 reg 1.000000e+04 train accuracy: 0.680000\n",
      "lr 3.162278e-05 reg 1.000000e-04 train accuracy: 0.653333\n",
      "lr 3.162278e-05 reg 7.742637e-04 train accuracy: 0.666667\n",
      "lr 3.162278e-05 reg 5.994843e-03 train accuracy: 0.653333\n",
      "lr 3.162278e-05 reg 4.641589e-02 train accuracy: 0.653333\n",
      "lr 3.162278e-05 reg 3.593814e-01 train accuracy: 0.653333\n",
      "lr 3.162278e-05 reg 2.782559e+00 train accuracy: 0.653333\n",
      "lr 3.162278e-05 reg 2.154435e+01 train accuracy: 0.666667\n",
      "lr 3.162278e-05 reg 1.668101e+02 train accuracy: 0.653333\n",
      "lr 3.162278e-05 reg 1.291550e+03 train accuracy: 0.653333\n",
      "lr 3.162278e-05 reg 1.000000e+04 train accuracy: 0.653333\n",
      "best training accuracy achieved: 0.826667\n"
     ]
    }
   ],
   "source": [
    "'''我一开始是用交叉熵损失来训练，效果不好 81.33% 对应61/75'''\n",
    "from cs231n.classifiers.softmax import softmax_loss_vectorized\n",
    "from cs231n.classifiers import Softmax\n",
    "results = {}\n",
    "best_acc = -1\n",
    "best_softmax = None\n",
    "\n",
    "num_tune = 10\n",
    "lr_tune=np.logspace(-6,-4.5,num_tune)\n",
    "reg_tune=np.logspace(-4,4,num_tune)\n",
    "np.random.shuffle(reg_tune)\n",
    "tune=[]\n",
    "for lr in lr_tune:\n",
    "    for reg in reg_tune:\n",
    "        tune.append((lr,reg))\n",
    "for lr,reg in tune:\n",
    "    softmax = Softmax()\n",
    "    loss_hist = softmax.train(x_train, y_train, learning_rate=lr, reg=reg,\n",
    "                              num_iters=1000, verbose=True)\n",
    "    y_train_pred = softmax.predict(x_train)\n",
    "    train_acc=np.mean(y_train == y_train_pred)\n",
    "    results[(lr,reg)]=train_acc\n",
    "    if train_acc>best_acc:\n",
    "        best_acc=train_acc\n",
    "        best_softmax=softmax\n",
    "################################################################################\n",
    "#                              END OF YOUR CODE                                #\n",
    "################################################################################\n",
    "    \n",
    "# Print out results.\n",
    "for lr, reg in sorted(results):\n",
    "    train_accuracy = results[(lr, reg)]\n",
    "    print('lr %e reg %e train accuracy: %f' % (\n",
    "                lr, reg, train_accuracy))\n",
    "    \n",
    "print('best training accuracy achieved: %f' % best_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration 0 / 3000: loss 1.999847\n",
      "iteration 100 / 3000: loss 1.848978\n",
      "iteration 200 / 3000: loss 1.741000\n",
      "iteration 300 / 3000: loss 1.615218\n",
      "iteration 400 / 3000: loss 1.460256\n",
      "iteration 500 / 3000: loss 1.260956\n",
      "iteration 600 / 3000: loss 1.194274\n",
      "iteration 700 / 3000: loss 1.206058\n",
      "iteration 800 / 3000: loss 1.177714\n",
      "iteration 900 / 3000: loss 1.053712\n",
      "iteration 1000 / 3000: loss 1.057704\n",
      "iteration 1100 / 3000: loss 1.077219\n",
      "iteration 1200 / 3000: loss 0.908143\n",
      "iteration 1300 / 3000: loss 1.004012\n",
      "iteration 1400 / 3000: loss 0.920516\n",
      "iteration 1500 / 3000: loss 0.973675\n",
      "iteration 1600 / 3000: loss 0.959617\n",
      "iteration 1700 / 3000: loss 0.830526\n",
      "iteration 1800 / 3000: loss 0.960347\n",
      "iteration 1900 / 3000: loss 1.008980\n",
      "iteration 2000 / 3000: loss 0.907089\n",
      "iteration 2100 / 3000: loss 0.882457\n",
      "iteration 2200 / 3000: loss 0.922509\n",
      "iteration 2300 / 3000: loss 0.911734\n",
      "iteration 2400 / 3000: loss 0.836767\n",
      "iteration 2500 / 3000: loss 0.919676\n",
      "iteration 2600 / 3000: loss 0.880035\n",
      "iteration 2700 / 3000: loss 0.874989\n",
      "iteration 2800 / 3000: loss 0.771352\n",
      "iteration 2900 / 3000: loss 0.864589\n",
      "iteration 0 / 3000: loss 1.995652\n",
      "iteration 100 / 3000: loss 1.923627\n",
      "iteration 200 / 3000: loss 1.895516\n",
      "iteration 300 / 3000: loss 1.898723\n",
      "iteration 400 / 3000: loss 1.885843\n",
      "iteration 500 / 3000: loss 1.909920\n",
      "iteration 600 / 3000: loss 1.913662\n",
      "iteration 700 / 3000: loss 1.874505\n",
      "iteration 800 / 3000: loss 1.916261\n",
      "iteration 900 / 3000: loss 1.879946\n",
      "iteration 1000 / 3000: loss 1.896764\n",
      "iteration 1100 / 3000: loss 1.876843\n",
      "iteration 1200 / 3000: loss 1.879759\n",
      "iteration 1300 / 3000: loss 1.918970\n",
      "iteration 1400 / 3000: loss 1.882462\n",
      "iteration 1500 / 3000: loss 1.897858\n",
      "iteration 1600 / 3000: loss 1.876191\n",
      "iteration 1700 / 3000: loss 1.892406\n",
      "iteration 1800 / 3000: loss 1.872622\n",
      "iteration 1900 / 3000: loss 1.899011\n",
      "iteration 2000 / 3000: loss 1.891516\n",
      "iteration 2100 / 3000: loss 1.884369\n",
      "iteration 2200 / 3000: loss 1.889056\n",
      "iteration 2300 / 3000: loss 1.883210\n",
      "iteration 2400 / 3000: loss 1.888197\n",
      "iteration 2500 / 3000: loss 1.876627\n",
      "iteration 2600 / 3000: loss 1.886353\n",
      "iteration 2700 / 3000: loss 1.907824\n",
      "iteration 2800 / 3000: loss 1.879848\n",
      "iteration 2900 / 3000: loss 1.895590\n",
      "iteration 0 / 3000: loss 2.002711\n",
      "iteration 100 / 3000: loss 1.854612\n",
      "iteration 200 / 3000: loss 1.734770\n",
      "iteration 300 / 3000: loss 1.609447\n",
      "iteration 400 / 3000: loss 1.407739\n",
      "iteration 500 / 3000: loss 1.326205\n",
      "iteration 600 / 3000: loss 1.186082\n",
      "iteration 700 / 3000: loss 1.152663\n",
      "iteration 800 / 3000: loss 1.212795\n",
      "iteration 900 / 3000: loss 1.116103\n",
      "iteration 1000 / 3000: loss 1.032803\n",
      "iteration 1100 / 3000: loss 1.018857\n",
      "iteration 1200 / 3000: loss 0.951434\n",
      "iteration 1300 / 3000: loss 0.916778\n",
      "iteration 1400 / 3000: loss 0.972339\n",
      "iteration 1500 / 3000: loss 0.937294\n",
      "iteration 1600 / 3000: loss 0.926799\n",
      "iteration 1700 / 3000: loss 1.022012\n",
      "iteration 1800 / 3000: loss 0.793089\n",
      "iteration 1900 / 3000: loss 0.819489\n",
      "iteration 2000 / 3000: loss 0.943713\n",
      "iteration 2100 / 3000: loss 0.846592\n",
      "iteration 2200 / 3000: loss 0.864382\n",
      "iteration 2300 / 3000: loss 0.863931\n",
      "iteration 2400 / 3000: loss 0.777352\n",
      "iteration 2500 / 3000: loss 0.862431\n",
      "iteration 2600 / 3000: loss 0.829772\n",
      "iteration 2700 / 3000: loss 0.737958\n",
      "iteration 2800 / 3000: loss 0.802336\n",
      "iteration 2900 / 3000: loss 0.820816\n",
      "iteration 0 / 3000: loss 1.999908\n",
      "iteration 100 / 3000: loss 1.862178\n",
      "iteration 200 / 3000: loss 1.731310\n",
      "iteration 300 / 3000: loss 1.609023\n",
      "iteration 400 / 3000: loss 1.520488\n",
      "iteration 500 / 3000: loss 1.291356\n",
      "iteration 600 / 3000: loss 1.158230\n",
      "iteration 700 / 3000: loss 1.185110\n",
      "iteration 800 / 3000: loss 1.206261\n",
      "iteration 900 / 3000: loss 1.101265\n",
      "iteration 1000 / 3000: loss 1.045474\n",
      "iteration 1100 / 3000: loss 0.920723\n",
      "iteration 1200 / 3000: loss 0.938389\n",
      "iteration 1300 / 3000: loss 0.976661\n",
      "iteration 1400 / 3000: loss 0.874622\n",
      "iteration 1500 / 3000: loss 0.951031\n",
      "iteration 1600 / 3000: loss 0.966204\n",
      "iteration 1700 / 3000: loss 0.930673\n",
      "iteration 1800 / 3000: loss 0.910673\n",
      "iteration 1900 / 3000: loss 0.794475\n",
      "iteration 2000 / 3000: loss 0.812511\n",
      "iteration 2100 / 3000: loss 0.888806\n",
      "iteration 2200 / 3000: loss 0.906915\n",
      "iteration 2300 / 3000: loss 0.890893\n",
      "iteration 2400 / 3000: loss 0.814942\n",
      "iteration 2500 / 3000: loss 0.848465\n",
      "iteration 2600 / 3000: loss 0.788208\n",
      "iteration 2700 / 3000: loss 0.782288\n",
      "iteration 2800 / 3000: loss 0.727028\n",
      "iteration 2900 / 3000: loss 0.688132\n",
      "iteration 0 / 3000: loss 1.998308\n",
      "iteration 100 / 3000: loss 1.857690\n",
      "iteration 200 / 3000: loss 1.729717\n",
      "iteration 300 / 3000: loss 1.590265\n",
      "iteration 400 / 3000: loss 1.453816\n",
      "iteration 500 / 3000: loss 1.312705\n",
      "iteration 600 / 3000: loss 1.081019\n",
      "iteration 700 / 3000: loss 1.102023\n",
      "iteration 800 / 3000: loss 1.020802\n",
      "iteration 900 / 3000: loss 1.110979\n",
      "iteration 1000 / 3000: loss 1.014880\n",
      "iteration 1100 / 3000: loss 1.090739\n",
      "iteration 1200 / 3000: loss 0.982561\n",
      "iteration 1300 / 3000: loss 1.017952\n",
      "iteration 1400 / 3000: loss 0.956266\n",
      "iteration 1500 / 3000: loss 0.898871\n",
      "iteration 1600 / 3000: loss 1.034423\n",
      "iteration 1700 / 3000: loss 0.809621\n",
      "iteration 1800 / 3000: loss 0.932639\n",
      "iteration 1900 / 3000: loss 0.823118\n",
      "iteration 2000 / 3000: loss 0.867056\n",
      "iteration 2100 / 3000: loss 0.941711\n",
      "iteration 2200 / 3000: loss 0.874270\n",
      "iteration 2300 / 3000: loss 0.873333\n",
      "iteration 2400 / 3000: loss 0.861648\n",
      "iteration 2500 / 3000: loss 0.765544\n",
      "iteration 2600 / 3000: loss 0.846841\n",
      "iteration 2700 / 3000: loss 0.842403\n",
      "iteration 2800 / 3000: loss 0.771552\n",
      "iteration 2900 / 3000: loss 0.852178\n",
      "iteration 0 / 3000: loss 2.002051\n",
      "iteration 100 / 3000: loss 1.880116\n",
      "iteration 200 / 3000: loss 1.734577\n",
      "iteration 300 / 3000: loss 1.596238\n",
      "iteration 400 / 3000: loss 1.474134\n",
      "iteration 500 / 3000: loss 1.313235\n",
      "iteration 600 / 3000: loss 1.295843\n",
      "iteration 700 / 3000: loss 1.171335\n",
      "iteration 800 / 3000: loss 1.151644\n",
      "iteration 900 / 3000: loss 1.196330\n",
      "iteration 1000 / 3000: loss 1.138262\n",
      "iteration 1100 / 3000: loss 1.078556\n",
      "iteration 1200 / 3000: loss 1.104272\n",
      "iteration 1300 / 3000: loss 1.028316\n",
      "iteration 1400 / 3000: loss 1.098150\n",
      "iteration 1500 / 3000: loss 1.006140\n",
      "iteration 1600 / 3000: loss 1.005978\n",
      "iteration 1700 / 3000: loss 1.100963\n",
      "iteration 1800 / 3000: loss 0.945497\n",
      "iteration 1900 / 3000: loss 0.947492\n",
      "iteration 2000 / 3000: loss 1.170700\n",
      "iteration 2100 / 3000: loss 0.954935\n",
      "iteration 2200 / 3000: loss 1.037153\n",
      "iteration 2300 / 3000: loss 1.017186\n",
      "iteration 2400 / 3000: loss 0.998158\n",
      "iteration 2500 / 3000: loss 1.056271\n",
      "iteration 2600 / 3000: loss 0.951972\n",
      "iteration 2700 / 3000: loss 0.972225\n",
      "iteration 2800 / 3000: loss 0.938834\n",
      "iteration 2900 / 3000: loss 0.995542\n",
      "iteration 0 / 3000: loss 2.005045\n",
      "iteration 100 / 3000: loss 1.860702\n",
      "iteration 200 / 3000: loss 1.743971\n",
      "iteration 300 / 3000: loss 1.589783\n",
      "iteration 400 / 3000: loss 1.381403\n",
      "iteration 500 / 3000: loss 1.382099\n",
      "iteration 600 / 3000: loss 1.290890\n",
      "iteration 700 / 3000: loss 1.152545\n",
      "iteration 800 / 3000: loss 1.149391\n",
      "iteration 900 / 3000: loss 1.072465\n",
      "iteration 1000 / 3000: loss 1.036066\n",
      "iteration 1100 / 3000: loss 1.120997\n",
      "iteration 1200 / 3000: loss 0.911983\n",
      "iteration 1300 / 3000: loss 0.945096\n",
      "iteration 1400 / 3000: loss 0.921051\n",
      "iteration 1500 / 3000: loss 1.039854\n",
      "iteration 1600 / 3000: loss 0.856198\n",
      "iteration 1700 / 3000: loss 0.880768\n",
      "iteration 1800 / 3000: loss 0.921253\n",
      "iteration 1900 / 3000: loss 0.927917\n",
      "iteration 2000 / 3000: loss 0.883862\n",
      "iteration 2100 / 3000: loss 0.856350\n",
      "iteration 2200 / 3000: loss 0.873792\n",
      "iteration 2300 / 3000: loss 0.784082\n",
      "iteration 2400 / 3000: loss 0.772548\n",
      "iteration 2500 / 3000: loss 0.812637\n",
      "iteration 2600 / 3000: loss 0.855031\n",
      "iteration 2700 / 3000: loss 0.850753\n",
      "iteration 2800 / 3000: loss 0.849282\n",
      "iteration 2900 / 3000: loss 0.854535\n",
      "iteration 0 / 3000: loss 1.993909\n",
      "iteration 100 / 3000: loss 1.880439\n",
      "iteration 200 / 3000: loss 1.743757\n",
      "iteration 300 / 3000: loss 1.569178\n",
      "iteration 400 / 3000: loss 1.438582\n",
      "iteration 500 / 3000: loss 1.275259\n",
      "iteration 600 / 3000: loss 1.187638\n",
      "iteration 700 / 3000: loss 1.134566\n",
      "iteration 800 / 3000: loss 1.147513\n",
      "iteration 900 / 3000: loss 1.105428\n",
      "iteration 1000 / 3000: loss 0.962742\n",
      "iteration 1100 / 3000: loss 1.059894\n",
      "iteration 1200 / 3000: loss 0.956516\n",
      "iteration 1300 / 3000: loss 0.926324\n",
      "iteration 1400 / 3000: loss 0.920304\n",
      "iteration 1500 / 3000: loss 0.929106\n",
      "iteration 1600 / 3000: loss 0.921839\n",
      "iteration 1700 / 3000: loss 0.975788\n",
      "iteration 1800 / 3000: loss 0.972569\n",
      "iteration 1900 / 3000: loss 0.908003\n",
      "iteration 2000 / 3000: loss 0.798813\n",
      "iteration 2100 / 3000: loss 0.853575\n",
      "iteration 2200 / 3000: loss 0.776442\n",
      "iteration 2300 / 3000: loss 0.893516\n",
      "iteration 2400 / 3000: loss 0.897006\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration 2500 / 3000: loss 0.796643\n",
      "iteration 2600 / 3000: loss 0.874450\n",
      "iteration 2700 / 3000: loss 0.805793\n",
      "iteration 2800 / 3000: loss 0.842484\n",
      "iteration 2900 / 3000: loss 0.810236\n",
      "iteration 0 / 3000: loss 1.997831\n",
      "iteration 100 / 3000: loss 1.855658\n",
      "iteration 200 / 3000: loss 1.747683\n",
      "iteration 300 / 3000: loss 1.658759\n",
      "iteration 400 / 3000: loss 1.585545\n",
      "iteration 500 / 3000: loss 1.485200\n",
      "iteration 600 / 3000: loss 1.398788\n",
      "iteration 700 / 3000: loss 1.302145\n",
      "iteration 800 / 3000: loss 1.270409\n",
      "iteration 900 / 3000: loss 1.255160\n",
      "iteration 1000 / 3000: loss 1.291536\n",
      "iteration 1100 / 3000: loss 1.326216\n",
      "iteration 1200 / 3000: loss 1.238189\n",
      "iteration 1300 / 3000: loss 1.345112\n",
      "iteration 1400 / 3000: loss 1.214089\n",
      "iteration 1500 / 3000: loss 1.194169\n",
      "iteration 1600 / 3000: loss 1.279610\n",
      "iteration 1700 / 3000: loss 1.263898\n",
      "iteration 1800 / 3000: loss 1.288992\n",
      "iteration 1900 / 3000: loss 1.236103\n",
      "iteration 2000 / 3000: loss 1.258642\n",
      "iteration 2100 / 3000: loss 1.320852\n",
      "iteration 2200 / 3000: loss 1.300971\n",
      "iteration 2300 / 3000: loss 1.213173\n",
      "iteration 2400 / 3000: loss 1.231673\n",
      "iteration 2500 / 3000: loss 1.185092\n",
      "iteration 2600 / 3000: loss 1.260004\n",
      "iteration 2700 / 3000: loss 1.258810\n",
      "iteration 2800 / 3000: loss 1.196739\n",
      "iteration 2900 / 3000: loss 1.310827\n",
      "iteration 0 / 3000: loss 1.999114\n",
      "iteration 100 / 3000: loss 1.890838\n",
      "iteration 200 / 3000: loss 1.806576\n",
      "iteration 300 / 3000: loss 1.764940\n",
      "iteration 400 / 3000: loss 1.706547\n",
      "iteration 500 / 3000: loss 1.688523\n",
      "iteration 600 / 3000: loss 1.655031\n",
      "iteration 700 / 3000: loss 1.651420\n",
      "iteration 800 / 3000: loss 1.642407\n",
      "iteration 900 / 3000: loss 1.674498\n",
      "iteration 1000 / 3000: loss 1.625092\n",
      "iteration 1100 / 3000: loss 1.646465\n",
      "iteration 1200 / 3000: loss 1.634037\n",
      "iteration 1300 / 3000: loss 1.654206\n",
      "iteration 1400 / 3000: loss 1.639828\n",
      "iteration 1500 / 3000: loss 1.635732\n",
      "iteration 1600 / 3000: loss 1.556653\n",
      "iteration 1700 / 3000: loss 1.590971\n",
      "iteration 1800 / 3000: loss 1.586965\n",
      "iteration 1900 / 3000: loss 1.662269\n",
      "iteration 2000 / 3000: loss 1.656284\n",
      "iteration 2100 / 3000: loss 1.579168\n",
      "iteration 2200 / 3000: loss 1.573404\n",
      "iteration 2300 / 3000: loss 1.600031\n",
      "iteration 2400 / 3000: loss 1.602083\n",
      "iteration 2500 / 3000: loss 1.622285\n",
      "iteration 2600 / 3000: loss 1.659704\n",
      "iteration 2700 / 3000: loss 1.593207\n",
      "iteration 2800 / 3000: loss 1.543789\n",
      "iteration 2900 / 3000: loss 1.574109\n",
      "iteration 0 / 3000: loss 1.999492\n",
      "iteration 100 / 3000: loss 1.573446\n",
      "iteration 200 / 3000: loss 1.190368\n",
      "iteration 300 / 3000: loss 1.109280\n",
      "iteration 400 / 3000: loss 1.032409\n",
      "iteration 500 / 3000: loss 0.999515\n",
      "iteration 600 / 3000: loss 0.894813\n",
      "iteration 700 / 3000: loss 0.870603\n",
      "iteration 800 / 3000: loss 0.869784\n",
      "iteration 900 / 3000: loss 0.912305\n",
      "iteration 1000 / 3000: loss 0.877209\n",
      "iteration 1100 / 3000: loss 0.764883\n",
      "iteration 1200 / 3000: loss 0.827707\n",
      "iteration 1300 / 3000: loss 0.829965\n",
      "iteration 1400 / 3000: loss 0.810062\n",
      "iteration 1500 / 3000: loss 0.781540\n",
      "iteration 1600 / 3000: loss 0.709433\n",
      "iteration 1700 / 3000: loss 0.739720\n",
      "iteration 1800 / 3000: loss 0.651571\n",
      "iteration 1900 / 3000: loss 0.687470\n",
      "iteration 2000 / 3000: loss 0.645996\n",
      "iteration 2100 / 3000: loss 0.724930\n",
      "iteration 2200 / 3000: loss 0.698841\n",
      "iteration 2300 / 3000: loss 0.615392\n",
      "iteration 2400 / 3000: loss 0.669001\n",
      "iteration 2500 / 3000: loss 0.674738\n",
      "iteration 2600 / 3000: loss 0.697952\n",
      "iteration 2700 / 3000: loss 0.653780\n",
      "iteration 2800 / 3000: loss 0.665063\n",
      "iteration 2900 / 3000: loss 0.628008\n",
      "iteration 0 / 3000: loss 2.002628\n",
      "iteration 100 / 3000: loss 1.890216\n",
      "iteration 200 / 3000: loss 1.887824\n",
      "iteration 300 / 3000: loss 1.903536\n",
      "iteration 400 / 3000: loss 1.897671\n",
      "iteration 500 / 3000: loss 1.894824\n",
      "iteration 600 / 3000: loss 1.892686\n",
      "iteration 700 / 3000: loss 1.869489\n",
      "iteration 800 / 3000: loss 1.895455\n",
      "iteration 900 / 3000: loss 1.891127\n",
      "iteration 1000 / 3000: loss 1.873855\n",
      "iteration 1100 / 3000: loss 1.879353\n",
      "iteration 1200 / 3000: loss 1.892122\n",
      "iteration 1300 / 3000: loss 1.901720\n",
      "iteration 1400 / 3000: loss 1.877967\n",
      "iteration 1500 / 3000: loss 1.888644\n",
      "iteration 1600 / 3000: loss 1.882294\n",
      "iteration 1700 / 3000: loss 1.898131\n",
      "iteration 1800 / 3000: loss 1.899435\n",
      "iteration 1900 / 3000: loss 1.885497\n",
      "iteration 2000 / 3000: loss 1.902255\n",
      "iteration 2100 / 3000: loss 1.901185\n",
      "iteration 2200 / 3000: loss 1.912934\n",
      "iteration 2300 / 3000: loss 1.870956\n",
      "iteration 2400 / 3000: loss 1.890995\n",
      "iteration 2500 / 3000: loss 1.903240\n",
      "iteration 2600 / 3000: loss 1.857693\n",
      "iteration 2700 / 3000: loss 1.901266\n",
      "iteration 2800 / 3000: loss 1.870469\n",
      "iteration 2900 / 3000: loss 1.904378\n",
      "iteration 0 / 3000: loss 1.998823\n",
      "iteration 100 / 3000: loss 1.583540\n",
      "iteration 200 / 3000: loss 1.233751\n",
      "iteration 300 / 3000: loss 1.148051\n",
      "iteration 400 / 3000: loss 1.001590\n",
      "iteration 500 / 3000: loss 0.854739\n",
      "iteration 600 / 3000: loss 0.911371\n",
      "iteration 700 / 3000: loss 0.897062\n",
      "iteration 800 / 3000: loss 0.886104\n",
      "iteration 900 / 3000: loss 0.775770\n",
      "iteration 1000 / 3000: loss 0.728064\n",
      "iteration 1100 / 3000: loss 0.760085\n",
      "iteration 1200 / 3000: loss 0.785118\n",
      "iteration 1300 / 3000: loss 0.654940\n",
      "iteration 1400 / 3000: loss 0.695226\n",
      "iteration 1500 / 3000: loss 0.700235\n",
      "iteration 1600 / 3000: loss 0.688270\n",
      "iteration 1700 / 3000: loss 0.644314\n",
      "iteration 1800 / 3000: loss 0.544668\n",
      "iteration 1900 / 3000: loss 0.631937\n",
      "iteration 2000 / 3000: loss 0.611852\n",
      "iteration 2100 / 3000: loss 0.602421\n",
      "iteration 2200 / 3000: loss 0.525920\n",
      "iteration 2300 / 3000: loss 0.563967\n",
      "iteration 2400 / 3000: loss 0.497617\n",
      "iteration 2500 / 3000: loss 0.508490\n",
      "iteration 2600 / 3000: loss 0.496788\n",
      "iteration 2700 / 3000: loss 0.526730\n",
      "iteration 2800 / 3000: loss 0.513691\n",
      "iteration 2900 / 3000: loss 0.574613\n",
      "iteration 0 / 3000: loss 2.001097\n",
      "iteration 100 / 3000: loss 1.577934\n",
      "iteration 200 / 3000: loss 1.198114\n",
      "iteration 300 / 3000: loss 1.073750\n",
      "iteration 400 / 3000: loss 0.970159\n",
      "iteration 500 / 3000: loss 0.889777\n",
      "iteration 600 / 3000: loss 0.937145\n",
      "iteration 700 / 3000: loss 0.802756\n",
      "iteration 800 / 3000: loss 0.775590\n",
      "iteration 900 / 3000: loss 0.718359\n",
      "iteration 1000 / 3000: loss 0.728256\n",
      "iteration 1100 / 3000: loss 0.744757\n",
      "iteration 1200 / 3000: loss 0.635163\n",
      "iteration 1300 / 3000: loss 0.689290\n",
      "iteration 1400 / 3000: loss 0.662004\n",
      "iteration 1500 / 3000: loss 0.646909\n",
      "iteration 1600 / 3000: loss 0.611715\n",
      "iteration 1700 / 3000: loss 0.582715\n",
      "iteration 1800 / 3000: loss 0.630628\n",
      "iteration 1900 / 3000: loss 0.589780\n",
      "iteration 2000 / 3000: loss 0.537644\n",
      "iteration 2100 / 3000: loss 0.557643\n",
      "iteration 2200 / 3000: loss 0.608021\n",
      "iteration 2300 / 3000: loss 0.566358\n",
      "iteration 2400 / 3000: loss 0.541842\n",
      "iteration 2500 / 3000: loss 0.530406\n",
      "iteration 2600 / 3000: loss 0.536620\n",
      "iteration 2700 / 3000: loss 0.552937\n",
      "iteration 2800 / 3000: loss 0.597775\n",
      "iteration 2900 / 3000: loss 0.580136\n",
      "iteration 0 / 3000: loss 1.999705\n",
      "iteration 100 / 3000: loss 1.531499\n",
      "iteration 200 / 3000: loss 1.182258\n",
      "iteration 300 / 3000: loss 1.024459\n",
      "iteration 400 / 3000: loss 0.870774\n",
      "iteration 500 / 3000: loss 0.964201\n",
      "iteration 600 / 3000: loss 0.719314\n",
      "iteration 700 / 3000: loss 0.794046\n",
      "iteration 800 / 3000: loss 0.781609\n",
      "iteration 900 / 3000: loss 0.788808\n",
      "iteration 1000 / 3000: loss 0.815805\n",
      "iteration 1100 / 3000: loss 0.790610\n",
      "iteration 1200 / 3000: loss 0.804747\n",
      "iteration 1300 / 3000: loss 0.747344\n",
      "iteration 1400 / 3000: loss 0.759889\n",
      "iteration 1500 / 3000: loss 0.710191\n",
      "iteration 1600 / 3000: loss 0.596874\n",
      "iteration 1700 / 3000: loss 0.766744\n",
      "iteration 1800 / 3000: loss 0.619283\n",
      "iteration 1900 / 3000: loss 0.738378\n",
      "iteration 2000 / 3000: loss 0.661663\n",
      "iteration 2100 / 3000: loss 0.620140\n",
      "iteration 2200 / 3000: loss 0.652273\n",
      "iteration 2300 / 3000: loss 0.632388\n",
      "iteration 2400 / 3000: loss 0.524907\n",
      "iteration 2500 / 3000: loss 0.585714\n",
      "iteration 2600 / 3000: loss 0.588052\n",
      "iteration 2700 / 3000: loss 0.570689\n",
      "iteration 2800 / 3000: loss 0.573941\n",
      "iteration 2900 / 3000: loss 0.576926\n",
      "iteration 0 / 3000: loss 1.999681\n",
      "iteration 100 / 3000: loss 1.568026\n",
      "iteration 200 / 3000: loss 1.281675\n",
      "iteration 300 / 3000: loss 1.118524\n",
      "iteration 400 / 3000: loss 1.143214\n",
      "iteration 500 / 3000: loss 1.024219\n",
      "iteration 600 / 3000: loss 1.010362\n",
      "iteration 700 / 3000: loss 0.987667\n",
      "iteration 800 / 3000: loss 0.992981\n",
      "iteration 900 / 3000: loss 1.013658\n",
      "iteration 1000 / 3000: loss 1.000083\n",
      "iteration 1100 / 3000: loss 0.966711\n",
      "iteration 1200 / 3000: loss 1.003627\n",
      "iteration 1300 / 3000: loss 1.104889\n",
      "iteration 1400 / 3000: loss 0.848339\n",
      "iteration 1500 / 3000: loss 0.981761\n",
      "iteration 1600 / 3000: loss 0.912309\n",
      "iteration 1700 / 3000: loss 0.959482\n",
      "iteration 1800 / 3000: loss 0.947753\n",
      "iteration 1900 / 3000: loss 0.839052\n",
      "iteration 2000 / 3000: loss 0.984379\n",
      "iteration 2100 / 3000: loss 0.979432\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration 2200 / 3000: loss 0.976626\n",
      "iteration 2300 / 3000: loss 0.997318\n",
      "iteration 2400 / 3000: loss 1.007989\n",
      "iteration 2500 / 3000: loss 0.957201\n",
      "iteration 2600 / 3000: loss 0.944737\n",
      "iteration 2700 / 3000: loss 0.944626\n",
      "iteration 2800 / 3000: loss 0.892907\n",
      "iteration 2900 / 3000: loss 1.003302\n",
      "iteration 0 / 3000: loss 1.999468\n",
      "iteration 100 / 3000: loss 1.623316\n",
      "iteration 200 / 3000: loss 1.279029\n",
      "iteration 300 / 3000: loss 1.045217\n",
      "iteration 400 / 3000: loss 0.976458\n",
      "iteration 500 / 3000: loss 0.877032\n",
      "iteration 600 / 3000: loss 0.905183\n",
      "iteration 700 / 3000: loss 0.870261\n",
      "iteration 800 / 3000: loss 0.833855\n",
      "iteration 900 / 3000: loss 0.802085\n",
      "iteration 1000 / 3000: loss 0.667809\n",
      "iteration 1100 / 3000: loss 0.721018\n",
      "iteration 1200 / 3000: loss 0.768673\n",
      "iteration 1300 / 3000: loss 0.666914\n",
      "iteration 1400 / 3000: loss 0.782261\n",
      "iteration 1500 / 3000: loss 0.649320\n",
      "iteration 1600 / 3000: loss 0.675332\n",
      "iteration 1700 / 3000: loss 0.707975\n",
      "iteration 1800 / 3000: loss 0.598808\n",
      "iteration 1900 / 3000: loss 0.639740\n",
      "iteration 2000 / 3000: loss 0.519066\n",
      "iteration 2100 / 3000: loss 0.614578\n",
      "iteration 2200 / 3000: loss 0.545866\n",
      "iteration 2300 / 3000: loss 0.535169\n",
      "iteration 2400 / 3000: loss 0.587644\n",
      "iteration 2500 / 3000: loss 0.554781\n",
      "iteration 2600 / 3000: loss 0.518432\n",
      "iteration 2700 / 3000: loss 0.556418\n",
      "iteration 2800 / 3000: loss 0.567200\n",
      "iteration 2900 / 3000: loss 0.525762\n",
      "iteration 0 / 3000: loss 2.003142\n",
      "iteration 100 / 3000: loss 1.522784\n",
      "iteration 200 / 3000: loss 1.151676\n",
      "iteration 300 / 3000: loss 1.018028\n",
      "iteration 400 / 3000: loss 0.973785\n",
      "iteration 500 / 3000: loss 0.995413\n",
      "iteration 600 / 3000: loss 0.938413\n",
      "iteration 700 / 3000: loss 0.738930\n",
      "iteration 800 / 3000: loss 0.834544\n",
      "iteration 900 / 3000: loss 0.804911\n",
      "iteration 1000 / 3000: loss 0.754015\n",
      "iteration 1100 / 3000: loss 0.749182\n",
      "iteration 1200 / 3000: loss 0.764707\n",
      "iteration 1300 / 3000: loss 0.725201\n",
      "iteration 1400 / 3000: loss 0.685234\n",
      "iteration 1500 / 3000: loss 0.668109\n",
      "iteration 1600 / 3000: loss 0.622999\n",
      "iteration 1700 / 3000: loss 0.633912\n",
      "iteration 1800 / 3000: loss 0.563545\n",
      "iteration 1900 / 3000: loss 0.560549\n",
      "iteration 2000 / 3000: loss 0.557732\n",
      "iteration 2100 / 3000: loss 0.594549\n",
      "iteration 2200 / 3000: loss 0.534778\n",
      "iteration 2300 / 3000: loss 0.506143\n",
      "iteration 2400 / 3000: loss 0.526240\n",
      "iteration 2500 / 3000: loss 0.528360\n",
      "iteration 2600 / 3000: loss 0.512643\n",
      "iteration 2700 / 3000: loss 0.564636\n",
      "iteration 2800 / 3000: loss 0.568346\n",
      "iteration 2900 / 3000: loss 0.443449\n",
      "iteration 0 / 3000: loss 1.999011\n",
      "iteration 100 / 3000: loss 1.665616\n",
      "iteration 200 / 3000: loss 1.336043\n",
      "iteration 300 / 3000: loss 1.395020\n",
      "iteration 400 / 3000: loss 1.237252\n",
      "iteration 500 / 3000: loss 1.378980\n",
      "iteration 600 / 3000: loss 1.243180\n",
      "iteration 700 / 3000: loss 1.404750\n",
      "iteration 800 / 3000: loss 1.242745\n",
      "iteration 900 / 3000: loss 1.373493\n",
      "iteration 1000 / 3000: loss 1.260491\n",
      "iteration 1100 / 3000: loss 1.211460\n",
      "iteration 1200 / 3000: loss 1.345995\n",
      "iteration 1300 / 3000: loss 1.220768\n",
      "iteration 1400 / 3000: loss 1.271631\n",
      "iteration 1500 / 3000: loss 1.225427\n",
      "iteration 1600 / 3000: loss 1.202248\n",
      "iteration 1700 / 3000: loss 1.161139\n",
      "iteration 1800 / 3000: loss 1.250558\n",
      "iteration 1900 / 3000: loss 1.285100\n",
      "iteration 2000 / 3000: loss 1.234946\n",
      "iteration 2100 / 3000: loss 1.276998\n",
      "iteration 2200 / 3000: loss 1.355519\n",
      "iteration 2300 / 3000: loss 1.148415\n",
      "iteration 2400 / 3000: loss 1.229766\n",
      "iteration 2500 / 3000: loss 1.248525\n",
      "iteration 2600 / 3000: loss 1.241733\n",
      "iteration 2700 / 3000: loss 1.217559\n",
      "iteration 2800 / 3000: loss 1.232187\n",
      "iteration 2900 / 3000: loss 1.219376\n",
      "iteration 0 / 3000: loss 1.999415\n",
      "iteration 100 / 3000: loss 1.737945\n",
      "iteration 200 / 3000: loss 1.674671\n",
      "iteration 300 / 3000: loss 1.614272\n",
      "iteration 400 / 3000: loss 1.611763\n",
      "iteration 500 / 3000: loss 1.587962\n",
      "iteration 600 / 3000: loss 1.614560\n",
      "iteration 700 / 3000: loss 1.652059\n",
      "iteration 800 / 3000: loss 1.733908\n",
      "iteration 900 / 3000: loss 1.600671\n",
      "iteration 1000 / 3000: loss 1.589752\n",
      "iteration 1100 / 3000: loss 1.614595\n",
      "iteration 1200 / 3000: loss 1.615993\n",
      "iteration 1300 / 3000: loss 1.666586\n",
      "iteration 1400 / 3000: loss 1.686955\n",
      "iteration 1500 / 3000: loss 1.581900\n",
      "iteration 1600 / 3000: loss 1.568811\n",
      "iteration 1700 / 3000: loss 1.651448\n",
      "iteration 1800 / 3000: loss 1.514824\n",
      "iteration 1900 / 3000: loss 1.649674\n",
      "iteration 2000 / 3000: loss 1.606922\n",
      "iteration 2100 / 3000: loss 1.604549\n",
      "iteration 2200 / 3000: loss 1.577448\n",
      "iteration 2300 / 3000: loss 1.590502\n",
      "iteration 2400 / 3000: loss 1.679100\n",
      "iteration 2500 / 3000: loss 1.637343\n",
      "iteration 2600 / 3000: loss 1.619814\n",
      "iteration 2700 / 3000: loss 1.607945\n",
      "iteration 2800 / 3000: loss 1.628235\n",
      "iteration 2900 / 3000: loss 1.569867\n",
      "iteration 0 / 3000: loss 1.999485\n",
      "iteration 100 / 3000: loss 1.126662\n",
      "iteration 200 / 3000: loss 0.866361\n",
      "iteration 300 / 3000: loss 0.928971\n",
      "iteration 400 / 3000: loss 0.840117\n",
      "iteration 500 / 3000: loss 0.729673\n",
      "iteration 600 / 3000: loss 0.703520\n",
      "iteration 700 / 3000: loss 0.703183\n",
      "iteration 800 / 3000: loss 0.684588\n",
      "iteration 900 / 3000: loss 0.730371\n",
      "iteration 1000 / 3000: loss 0.624247\n",
      "iteration 1100 / 3000: loss 0.603200\n",
      "iteration 1200 / 3000: loss 0.663576\n",
      "iteration 1300 / 3000: loss 0.623493\n",
      "iteration 1400 / 3000: loss 0.653798\n",
      "iteration 1500 / 3000: loss 0.665947\n",
      "iteration 1600 / 3000: loss 0.676009\n",
      "iteration 1700 / 3000: loss 0.678454\n",
      "iteration 1800 / 3000: loss 0.687193\n",
      "iteration 1900 / 3000: loss 0.653496\n",
      "iteration 2000 / 3000: loss 0.704250\n",
      "iteration 2100 / 3000: loss 0.613383\n",
      "iteration 2200 / 3000: loss 0.642076\n",
      "iteration 2300 / 3000: loss 0.678197\n",
      "iteration 2400 / 3000: loss 0.630711\n",
      "iteration 2500 / 3000: loss 0.661652\n",
      "iteration 2600 / 3000: loss 0.703454\n",
      "iteration 2700 / 3000: loss 0.657670\n",
      "iteration 2800 / 3000: loss 0.602608\n",
      "iteration 2900 / 3000: loss 0.711336\n",
      "iteration 0 / 3000: loss 2.000702\n",
      "iteration 100 / 3000: loss 1.895807\n",
      "iteration 200 / 3000: loss 1.882922\n",
      "iteration 300 / 3000: loss 1.887937\n",
      "iteration 400 / 3000: loss 1.882350\n",
      "iteration 500 / 3000: loss 1.896450\n",
      "iteration 600 / 3000: loss 1.890271\n",
      "iteration 700 / 3000: loss 1.885801\n",
      "iteration 800 / 3000: loss 1.902365\n",
      "iteration 900 / 3000: loss 1.870130\n",
      "iteration 1000 / 3000: loss 1.897995\n",
      "iteration 1100 / 3000: loss 1.899242\n",
      "iteration 1200 / 3000: loss 1.901548\n",
      "iteration 1300 / 3000: loss 1.878351\n",
      "iteration 1400 / 3000: loss 1.896565\n",
      "iteration 1500 / 3000: loss 1.888102\n",
      "iteration 1600 / 3000: loss 1.900544\n",
      "iteration 1700 / 3000: loss 1.908919\n",
      "iteration 1800 / 3000: loss 1.867331\n",
      "iteration 1900 / 3000: loss 1.884326\n",
      "iteration 2000 / 3000: loss 1.879731\n",
      "iteration 2100 / 3000: loss 1.893091\n",
      "iteration 2200 / 3000: loss 1.894977\n",
      "iteration 2300 / 3000: loss 1.875890\n",
      "iteration 2400 / 3000: loss 1.872037\n",
      "iteration 2500 / 3000: loss 1.897768\n",
      "iteration 2600 / 3000: loss 1.871090\n",
      "iteration 2700 / 3000: loss 1.898580\n",
      "iteration 2800 / 3000: loss 1.885916\n",
      "iteration 2900 / 3000: loss 1.905009\n",
      "iteration 0 / 3000: loss 2.000582\n",
      "iteration 100 / 3000: loss 1.023274\n",
      "iteration 200 / 3000: loss 0.839033\n",
      "iteration 300 / 3000: loss 0.712146\n",
      "iteration 400 / 3000: loss 0.743508\n",
      "iteration 500 / 3000: loss 0.678543\n",
      "iteration 600 / 3000: loss 0.601078\n",
      "iteration 700 / 3000: loss 0.553681\n",
      "iteration 800 / 3000: loss 0.583339\n",
      "iteration 900 / 3000: loss 0.521230\n",
      "iteration 1000 / 3000: loss 0.498954\n",
      "iteration 1100 / 3000: loss 0.525003\n",
      "iteration 1200 / 3000: loss 0.430804\n",
      "iteration 1300 / 3000: loss 0.482015\n",
      "iteration 1400 / 3000: loss 0.479078\n",
      "iteration 1500 / 3000: loss 0.510123\n",
      "iteration 1600 / 3000: loss 0.484520\n",
      "iteration 1700 / 3000: loss 0.414922\n",
      "iteration 1800 / 3000: loss 0.508630\n",
      "iteration 1900 / 3000: loss 0.404025\n",
      "iteration 2000 / 3000: loss 0.458347\n",
      "iteration 2100 / 3000: loss 0.429006\n",
      "iteration 2200 / 3000: loss 0.476630\n",
      "iteration 2300 / 3000: loss 0.358431\n",
      "iteration 2400 / 3000: loss 0.460152\n",
      "iteration 2500 / 3000: loss 0.453737\n",
      "iteration 2600 / 3000: loss 0.431812\n",
      "iteration 2700 / 3000: loss 0.396939\n",
      "iteration 2800 / 3000: loss 0.435105\n",
      "iteration 2900 / 3000: loss 0.398739\n",
      "iteration 0 / 3000: loss 1.998739\n",
      "iteration 100 / 3000: loss 1.051741\n",
      "iteration 200 / 3000: loss 0.759171\n",
      "iteration 300 / 3000: loss 0.636760\n",
      "iteration 400 / 3000: loss 0.626980\n",
      "iteration 500 / 3000: loss 0.668200\n",
      "iteration 600 / 3000: loss 0.534457\n",
      "iteration 700 / 3000: loss 0.567407\n",
      "iteration 800 / 3000: loss 0.546694\n",
      "iteration 900 / 3000: loss 0.548361\n",
      "iteration 1000 / 3000: loss 0.552067\n",
      "iteration 1100 / 3000: loss 0.470038\n",
      "iteration 1200 / 3000: loss 0.446991\n",
      "iteration 1300 / 3000: loss 0.502451\n",
      "iteration 1400 / 3000: loss 0.511933\n",
      "iteration 1500 / 3000: loss 0.539363\n",
      "iteration 1600 / 3000: loss 0.497265\n",
      "iteration 1700 / 3000: loss 0.493313\n",
      "iteration 1800 / 3000: loss 0.540700\n",
      "iteration 1900 / 3000: loss 0.539773\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration 2000 / 3000: loss 0.445178\n",
      "iteration 2100 / 3000: loss 0.415080\n",
      "iteration 2200 / 3000: loss 0.503988\n",
      "iteration 2300 / 3000: loss 0.453192\n",
      "iteration 2400 / 3000: loss 0.454013\n",
      "iteration 2500 / 3000: loss 0.411923\n",
      "iteration 2600 / 3000: loss 0.446916\n",
      "iteration 2700 / 3000: loss 0.502373\n",
      "iteration 2800 / 3000: loss 0.429180\n",
      "iteration 2900 / 3000: loss 0.378651\n",
      "iteration 0 / 3000: loss 1.998185\n",
      "iteration 100 / 3000: loss 1.020131\n",
      "iteration 200 / 3000: loss 0.875767\n",
      "iteration 300 / 3000: loss 0.930353\n",
      "iteration 400 / 3000: loss 0.717078\n",
      "iteration 500 / 3000: loss 0.690790\n",
      "iteration 600 / 3000: loss 0.530444\n",
      "iteration 700 / 3000: loss 0.646134\n",
      "iteration 800 / 3000: loss 0.603589\n",
      "iteration 900 / 3000: loss 0.538969\n",
      "iteration 1000 / 3000: loss 0.602362\n",
      "iteration 1100 / 3000: loss 0.543034\n",
      "iteration 1200 / 3000: loss 0.550366\n",
      "iteration 1300 / 3000: loss 0.641467\n",
      "iteration 1400 / 3000: loss 0.505829\n",
      "iteration 1500 / 3000: loss 0.496837\n",
      "iteration 1600 / 3000: loss 0.541239\n",
      "iteration 1700 / 3000: loss 0.566074\n",
      "iteration 1800 / 3000: loss 0.549866\n",
      "iteration 1900 / 3000: loss 0.574861\n",
      "iteration 2000 / 3000: loss 0.519766\n",
      "iteration 2100 / 3000: loss 0.545596\n",
      "iteration 2200 / 3000: loss 0.538907\n",
      "iteration 2300 / 3000: loss 0.581687\n",
      "iteration 2400 / 3000: loss 0.614258\n",
      "iteration 2500 / 3000: loss 0.507039\n",
      "iteration 2600 / 3000: loss 0.554122\n",
      "iteration 2700 / 3000: loss 0.533603\n",
      "iteration 2800 / 3000: loss 0.515230\n",
      "iteration 2900 / 3000: loss 0.586869\n",
      "iteration 0 / 3000: loss 1.999135\n",
      "iteration 100 / 3000: loss 0.996282\n",
      "iteration 200 / 3000: loss 0.975365\n",
      "iteration 300 / 3000: loss 1.026918\n",
      "iteration 400 / 3000: loss 0.992800\n",
      "iteration 500 / 3000: loss 0.994902\n",
      "iteration 600 / 3000: loss 0.929043\n",
      "iteration 700 / 3000: loss 0.920710\n",
      "iteration 800 / 3000: loss 0.903739\n",
      "iteration 900 / 3000: loss 1.024356\n",
      "iteration 1000 / 3000: loss 0.964542\n",
      "iteration 1100 / 3000: loss 0.917035\n",
      "iteration 1200 / 3000: loss 0.940307\n",
      "iteration 1300 / 3000: loss 0.893805\n",
      "iteration 1400 / 3000: loss 0.915165\n",
      "iteration 1500 / 3000: loss 0.902105\n",
      "iteration 1600 / 3000: loss 0.914927\n",
      "iteration 1700 / 3000: loss 0.895418\n",
      "iteration 1800 / 3000: loss 0.980736\n",
      "iteration 1900 / 3000: loss 0.934310\n",
      "iteration 2000 / 3000: loss 0.912065\n",
      "iteration 2100 / 3000: loss 0.936957\n",
      "iteration 2200 / 3000: loss 0.836224\n",
      "iteration 2300 / 3000: loss 0.907428\n",
      "iteration 2400 / 3000: loss 0.881390\n",
      "iteration 2500 / 3000: loss 0.921304\n",
      "iteration 2600 / 3000: loss 0.868508\n",
      "iteration 2700 / 3000: loss 1.002227\n",
      "iteration 2800 / 3000: loss 0.931922\n",
      "iteration 2900 / 3000: loss 0.991171\n",
      "iteration 0 / 3000: loss 2.005020\n",
      "iteration 100 / 3000: loss 1.015495\n",
      "iteration 200 / 3000: loss 0.984384\n",
      "iteration 300 / 3000: loss 0.754228\n",
      "iteration 400 / 3000: loss 0.703762\n",
      "iteration 500 / 3000: loss 0.721471\n",
      "iteration 600 / 3000: loss 0.675428\n",
      "iteration 700 / 3000: loss 0.530066\n",
      "iteration 800 / 3000: loss 0.595629\n",
      "iteration 900 / 3000: loss 0.528507\n",
      "iteration 1000 / 3000: loss 0.567364\n",
      "iteration 1100 / 3000: loss 0.472993\n",
      "iteration 1200 / 3000: loss 0.548520\n",
      "iteration 1300 / 3000: loss 0.449680\n",
      "iteration 1400 / 3000: loss 0.531932\n",
      "iteration 1500 / 3000: loss 0.487780\n",
      "iteration 1600 / 3000: loss 0.395876\n",
      "iteration 1700 / 3000: loss 0.450688\n",
      "iteration 1800 / 3000: loss 0.466183\n",
      "iteration 1900 / 3000: loss 0.439637\n",
      "iteration 2000 / 3000: loss 0.420125\n",
      "iteration 2100 / 3000: loss 0.478478\n",
      "iteration 2200 / 3000: loss 0.477038\n",
      "iteration 2300 / 3000: loss 0.445180\n",
      "iteration 2400 / 3000: loss 0.457241\n",
      "iteration 2500 / 3000: loss 0.534440\n",
      "iteration 2600 / 3000: loss 0.471973\n",
      "iteration 2700 / 3000: loss 0.472454\n",
      "iteration 2800 / 3000: loss 0.487424\n",
      "iteration 2900 / 3000: loss 0.455395\n",
      "iteration 0 / 3000: loss 2.000712\n",
      "iteration 100 / 3000: loss 1.067879\n",
      "iteration 200 / 3000: loss 0.829818\n",
      "iteration 300 / 3000: loss 0.845714\n",
      "iteration 400 / 3000: loss 0.750428\n",
      "iteration 500 / 3000: loss 0.664975\n",
      "iteration 600 / 3000: loss 0.611336\n",
      "iteration 700 / 3000: loss 0.570762\n",
      "iteration 800 / 3000: loss 0.566580\n",
      "iteration 900 / 3000: loss 0.535283\n",
      "iteration 1000 / 3000: loss 0.524797\n",
      "iteration 1100 / 3000: loss 0.500507\n",
      "iteration 1200 / 3000: loss 0.529325\n",
      "iteration 1300 / 3000: loss 0.496430\n",
      "iteration 1400 / 3000: loss 0.419636\n",
      "iteration 1500 / 3000: loss 0.485749\n",
      "iteration 1600 / 3000: loss 0.471828\n",
      "iteration 1700 / 3000: loss 0.418508\n",
      "iteration 1800 / 3000: loss 0.423830\n",
      "iteration 1900 / 3000: loss 0.473734\n",
      "iteration 2000 / 3000: loss 0.351018\n",
      "iteration 2100 / 3000: loss 0.396466\n",
      "iteration 2200 / 3000: loss 0.495211\n",
      "iteration 2300 / 3000: loss 0.466773\n",
      "iteration 2400 / 3000: loss 0.483612\n",
      "iteration 2500 / 3000: loss 0.462346\n",
      "iteration 2600 / 3000: loss 0.414521\n",
      "iteration 2700 / 3000: loss 0.466758\n",
      "iteration 2800 / 3000: loss 0.337759\n",
      "iteration 2900 / 3000: loss 0.450644\n",
      "iteration 0 / 3000: loss 1.997782\n",
      "iteration 100 / 3000: loss 1.217518\n",
      "iteration 200 / 3000: loss 1.331964\n",
      "iteration 300 / 3000: loss 1.277305\n",
      "iteration 400 / 3000: loss 1.307648\n",
      "iteration 500 / 3000: loss 1.267115\n",
      "iteration 600 / 3000: loss 1.306986\n",
      "iteration 700 / 3000: loss 1.237546\n",
      "iteration 800 / 3000: loss 1.214029\n",
      "iteration 900 / 3000: loss 1.255476\n",
      "iteration 1000 / 3000: loss 1.140028\n",
      "iteration 1100 / 3000: loss 1.167001\n",
      "iteration 1200 / 3000: loss 1.317810\n",
      "iteration 1300 / 3000: loss 1.341220\n",
      "iteration 1400 / 3000: loss 1.268189\n",
      "iteration 1500 / 3000: loss 1.261164\n",
      "iteration 1600 / 3000: loss 1.238963\n",
      "iteration 1700 / 3000: loss 1.186008\n",
      "iteration 1800 / 3000: loss 1.332183\n",
      "iteration 1900 / 3000: loss 1.327294\n",
      "iteration 2000 / 3000: loss 1.305322\n",
      "iteration 2100 / 3000: loss 1.321749\n",
      "iteration 2200 / 3000: loss 1.351616\n",
      "iteration 2300 / 3000: loss 1.267736\n",
      "iteration 2400 / 3000: loss 1.235598\n",
      "iteration 2500 / 3000: loss 1.220612\n",
      "iteration 2600 / 3000: loss 1.153820\n",
      "iteration 2700 / 3000: loss 1.290443\n",
      "iteration 2800 / 3000: loss 1.323901\n",
      "iteration 2900 / 3000: loss 1.253874\n",
      "iteration 0 / 3000: loss 2.000775\n",
      "iteration 100 / 3000: loss 1.599137\n",
      "iteration 200 / 3000: loss 1.738328\n",
      "iteration 300 / 3000: loss 1.643447\n",
      "iteration 400 / 3000: loss 1.520311\n",
      "iteration 500 / 3000: loss 1.651967\n",
      "iteration 600 / 3000: loss 1.678109\n",
      "iteration 700 / 3000: loss 1.636311\n",
      "iteration 800 / 3000: loss 1.643750\n",
      "iteration 900 / 3000: loss 1.646951\n",
      "iteration 1000 / 3000: loss 1.582870\n",
      "iteration 1100 / 3000: loss 1.628959\n",
      "iteration 1200 / 3000: loss 1.574668\n",
      "iteration 1300 / 3000: loss 1.635223\n",
      "iteration 1400 / 3000: loss 1.637393\n",
      "iteration 1500 / 3000: loss 1.510670\n",
      "iteration 1600 / 3000: loss 1.569731\n",
      "iteration 1700 / 3000: loss 1.586335\n",
      "iteration 1800 / 3000: loss 1.657132\n",
      "iteration 1900 / 3000: loss 1.609181\n",
      "iteration 2000 / 3000: loss 1.651704\n",
      "iteration 2100 / 3000: loss 1.562384\n",
      "iteration 2200 / 3000: loss 1.672094\n",
      "iteration 2300 / 3000: loss 1.508206\n",
      "iteration 2400 / 3000: loss 1.582981\n",
      "iteration 2500 / 3000: loss 1.600294\n",
      "iteration 2600 / 3000: loss 1.607932\n",
      "iteration 2700 / 3000: loss 1.681735\n",
      "iteration 2800 / 3000: loss 1.601118\n",
      "iteration 2900 / 3000: loss 1.594584\n",
      "iteration 0 / 3000: loss 2.001557\n",
      "iteration 100 / 3000: loss 0.815201\n",
      "iteration 200 / 3000: loss 0.707512\n",
      "iteration 300 / 3000: loss 0.706350\n",
      "iteration 400 / 3000: loss 0.664817\n",
      "iteration 500 / 3000: loss 0.740840\n",
      "iteration 600 / 3000: loss 0.722420\n",
      "iteration 700 / 3000: loss 0.746893\n",
      "iteration 800 / 3000: loss 0.730267\n",
      "iteration 900 / 3000: loss 0.608788\n",
      "iteration 1000 / 3000: loss 0.650373\n",
      "iteration 1100 / 3000: loss 0.638929\n",
      "iteration 1200 / 3000: loss 0.672559\n",
      "iteration 1300 / 3000: loss 0.670552\n",
      "iteration 1400 / 3000: loss 0.694718\n",
      "iteration 1500 / 3000: loss 0.670357\n",
      "iteration 1600 / 3000: loss 0.588928\n",
      "iteration 1700 / 3000: loss 0.662742\n",
      "iteration 1800 / 3000: loss 0.683684\n",
      "iteration 1900 / 3000: loss 0.658853\n",
      "iteration 2000 / 3000: loss 0.661535\n",
      "iteration 2100 / 3000: loss 0.659499\n",
      "iteration 2200 / 3000: loss 0.680359\n",
      "iteration 2300 / 3000: loss 0.646523\n",
      "iteration 2400 / 3000: loss 0.690112\n",
      "iteration 2500 / 3000: loss 0.731275\n",
      "iteration 2600 / 3000: loss 0.657934\n",
      "iteration 2700 / 3000: loss 0.608330\n",
      "iteration 2800 / 3000: loss 0.660666\n",
      "iteration 2900 / 3000: loss 0.622883\n",
      "iteration 0 / 3000: loss 2.003185\n",
      "iteration 100 / 3000: loss 1.878796\n",
      "iteration 200 / 3000: loss 1.893125\n",
      "iteration 300 / 3000: loss 1.893109\n",
      "iteration 400 / 3000: loss 1.893984\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration 500 / 3000: loss 1.885015\n",
      "iteration 600 / 3000: loss 1.870129\n",
      "iteration 700 / 3000: loss 1.901141\n",
      "iteration 800 / 3000: loss 1.889479\n",
      "iteration 900 / 3000: loss 1.872412\n",
      "iteration 1000 / 3000: loss 1.872424\n",
      "iteration 1100 / 3000: loss 1.898959\n",
      "iteration 1200 / 3000: loss 1.908114\n",
      "iteration 1300 / 3000: loss 1.880660\n",
      "iteration 1400 / 3000: loss 1.883187\n",
      "iteration 1500 / 3000: loss 1.876400\n",
      "iteration 1600 / 3000: loss 1.895952\n",
      "iteration 1700 / 3000: loss 1.886227\n",
      "iteration 1800 / 3000: loss 1.909172\n",
      "iteration 1900 / 3000: loss 1.900707\n",
      "iteration 2000 / 3000: loss 1.887034\n",
      "iteration 2100 / 3000: loss 1.890002\n",
      "iteration 2200 / 3000: loss 1.905174\n",
      "iteration 2300 / 3000: loss 1.896165\n",
      "iteration 2400 / 3000: loss 1.921919\n",
      "iteration 2500 / 3000: loss 1.901780\n",
      "iteration 2600 / 3000: loss 1.894431\n",
      "iteration 2700 / 3000: loss 1.890739\n",
      "iteration 2800 / 3000: loss 1.888537\n",
      "iteration 2900 / 3000: loss 1.907179\n",
      "iteration 0 / 3000: loss 1.996129\n",
      "iteration 100 / 3000: loss 0.829589\n",
      "iteration 200 / 3000: loss 0.547788\n",
      "iteration 300 / 3000: loss 0.585116\n",
      "iteration 400 / 3000: loss 0.513399\n",
      "iteration 500 / 3000: loss 0.437636\n",
      "iteration 600 / 3000: loss 0.444203\n",
      "iteration 700 / 3000: loss 0.410070\n",
      "iteration 800 / 3000: loss 0.386030\n",
      "iteration 900 / 3000: loss 0.348906\n",
      "iteration 1000 / 3000: loss 0.461772\n",
      "iteration 1100 / 3000: loss 0.465634\n",
      "iteration 1200 / 3000: loss 0.407716\n",
      "iteration 1300 / 3000: loss 0.416518\n",
      "iteration 1400 / 3000: loss 0.345625\n",
      "iteration 1500 / 3000: loss 0.449192\n",
      "iteration 1600 / 3000: loss 0.443219\n",
      "iteration 1700 / 3000: loss 0.266419\n",
      "iteration 1800 / 3000: loss 0.271396\n",
      "iteration 1900 / 3000: loss 0.327573\n",
      "iteration 2000 / 3000: loss 0.409891\n",
      "iteration 2100 / 3000: loss 0.308511\n",
      "iteration 2200 / 3000: loss 0.328494\n",
      "iteration 2300 / 3000: loss 0.326093\n",
      "iteration 2400 / 3000: loss 0.344076\n",
      "iteration 2500 / 3000: loss 0.340465\n",
      "iteration 2600 / 3000: loss 0.321392\n",
      "iteration 2700 / 3000: loss 0.302343\n",
      "iteration 2800 / 3000: loss 0.345269\n",
      "iteration 2900 / 3000: loss 0.339905\n",
      "iteration 0 / 3000: loss 1.999873\n",
      "iteration 100 / 3000: loss 0.788461\n",
      "iteration 200 / 3000: loss 0.603288\n",
      "iteration 300 / 3000: loss 0.566411\n",
      "iteration 400 / 3000: loss 0.429969\n",
      "iteration 500 / 3000: loss 0.482322\n",
      "iteration 600 / 3000: loss 0.532641\n",
      "iteration 700 / 3000: loss 0.442674\n",
      "iteration 800 / 3000: loss 0.390843\n",
      "iteration 900 / 3000: loss 0.475176\n",
      "iteration 1000 / 3000: loss 0.334083\n",
      "iteration 1100 / 3000: loss 0.375715\n",
      "iteration 1200 / 3000: loss 0.382580\n",
      "iteration 1300 / 3000: loss 0.443019\n",
      "iteration 1400 / 3000: loss 0.375158\n",
      "iteration 1500 / 3000: loss 0.340727\n",
      "iteration 1600 / 3000: loss 0.409061\n",
      "iteration 1700 / 3000: loss 0.372814\n",
      "iteration 1800 / 3000: loss 0.346078\n",
      "iteration 1900 / 3000: loss 0.380910\n",
      "iteration 2000 / 3000: loss 0.329524\n",
      "iteration 2100 / 3000: loss 0.273542\n",
      "iteration 2200 / 3000: loss 0.442834\n",
      "iteration 2300 / 3000: loss 0.253475\n",
      "iteration 2400 / 3000: loss 0.344547\n",
      "iteration 2500 / 3000: loss 0.388130\n",
      "iteration 2600 / 3000: loss 0.373191\n",
      "iteration 2700 / 3000: loss 0.398300\n",
      "iteration 2800 / 3000: loss 0.281700\n",
      "iteration 2900 / 3000: loss 0.332192\n",
      "iteration 0 / 3000: loss 2.002592\n",
      "iteration 100 / 3000: loss 0.803458\n",
      "iteration 200 / 3000: loss 0.684828\n",
      "iteration 300 / 3000: loss 0.597147\n",
      "iteration 400 / 3000: loss 0.556816\n",
      "iteration 500 / 3000: loss 0.565241\n",
      "iteration 600 / 3000: loss 0.538412\n",
      "iteration 700 / 3000: loss 0.517582\n",
      "iteration 800 / 3000: loss 0.497103\n",
      "iteration 900 / 3000: loss 0.608315\n",
      "iteration 1000 / 3000: loss 0.448863\n",
      "iteration 1100 / 3000: loss 0.500276\n",
      "iteration 1200 / 3000: loss 0.501068\n",
      "iteration 1300 / 3000: loss 0.586643\n",
      "iteration 1400 / 3000: loss 0.537739\n",
      "iteration 1500 / 3000: loss 0.536727\n",
      "iteration 1600 / 3000: loss 0.518764\n",
      "iteration 1700 / 3000: loss 0.446039\n",
      "iteration 1800 / 3000: loss 0.524214\n",
      "iteration 1900 / 3000: loss 0.551715\n",
      "iteration 2000 / 3000: loss 0.466338\n",
      "iteration 2100 / 3000: loss 0.531648\n",
      "iteration 2200 / 3000: loss 0.473220\n",
      "iteration 2300 / 3000: loss 0.455816\n",
      "iteration 2400 / 3000: loss 0.465718\n",
      "iteration 2500 / 3000: loss 0.511848\n",
      "iteration 2600 / 3000: loss 0.573734\n",
      "iteration 2700 / 3000: loss 0.521215\n",
      "iteration 2800 / 3000: loss 0.476033\n",
      "iteration 2900 / 3000: loss 0.567242\n",
      "iteration 0 / 3000: loss 2.000689\n",
      "iteration 100 / 3000: loss 0.956334\n",
      "iteration 200 / 3000: loss 0.961260\n",
      "iteration 300 / 3000: loss 0.989666\n",
      "iteration 400 / 3000: loss 0.864711\n",
      "iteration 500 / 3000: loss 0.971456\n",
      "iteration 600 / 3000: loss 0.896525\n",
      "iteration 700 / 3000: loss 0.924781\n",
      "iteration 800 / 3000: loss 0.950846\n",
      "iteration 900 / 3000: loss 0.949460\n",
      "iteration 1000 / 3000: loss 0.978613\n",
      "iteration 1100 / 3000: loss 0.926144\n",
      "iteration 1200 / 3000: loss 0.969102\n",
      "iteration 1300 / 3000: loss 0.905736\n",
      "iteration 1400 / 3000: loss 0.989863\n",
      "iteration 1500 / 3000: loss 0.908254\n",
      "iteration 1600 / 3000: loss 0.817750\n",
      "iteration 1700 / 3000: loss 0.879924\n",
      "iteration 1800 / 3000: loss 0.978617\n",
      "iteration 1900 / 3000: loss 0.947108\n",
      "iteration 2000 / 3000: loss 1.006291\n",
      "iteration 2100 / 3000: loss 0.926711\n",
      "iteration 2200 / 3000: loss 0.869066\n",
      "iteration 2300 / 3000: loss 0.989489\n",
      "iteration 2400 / 3000: loss 1.010152\n",
      "iteration 2500 / 3000: loss 0.912499\n",
      "iteration 2600 / 3000: loss 0.889901\n",
      "iteration 2700 / 3000: loss 0.872904\n",
      "iteration 2800 / 3000: loss 0.875977\n",
      "iteration 2900 / 3000: loss 0.950463\n",
      "iteration 0 / 3000: loss 2.002044\n",
      "iteration 100 / 3000: loss 0.771950\n",
      "iteration 200 / 3000: loss 0.606129\n",
      "iteration 300 / 3000: loss 0.517994\n",
      "iteration 400 / 3000: loss 0.499511\n",
      "iteration 500 / 3000: loss 0.424541\n",
      "iteration 600 / 3000: loss 0.455117\n",
      "iteration 700 / 3000: loss 0.479823\n",
      "iteration 800 / 3000: loss 0.405079\n",
      "iteration 900 / 3000: loss 0.466676\n",
      "iteration 1000 / 3000: loss 0.418605\n",
      "iteration 1100 / 3000: loss 0.404889\n",
      "iteration 1200 / 3000: loss 0.392240\n",
      "iteration 1300 / 3000: loss 0.527453\n",
      "iteration 1400 / 3000: loss 0.359733\n",
      "iteration 1500 / 3000: loss 0.345092\n",
      "iteration 1600 / 3000: loss 0.368518\n",
      "iteration 1700 / 3000: loss 0.445426\n",
      "iteration 1800 / 3000: loss 0.436224\n",
      "iteration 1900 / 3000: loss 0.454665\n",
      "iteration 2000 / 3000: loss 0.364746\n",
      "iteration 2100 / 3000: loss 0.417307\n",
      "iteration 2200 / 3000: loss 0.354475\n",
      "iteration 2300 / 3000: loss 0.435460\n",
      "iteration 2400 / 3000: loss 0.451317\n",
      "iteration 2500 / 3000: loss 0.395029\n",
      "iteration 2600 / 3000: loss 0.345988\n",
      "iteration 2700 / 3000: loss 0.309458\n",
      "iteration 2800 / 3000: loss 0.351752\n",
      "iteration 2900 / 3000: loss 0.376105\n",
      "iteration 0 / 3000: loss 2.003856\n",
      "iteration 100 / 3000: loss 0.834789\n",
      "iteration 200 / 3000: loss 0.640883\n",
      "iteration 300 / 3000: loss 0.496410\n",
      "iteration 400 / 3000: loss 0.484499\n",
      "iteration 500 / 3000: loss 0.496015\n",
      "iteration 600 / 3000: loss 0.409038\n",
      "iteration 700 / 3000: loss 0.384813\n",
      "iteration 800 / 3000: loss 0.512442\n",
      "iteration 900 / 3000: loss 0.519608\n",
      "iteration 1000 / 3000: loss 0.507235\n",
      "iteration 1100 / 3000: loss 0.454539\n",
      "iteration 1200 / 3000: loss 0.421015\n",
      "iteration 1300 / 3000: loss 0.334419\n",
      "iteration 1400 / 3000: loss 0.313524\n",
      "iteration 1500 / 3000: loss 0.424249\n",
      "iteration 1600 / 3000: loss 0.279976\n",
      "iteration 1700 / 3000: loss 0.383991\n",
      "iteration 1800 / 3000: loss 0.337310\n",
      "iteration 1900 / 3000: loss 0.357330\n",
      "iteration 2000 / 3000: loss 0.355648\n",
      "iteration 2100 / 3000: loss 0.375228\n",
      "iteration 2200 / 3000: loss 0.304080\n",
      "iteration 2300 / 3000: loss 0.341152\n",
      "iteration 2400 / 3000: loss 0.352692\n",
      "iteration 2500 / 3000: loss 0.328715\n",
      "iteration 2600 / 3000: loss 0.329018\n",
      "iteration 2700 / 3000: loss 0.364215\n",
      "iteration 2800 / 3000: loss 0.382806\n",
      "iteration 2900 / 3000: loss 0.461608\n",
      "iteration 0 / 3000: loss 2.003348\n",
      "iteration 100 / 3000: loss 1.362823\n",
      "iteration 200 / 3000: loss 1.232894\n",
      "iteration 300 / 3000: loss 1.152141\n",
      "iteration 400 / 3000: loss 1.276694\n",
      "iteration 500 / 3000: loss 1.216072\n",
      "iteration 600 / 3000: loss 1.242639\n",
      "iteration 700 / 3000: loss 1.202089\n",
      "iteration 800 / 3000: loss 1.220367\n",
      "iteration 900 / 3000: loss 1.164559\n",
      "iteration 1000 / 3000: loss 1.355518\n",
      "iteration 1100 / 3000: loss 1.250912\n",
      "iteration 1200 / 3000: loss 1.327752\n",
      "iteration 1300 / 3000: loss 1.324483\n",
      "iteration 1400 / 3000: loss 1.304160\n",
      "iteration 1500 / 3000: loss 1.309912\n",
      "iteration 1600 / 3000: loss 1.180873\n",
      "iteration 1700 / 3000: loss 1.240176\n",
      "iteration 1800 / 3000: loss 1.158433\n",
      "iteration 1900 / 3000: loss 1.230756\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration 2000 / 3000: loss 1.234334\n",
      "iteration 2100 / 3000: loss 1.290454\n",
      "iteration 2200 / 3000: loss 1.291905\n",
      "iteration 2300 / 3000: loss 1.284682\n",
      "iteration 2400 / 3000: loss 1.231821\n",
      "iteration 2500 / 3000: loss 1.319462\n",
      "iteration 2600 / 3000: loss 1.372620\n",
      "iteration 2700 / 3000: loss 1.300762\n",
      "iteration 2800 / 3000: loss 1.232923\n",
      "iteration 2900 / 3000: loss 1.259843\n",
      "iteration 0 / 3000: loss 1.997178\n",
      "iteration 100 / 3000: loss 1.585260\n",
      "iteration 200 / 3000: loss 1.626387\n",
      "iteration 300 / 3000: loss 1.569061\n",
      "iteration 400 / 3000: loss 1.582764\n",
      "iteration 500 / 3000: loss 1.642686\n",
      "iteration 600 / 3000: loss 1.613599\n",
      "iteration 700 / 3000: loss 1.599731\n",
      "iteration 800 / 3000: loss 1.570910\n",
      "iteration 900 / 3000: loss 1.593830\n",
      "iteration 1000 / 3000: loss 1.596954\n",
      "iteration 1100 / 3000: loss 1.642717\n",
      "iteration 1200 / 3000: loss 1.705722\n",
      "iteration 1300 / 3000: loss 1.666290\n",
      "iteration 1400 / 3000: loss 1.555766\n",
      "iteration 1500 / 3000: loss 1.661142\n",
      "iteration 1600 / 3000: loss 1.617224\n",
      "iteration 1700 / 3000: loss 1.636935\n",
      "iteration 1800 / 3000: loss 1.516501\n",
      "iteration 1900 / 3000: loss 1.630140\n",
      "iteration 2000 / 3000: loss 1.610643\n",
      "iteration 2100 / 3000: loss 1.556616\n",
      "iteration 2200 / 3000: loss 1.639615\n",
      "iteration 2300 / 3000: loss 1.548906\n",
      "iteration 2400 / 3000: loss 1.600926\n",
      "iteration 2500 / 3000: loss 1.663520\n",
      "iteration 2600 / 3000: loss 1.594617\n",
      "iteration 2700 / 3000: loss 1.621498\n",
      "iteration 2800 / 3000: loss 1.595402\n",
      "iteration 2900 / 3000: loss 1.627797\n",
      "iteration 0 / 3000: loss 2.001037\n",
      "iteration 100 / 3000: loss 0.634004\n",
      "iteration 200 / 3000: loss 0.739074\n",
      "iteration 300 / 3000: loss 0.707956\n",
      "iteration 400 / 3000: loss 0.704796\n",
      "iteration 500 / 3000: loss 0.695470\n",
      "iteration 600 / 3000: loss 0.650764\n",
      "iteration 700 / 3000: loss 0.689393\n",
      "iteration 800 / 3000: loss 0.638392\n",
      "iteration 900 / 3000: loss 0.664592\n",
      "iteration 1000 / 3000: loss 0.594359\n",
      "iteration 1100 / 3000: loss 0.659757\n",
      "iteration 1200 / 3000: loss 0.661432\n",
      "iteration 1300 / 3000: loss 0.699824\n",
      "iteration 1400 / 3000: loss 0.649004\n",
      "iteration 1500 / 3000: loss 0.620360\n",
      "iteration 1600 / 3000: loss 0.662320\n",
      "iteration 1700 / 3000: loss 0.714807\n",
      "iteration 1800 / 3000: loss 0.635946\n",
      "iteration 1900 / 3000: loss 0.666280\n",
      "iteration 2000 / 3000: loss 0.703773\n",
      "iteration 2100 / 3000: loss 0.653171\n",
      "iteration 2200 / 3000: loss 0.794671\n",
      "iteration 2300 / 3000: loss 0.686313\n",
      "iteration 2400 / 3000: loss 0.653704\n",
      "iteration 2500 / 3000: loss 0.688602\n",
      "iteration 2600 / 3000: loss 0.747650\n",
      "iteration 2700 / 3000: loss 0.612606\n",
      "iteration 2800 / 3000: loss 0.591128\n",
      "iteration 2900 / 3000: loss 0.663207\n",
      "iteration 0 / 3000: loss 2.002634\n",
      "iteration 100 / 3000: loss 1.870718\n",
      "iteration 200 / 3000: loss 1.888803\n",
      "iteration 300 / 3000: loss 1.891611\n",
      "iteration 400 / 3000: loss 1.889708\n",
      "iteration 500 / 3000: loss 1.909767\n",
      "iteration 600 / 3000: loss 1.870453\n",
      "iteration 700 / 3000: loss 1.903105\n",
      "iteration 800 / 3000: loss 1.891590\n",
      "iteration 900 / 3000: loss 1.882345\n",
      "iteration 1000 / 3000: loss 1.866109\n",
      "iteration 1100 / 3000: loss 1.889210\n",
      "iteration 1200 / 3000: loss 1.858436\n",
      "iteration 1300 / 3000: loss 1.892956\n",
      "iteration 1400 / 3000: loss 1.894906\n",
      "iteration 1500 / 3000: loss 1.919808\n",
      "iteration 1600 / 3000: loss 1.869384\n",
      "iteration 1700 / 3000: loss 1.884869\n",
      "iteration 1800 / 3000: loss 1.887957\n",
      "iteration 1900 / 3000: loss 1.909363\n",
      "iteration 2000 / 3000: loss 1.885204\n",
      "iteration 2100 / 3000: loss 1.882718\n",
      "iteration 2200 / 3000: loss 1.883858\n",
      "iteration 2300 / 3000: loss 1.902505\n",
      "iteration 2400 / 3000: loss 1.882460\n",
      "iteration 2500 / 3000: loss 1.910454\n",
      "iteration 2600 / 3000: loss 1.894488\n",
      "iteration 2700 / 3000: loss 1.885870\n",
      "iteration 2800 / 3000: loss 1.888746\n",
      "iteration 2900 / 3000: loss 1.893752\n",
      "iteration 0 / 3000: loss 1.998830\n",
      "iteration 100 / 3000: loss 0.490054\n",
      "iteration 200 / 3000: loss 0.489860\n",
      "iteration 300 / 3000: loss 0.427032\n",
      "iteration 400 / 3000: loss 0.450512\n",
      "iteration 500 / 3000: loss 0.286438\n",
      "iteration 600 / 3000: loss 0.310082\n",
      "iteration 700 / 3000: loss 0.439071\n",
      "iteration 800 / 3000: loss 0.418913\n",
      "iteration 900 / 3000: loss 0.302064\n",
      "iteration 1000 / 3000: loss 0.383766\n",
      "iteration 1100 / 3000: loss 0.288298\n",
      "iteration 1200 / 3000: loss 0.382482\n",
      "iteration 1300 / 3000: loss 0.307024\n",
      "iteration 1400 / 3000: loss 0.344876\n",
      "iteration 1500 / 3000: loss 0.326852\n",
      "iteration 1600 / 3000: loss 0.421108\n",
      "iteration 1700 / 3000: loss 0.320596\n",
      "iteration 1800 / 3000: loss 0.287355\n",
      "iteration 1900 / 3000: loss 0.321379\n",
      "iteration 2000 / 3000: loss 0.241865\n",
      "iteration 2100 / 3000: loss 0.392946\n",
      "iteration 2200 / 3000: loss 0.283964\n",
      "iteration 2300 / 3000: loss 0.307132\n",
      "iteration 2400 / 3000: loss 0.276806\n",
      "iteration 2500 / 3000: loss 0.331062\n",
      "iteration 2600 / 3000: loss 0.237099\n",
      "iteration 2700 / 3000: loss 0.301068\n",
      "iteration 2800 / 3000: loss 0.312325\n",
      "iteration 2900 / 3000: loss 0.279695\n",
      "iteration 0 / 3000: loss 2.000660\n",
      "iteration 100 / 3000: loss 0.508220\n",
      "iteration 200 / 3000: loss 0.411045\n",
      "iteration 300 / 3000: loss 0.405101\n",
      "iteration 400 / 3000: loss 0.346938\n",
      "iteration 500 / 3000: loss 0.392753\n",
      "iteration 600 / 3000: loss 0.388291\n",
      "iteration 700 / 3000: loss 0.291758\n",
      "iteration 800 / 3000: loss 0.351353\n",
      "iteration 900 / 3000: loss 0.347451\n",
      "iteration 1000 / 3000: loss 0.282800\n",
      "iteration 1100 / 3000: loss 0.332094\n",
      "iteration 1200 / 3000: loss 0.307721\n",
      "iteration 1300 / 3000: loss 0.391972\n",
      "iteration 1400 / 3000: loss 0.289310\n",
      "iteration 1500 / 3000: loss 0.245123\n",
      "iteration 1600 / 3000: loss 0.261521\n",
      "iteration 1700 / 3000: loss 0.398744\n",
      "iteration 1800 / 3000: loss 0.262026\n",
      "iteration 1900 / 3000: loss 0.360038\n",
      "iteration 2000 / 3000: loss 0.292895\n",
      "iteration 2100 / 3000: loss 0.307200\n",
      "iteration 2200 / 3000: loss 0.218228\n",
      "iteration 2300 / 3000: loss 0.359349\n",
      "iteration 2400 / 3000: loss 0.261951\n",
      "iteration 2500 / 3000: loss 0.356891\n",
      "iteration 2600 / 3000: loss 0.358497\n",
      "iteration 2700 / 3000: loss 0.263611\n",
      "iteration 2800 / 3000: loss 0.315625\n",
      "iteration 2900 / 3000: loss 0.439729\n",
      "iteration 0 / 3000: loss 1.999286\n",
      "iteration 100 / 3000: loss 0.563022\n",
      "iteration 200 / 3000: loss 0.454151\n",
      "iteration 300 / 3000: loss 0.505910\n",
      "iteration 400 / 3000: loss 0.523469\n",
      "iteration 500 / 3000: loss 0.502087\n",
      "iteration 600 / 3000: loss 0.499058\n",
      "iteration 700 / 3000: loss 0.446359\n",
      "iteration 800 / 3000: loss 0.487799\n",
      "iteration 900 / 3000: loss 0.585294\n",
      "iteration 1000 / 3000: loss 0.525992\n",
      "iteration 1100 / 3000: loss 0.394931\n",
      "iteration 1200 / 3000: loss 0.484196\n",
      "iteration 1300 / 3000: loss 0.502930\n",
      "iteration 1400 / 3000: loss 0.477949\n",
      "iteration 1500 / 3000: loss 0.486767\n",
      "iteration 1600 / 3000: loss 0.439475\n",
      "iteration 1700 / 3000: loss 0.518195\n",
      "iteration 1800 / 3000: loss 0.496902\n",
      "iteration 1900 / 3000: loss 0.461880\n",
      "iteration 2000 / 3000: loss 0.459894\n",
      "iteration 2100 / 3000: loss 0.488128\n",
      "iteration 2200 / 3000: loss 0.538602\n",
      "iteration 2300 / 3000: loss 0.465689\n",
      "iteration 2400 / 3000: loss 0.514534\n",
      "iteration 2500 / 3000: loss 0.468372\n",
      "iteration 2600 / 3000: loss 0.472896\n",
      "iteration 2700 / 3000: loss 0.495708\n",
      "iteration 2800 / 3000: loss 0.530884\n",
      "iteration 2900 / 3000: loss 0.461957\n",
      "iteration 0 / 3000: loss 2.001319\n",
      "iteration 100 / 3000: loss 0.878592\n",
      "iteration 200 / 3000: loss 0.879985\n",
      "iteration 300 / 3000: loss 0.949739\n",
      "iteration 400 / 3000: loss 0.920693\n",
      "iteration 500 / 3000: loss 0.902980\n",
      "iteration 600 / 3000: loss 0.946622\n",
      "iteration 700 / 3000: loss 0.937754\n",
      "iteration 800 / 3000: loss 0.933041\n",
      "iteration 900 / 3000: loss 0.985310\n",
      "iteration 1000 / 3000: loss 0.915926\n",
      "iteration 1100 / 3000: loss 0.916008\n",
      "iteration 1200 / 3000: loss 0.911681\n",
      "iteration 1300 / 3000: loss 0.907807\n",
      "iteration 1400 / 3000: loss 0.922517\n",
      "iteration 1500 / 3000: loss 0.885872\n",
      "iteration 1600 / 3000: loss 0.999850\n",
      "iteration 1700 / 3000: loss 0.902141\n",
      "iteration 1800 / 3000: loss 0.909065\n",
      "iteration 1900 / 3000: loss 0.895528\n",
      "iteration 2000 / 3000: loss 0.955913\n",
      "iteration 2100 / 3000: loss 0.943378\n",
      "iteration 2200 / 3000: loss 0.917015\n",
      "iteration 2300 / 3000: loss 0.914004\n",
      "iteration 2400 / 3000: loss 0.969206\n",
      "iteration 2500 / 3000: loss 0.942088\n",
      "iteration 2600 / 3000: loss 0.980527\n",
      "iteration 2700 / 3000: loss 0.920685\n",
      "iteration 2800 / 3000: loss 0.887754\n",
      "iteration 2900 / 3000: loss 0.908448\n",
      "iteration 0 / 3000: loss 2.003226\n",
      "iteration 100 / 3000: loss 0.567000\n",
      "iteration 200 / 3000: loss 0.523305\n",
      "iteration 300 / 3000: loss 0.413810\n",
      "iteration 400 / 3000: loss 0.432663\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration 500 / 3000: loss 0.469891\n",
      "iteration 600 / 3000: loss 0.427874\n",
      "iteration 700 / 3000: loss 0.463941\n",
      "iteration 800 / 3000: loss 0.367281\n",
      "iteration 900 / 3000: loss 0.360969\n",
      "iteration 1000 / 3000: loss 0.417704\n",
      "iteration 1100 / 3000: loss 0.377226\n",
      "iteration 1200 / 3000: loss 0.388736\n",
      "iteration 1300 / 3000: loss 0.381411\n",
      "iteration 1400 / 3000: loss 0.396870\n",
      "iteration 1500 / 3000: loss 0.370994\n",
      "iteration 1600 / 3000: loss 0.423194\n",
      "iteration 1700 / 3000: loss 0.380470\n",
      "iteration 1800 / 3000: loss 0.464363\n",
      "iteration 1900 / 3000: loss 0.290396\n",
      "iteration 2000 / 3000: loss 0.400222\n",
      "iteration 2100 / 3000: loss 0.430422\n",
      "iteration 2200 / 3000: loss 0.444449\n",
      "iteration 2300 / 3000: loss 0.366367\n",
      "iteration 2400 / 3000: loss 0.358915\n",
      "iteration 2500 / 3000: loss 0.298643\n",
      "iteration 2600 / 3000: loss 0.326992\n",
      "iteration 2700 / 3000: loss 0.391186\n",
      "iteration 2800 / 3000: loss 0.367613\n",
      "iteration 2900 / 3000: loss 0.335617\n",
      "iteration 0 / 3000: loss 1.999907\n",
      "iteration 100 / 3000: loss 0.521305\n",
      "iteration 200 / 3000: loss 0.474196\n",
      "iteration 300 / 3000: loss 0.418872\n",
      "iteration 400 / 3000: loss 0.377924\n",
      "iteration 500 / 3000: loss 0.343745\n",
      "iteration 600 / 3000: loss 0.344938\n",
      "iteration 700 / 3000: loss 0.292277\n",
      "iteration 800 / 3000: loss 0.334369\n",
      "iteration 900 / 3000: loss 0.370209\n",
      "iteration 1000 / 3000: loss 0.463814\n",
      "iteration 1100 / 3000: loss 0.378377\n",
      "iteration 1200 / 3000: loss 0.404020\n",
      "iteration 1300 / 3000: loss 0.280544\n",
      "iteration 1400 / 3000: loss 0.335666\n",
      "iteration 1500 / 3000: loss 0.275827\n",
      "iteration 1600 / 3000: loss 0.431907\n",
      "iteration 1700 / 3000: loss 0.364292\n",
      "iteration 1800 / 3000: loss 0.313603\n",
      "iteration 1900 / 3000: loss 0.347753\n",
      "iteration 2000 / 3000: loss 0.335798\n",
      "iteration 2100 / 3000: loss 0.404723\n",
      "iteration 2200 / 3000: loss 0.321347\n",
      "iteration 2300 / 3000: loss 0.206043\n",
      "iteration 2400 / 3000: loss 0.241972\n",
      "iteration 2500 / 3000: loss 0.365411\n",
      "iteration 2600 / 3000: loss 0.462894\n",
      "iteration 2700 / 3000: loss 0.223937\n",
      "iteration 2800 / 3000: loss 0.296236\n",
      "iteration 2900 / 3000: loss 0.323160\n",
      "iteration 0 / 3000: loss 1.998973\n",
      "iteration 100 / 3000: loss 1.313513\n",
      "iteration 200 / 3000: loss 1.217917\n",
      "iteration 300 / 3000: loss 1.280090\n",
      "iteration 400 / 3000: loss 1.238757\n",
      "iteration 500 / 3000: loss 1.140609\n",
      "iteration 600 / 3000: loss 1.169340\n",
      "iteration 700 / 3000: loss 1.274993\n",
      "iteration 800 / 3000: loss 1.205535\n",
      "iteration 900 / 3000: loss 1.219615\n",
      "iteration 1000 / 3000: loss 1.206491\n",
      "iteration 1100 / 3000: loss 1.347241\n",
      "iteration 1200 / 3000: loss 1.270634\n",
      "iteration 1300 / 3000: loss 1.297440\n",
      "iteration 1400 / 3000: loss 1.261857\n",
      "iteration 1500 / 3000: loss 1.303217\n",
      "iteration 1600 / 3000: loss 1.251674\n",
      "iteration 1700 / 3000: loss 1.293325\n",
      "iteration 1800 / 3000: loss 1.204508\n",
      "iteration 1900 / 3000: loss 1.262909\n",
      "iteration 2000 / 3000: loss 1.174113\n",
      "iteration 2100 / 3000: loss 1.281039\n",
      "iteration 2200 / 3000: loss 1.313557\n",
      "iteration 2300 / 3000: loss 1.221424\n",
      "iteration 2400 / 3000: loss 1.182504\n",
      "iteration 2500 / 3000: loss 1.280726\n",
      "iteration 2600 / 3000: loss 1.294466\n",
      "iteration 2700 / 3000: loss 1.237361\n",
      "iteration 2800 / 3000: loss 1.230369\n",
      "iteration 2900 / 3000: loss 1.253452\n",
      "iteration 0 / 3000: loss 1.998356\n",
      "iteration 100 / 3000: loss 1.632713\n",
      "iteration 200 / 3000: loss 1.633209\n",
      "iteration 300 / 3000: loss 1.550012\n",
      "iteration 400 / 3000: loss 1.562610\n",
      "iteration 500 / 3000: loss 1.576869\n",
      "iteration 600 / 3000: loss 1.593898\n",
      "iteration 700 / 3000: loss 1.571415\n",
      "iteration 800 / 3000: loss 1.668481\n",
      "iteration 900 / 3000: loss 1.564019\n",
      "iteration 1000 / 3000: loss 1.615379\n",
      "iteration 1100 / 3000: loss 1.655238\n",
      "iteration 1200 / 3000: loss 1.573956\n",
      "iteration 1300 / 3000: loss 1.679637\n",
      "iteration 1400 / 3000: loss 1.606416\n",
      "iteration 1500 / 3000: loss 1.570769\n",
      "iteration 1600 / 3000: loss 1.630859\n",
      "iteration 1700 / 3000: loss 1.634757\n",
      "iteration 1800 / 3000: loss 1.612927\n",
      "iteration 1900 / 3000: loss 1.571079\n",
      "iteration 2000 / 3000: loss 1.652732\n",
      "iteration 2100 / 3000: loss 1.664155\n",
      "iteration 2200 / 3000: loss 1.591359\n",
      "iteration 2300 / 3000: loss 1.571176\n",
      "iteration 2400 / 3000: loss 1.694706\n",
      "iteration 2500 / 3000: loss 1.568172\n",
      "iteration 2600 / 3000: loss 1.620114\n",
      "iteration 2700 / 3000: loss 1.550294\n",
      "iteration 2800 / 3000: loss 1.650989\n",
      "iteration 2900 / 3000: loss 1.637529\n",
      "iteration 0 / 3000: loss 1.997462\n",
      "iteration 100 / 3000: loss 0.690523\n",
      "iteration 200 / 3000: loss 0.676402\n",
      "iteration 300 / 3000: loss 0.635810\n",
      "iteration 400 / 3000: loss 0.699656\n",
      "iteration 500 / 3000: loss 0.707889\n",
      "iteration 600 / 3000: loss 0.665617\n",
      "iteration 700 / 3000: loss 0.694764\n",
      "iteration 800 / 3000: loss 0.698521\n",
      "iteration 900 / 3000: loss 0.691182\n",
      "iteration 1000 / 3000: loss 0.642457\n",
      "iteration 1100 / 3000: loss 0.627934\n",
      "iteration 1200 / 3000: loss 0.611383\n",
      "iteration 1300 / 3000: loss 0.677465\n",
      "iteration 1400 / 3000: loss 0.693239\n",
      "iteration 1500 / 3000: loss 0.622174\n",
      "iteration 1600 / 3000: loss 0.672107\n",
      "iteration 1700 / 3000: loss 0.695719\n",
      "iteration 1800 / 3000: loss 0.627573\n",
      "iteration 1900 / 3000: loss 0.619902\n",
      "iteration 2000 / 3000: loss 0.649678\n",
      "iteration 2100 / 3000: loss 0.617904\n",
      "iteration 2200 / 3000: loss 0.677139\n",
      "iteration 2300 / 3000: loss 0.644612\n",
      "iteration 2400 / 3000: loss 0.653507\n",
      "iteration 2500 / 3000: loss 0.615808\n",
      "iteration 2600 / 3000: loss 0.703419\n",
      "iteration 2700 / 3000: loss 0.675967\n",
      "iteration 2800 / 3000: loss 0.721069\n",
      "iteration 2900 / 3000: loss 0.633864\n",
      "iteration 0 / 3000: loss 2.000503\n",
      "iteration 100 / 3000: loss 911.424636\n",
      "iteration 200 / 3000: loss 5266.194101\n",
      "iteration 300 / 3000: loss 13159.413764\n",
      "iteration 400 / 3000: loss 24536.184821\n",
      "iteration 500 / 3000: loss 39502.023481\n",
      "iteration 600 / 3000: loss 58138.750728\n",
      "iteration 700 / 3000: loss 80240.864658\n",
      "iteration 800 / 3000: loss 105666.430804\n",
      "iteration 900 / 3000: loss 134327.412413\n",
      "iteration 1000 / 3000: loss 166727.986595\n",
      "iteration 1100 / 3000: loss 202985.587025\n",
      "iteration 1200 / 3000: loss 242450.019001\n",
      "iteration 1300 / 3000: loss 285490.633753\n",
      "iteration 1400 / 3000: loss 332031.272880\n",
      "iteration 1500 / 3000: loss 382825.058780\n",
      "iteration 1600 / 3000: loss 437031.925821\n",
      "iteration 1700 / 3000: loss 494566.129972\n",
      "iteration 1800 / 3000: loss 555038.136565\n",
      "iteration 1900 / 3000: loss 619356.225194\n",
      "iteration 2000 / 3000: loss 688154.982584\n",
      "iteration 2100 / 3000: loss 759336.553988\n",
      "iteration 2200 / 3000: loss 835327.385283\n",
      "iteration 2300 / 3000: loss 913833.817639\n",
      "iteration 2400 / 3000: loss 996270.724833\n",
      "iteration 2500 / 3000: loss 1081763.607345\n",
      "iteration 2600 / 3000: loss 1171526.235304\n",
      "iteration 2700 / 3000: loss 1264382.527770\n",
      "iteration 2800 / 3000: loss 1360820.298545\n",
      "iteration 2900 / 3000: loss 1460823.041622\n",
      "iteration 0 / 3000: loss 1.998912\n",
      "iteration 100 / 3000: loss 0.393608\n",
      "iteration 200 / 3000: loss 0.356931\n",
      "iteration 300 / 3000: loss 0.323855\n",
      "iteration 400 / 3000: loss 0.424533\n",
      "iteration 500 / 3000: loss 0.351626\n",
      "iteration 600 / 3000: loss 0.368189\n",
      "iteration 700 / 3000: loss 0.281901\n",
      "iteration 800 / 3000: loss 0.301958\n",
      "iteration 900 / 3000: loss 0.314278\n",
      "iteration 1000 / 3000: loss 0.274753\n",
      "iteration 1100 / 3000: loss 0.371081\n",
      "iteration 1200 / 3000: loss 0.305659\n",
      "iteration 1300 / 3000: loss 0.295795\n",
      "iteration 1400 / 3000: loss 0.409710\n",
      "iteration 1500 / 3000: loss 0.351019\n",
      "iteration 1600 / 3000: loss 0.257772\n",
      "iteration 1700 / 3000: loss 0.281891\n",
      "iteration 1800 / 3000: loss 0.288188\n",
      "iteration 1900 / 3000: loss 0.311484\n",
      "iteration 2000 / 3000: loss 0.369644\n",
      "iteration 2100 / 3000: loss 0.291095\n",
      "iteration 2200 / 3000: loss 0.225263\n",
      "iteration 2300 / 3000: loss 0.339333\n",
      "iteration 2400 / 3000: loss 0.295506\n",
      "iteration 2500 / 3000: loss 0.389425\n",
      "iteration 2600 / 3000: loss 0.323828\n",
      "iteration 2700 / 3000: loss 0.336078\n",
      "iteration 2800 / 3000: loss 0.305571\n",
      "iteration 2900 / 3000: loss 0.290129\n",
      "iteration 0 / 3000: loss 1.999671\n",
      "iteration 100 / 3000: loss 0.470934\n",
      "iteration 200 / 3000: loss 0.353297\n",
      "iteration 300 / 3000: loss 0.379368\n",
      "iteration 400 / 3000: loss 0.324583\n",
      "iteration 500 / 3000: loss 0.277680\n",
      "iteration 600 / 3000: loss 0.292163\n",
      "iteration 700 / 3000: loss 0.335781\n",
      "iteration 800 / 3000: loss 0.342582\n",
      "iteration 900 / 3000: loss 0.334472\n",
      "iteration 1000 / 3000: loss 0.313663\n",
      "iteration 1100 / 3000: loss 0.387373\n",
      "iteration 1200 / 3000: loss 0.341832\n",
      "iteration 1300 / 3000: loss 0.355215\n",
      "iteration 1400 / 3000: loss 0.340286\n",
      "iteration 1500 / 3000: loss 0.292160\n",
      "iteration 1600 / 3000: loss 0.400512\n",
      "iteration 1700 / 3000: loss 0.243637\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration 1800 / 3000: loss 0.331016\n",
      "iteration 1900 / 3000: loss 0.314791\n",
      "iteration 2000 / 3000: loss 0.293327\n",
      "iteration 2100 / 3000: loss 0.275234\n",
      "iteration 2200 / 3000: loss 0.240000\n",
      "iteration 2300 / 3000: loss 0.243758\n",
      "iteration 2400 / 3000: loss 0.222391\n",
      "iteration 2500 / 3000: loss 0.273273\n",
      "iteration 2600 / 3000: loss 0.193621\n",
      "iteration 2700 / 3000: loss 0.358027\n",
      "iteration 2800 / 3000: loss 0.180489\n",
      "iteration 2900 / 3000: loss 0.211376\n",
      "iteration 0 / 3000: loss 2.001293\n",
      "iteration 100 / 3000: loss 0.511831\n",
      "iteration 200 / 3000: loss 0.455312\n",
      "iteration 300 / 3000: loss 0.465972\n",
      "iteration 400 / 3000: loss 0.536988\n",
      "iteration 500 / 3000: loss 0.530833\n",
      "iteration 600 / 3000: loss 0.427313\n",
      "iteration 700 / 3000: loss 0.564605\n",
      "iteration 800 / 3000: loss 0.501606\n",
      "iteration 900 / 3000: loss 0.493894\n",
      "iteration 1000 / 3000: loss 0.457187\n",
      "iteration 1100 / 3000: loss 0.532843\n",
      "iteration 1200 / 3000: loss 0.503619\n",
      "iteration 1300 / 3000: loss 0.448667\n",
      "iteration 1400 / 3000: loss 0.466908\n",
      "iteration 1500 / 3000: loss 0.572611\n",
      "iteration 1600 / 3000: loss 0.448635\n",
      "iteration 1700 / 3000: loss 0.486167\n",
      "iteration 1800 / 3000: loss 0.553000\n",
      "iteration 1900 / 3000: loss 0.542207\n",
      "iteration 2000 / 3000: loss 0.467147\n",
      "iteration 2100 / 3000: loss 0.441207\n",
      "iteration 2200 / 3000: loss 0.423524\n",
      "iteration 2300 / 3000: loss 0.411048\n",
      "iteration 2400 / 3000: loss 0.463559\n",
      "iteration 2500 / 3000: loss 0.504713\n",
      "iteration 2600 / 3000: loss 0.472128\n",
      "iteration 2700 / 3000: loss 0.469007\n",
      "iteration 2800 / 3000: loss 0.454676\n",
      "iteration 2900 / 3000: loss 0.487153\n",
      "iteration 0 / 3000: loss 2.002156\n",
      "iteration 100 / 3000: loss 0.875965\n",
      "iteration 200 / 3000: loss 0.971491\n",
      "iteration 300 / 3000: loss 0.903935\n",
      "iteration 400 / 3000: loss 0.876688\n",
      "iteration 500 / 3000: loss 0.913202\n",
      "iteration 600 / 3000: loss 0.939227\n",
      "iteration 700 / 3000: loss 0.951143\n",
      "iteration 800 / 3000: loss 0.968536\n",
      "iteration 900 / 3000: loss 0.953712\n",
      "iteration 1000 / 3000: loss 0.904672\n",
      "iteration 1100 / 3000: loss 0.898331\n",
      "iteration 1200 / 3000: loss 0.950213\n",
      "iteration 1300 / 3000: loss 0.947133\n",
      "iteration 1400 / 3000: loss 0.915000\n",
      "iteration 1500 / 3000: loss 0.942542\n",
      "iteration 1600 / 3000: loss 0.960331\n",
      "iteration 1700 / 3000: loss 0.882234\n",
      "iteration 1800 / 3000: loss 0.909761\n",
      "iteration 1900 / 3000: loss 0.941946\n",
      "iteration 2000 / 3000: loss 0.967349\n",
      "iteration 2100 / 3000: loss 0.923658\n",
      "iteration 2200 / 3000: loss 0.963548\n",
      "iteration 2300 / 3000: loss 0.861867\n",
      "iteration 2400 / 3000: loss 0.881079\n",
      "iteration 2500 / 3000: loss 0.966292\n",
      "iteration 2600 / 3000: loss 0.914434\n",
      "iteration 2700 / 3000: loss 0.824885\n",
      "iteration 2800 / 3000: loss 0.900282\n",
      "iteration 2900 / 3000: loss 0.873473\n",
      "iteration 0 / 3000: loss 2.001970\n",
      "iteration 100 / 3000: loss 0.418935\n",
      "iteration 200 / 3000: loss 0.376801\n",
      "iteration 300 / 3000: loss 0.382179\n",
      "iteration 400 / 3000: loss 0.303678\n",
      "iteration 500 / 3000: loss 0.317168\n",
      "iteration 600 / 3000: loss 0.396713\n",
      "iteration 700 / 3000: loss 0.317928\n",
      "iteration 800 / 3000: loss 0.349380\n",
      "iteration 900 / 3000: loss 0.399899\n",
      "iteration 1000 / 3000: loss 0.437475\n",
      "iteration 1100 / 3000: loss 0.393777\n",
      "iteration 1200 / 3000: loss 0.318525\n",
      "iteration 1300 / 3000: loss 0.431804\n",
      "iteration 1400 / 3000: loss 0.322629\n",
      "iteration 1500 / 3000: loss 0.330930\n",
      "iteration 1600 / 3000: loss 0.383959\n",
      "iteration 1700 / 3000: loss 0.387179\n",
      "iteration 1800 / 3000: loss 0.334070\n",
      "iteration 1900 / 3000: loss 0.407233\n",
      "iteration 2000 / 3000: loss 0.411283\n",
      "iteration 2100 / 3000: loss 0.303505\n",
      "iteration 2200 / 3000: loss 0.393919\n",
      "iteration 2300 / 3000: loss 0.395296\n",
      "iteration 2400 / 3000: loss 0.359489\n",
      "iteration 2500 / 3000: loss 0.361570\n",
      "iteration 2600 / 3000: loss 0.324136\n",
      "iteration 2700 / 3000: loss 0.310059\n",
      "iteration 2800 / 3000: loss 0.446344\n",
      "iteration 2900 / 3000: loss 0.411715\n",
      "iteration 0 / 3000: loss 1.999515\n",
      "iteration 100 / 3000: loss 0.425223\n",
      "iteration 200 / 3000: loss 0.329848\n",
      "iteration 300 / 3000: loss 0.315554\n",
      "iteration 400 / 3000: loss 0.307454\n",
      "iteration 500 / 3000: loss 0.274699\n",
      "iteration 600 / 3000: loss 0.248963\n",
      "iteration 700 / 3000: loss 0.347796\n",
      "iteration 800 / 3000: loss 0.303468\n",
      "iteration 900 / 3000: loss 0.291263\n",
      "iteration 1000 / 3000: loss 0.304821\n",
      "iteration 1100 / 3000: loss 0.367425\n",
      "iteration 1200 / 3000: loss 0.367737\n",
      "iteration 1300 / 3000: loss 0.326590\n",
      "iteration 1400 / 3000: loss 0.310010\n",
      "iteration 1500 / 3000: loss 0.186939\n",
      "iteration 1600 / 3000: loss 0.386101\n",
      "iteration 1700 / 3000: loss 0.286959\n",
      "iteration 1800 / 3000: loss 0.417041\n",
      "iteration 1900 / 3000: loss 0.315267\n",
      "iteration 2000 / 3000: loss 0.351655\n",
      "iteration 2100 / 3000: loss 0.381318\n",
      "iteration 2200 / 3000: loss 0.320591\n",
      "iteration 2300 / 3000: loss 0.328580\n",
      "iteration 2400 / 3000: loss 0.365632\n",
      "iteration 2500 / 3000: loss 0.295880\n",
      "iteration 2600 / 3000: loss 0.311738\n",
      "iteration 2700 / 3000: loss 0.366125\n",
      "iteration 2800 / 3000: loss 0.281508\n",
      "iteration 2900 / 3000: loss 0.297046\n",
      "iteration 0 / 3000: loss 1.996478\n",
      "iteration 100 / 3000: loss 1.235936\n",
      "iteration 200 / 3000: loss 1.282604\n",
      "iteration 300 / 3000: loss 1.278600\n",
      "iteration 400 / 3000: loss 1.216522\n",
      "iteration 500 / 3000: loss 1.239574\n",
      "iteration 600 / 3000: loss 1.280317\n",
      "iteration 700 / 3000: loss 1.203646\n",
      "iteration 800 / 3000: loss 1.350578\n",
      "iteration 900 / 3000: loss 1.327852\n",
      "iteration 1000 / 3000: loss 1.325088\n",
      "iteration 1100 / 3000: loss 1.247342\n",
      "iteration 1200 / 3000: loss 1.259105\n",
      "iteration 1300 / 3000: loss 1.246880\n",
      "iteration 1400 / 3000: loss 1.279363\n",
      "iteration 1500 / 3000: loss 1.263008\n",
      "iteration 1600 / 3000: loss 1.301754\n",
      "iteration 1700 / 3000: loss 1.093378\n",
      "iteration 1800 / 3000: loss 1.261651\n",
      "iteration 1900 / 3000: loss 1.212214\n",
      "iteration 2000 / 3000: loss 1.210143\n",
      "iteration 2100 / 3000: loss 1.324532\n",
      "iteration 2200 / 3000: loss 1.333763\n",
      "iteration 2300 / 3000: loss 1.247697\n",
      "iteration 2400 / 3000: loss 1.186512\n",
      "iteration 2500 / 3000: loss 1.295027\n",
      "iteration 2600 / 3000: loss 1.277608\n",
      "iteration 2700 / 3000: loss 1.151210\n",
      "iteration 2800 / 3000: loss 1.338030\n",
      "iteration 2900 / 3000: loss 1.289460\n",
      "iteration 0 / 3000: loss 1.998983\n",
      "iteration 100 / 3000: loss 1.643101\n",
      "iteration 200 / 3000: loss 1.621424\n",
      "iteration 300 / 3000: loss 1.595838\n",
      "iteration 400 / 3000: loss 1.620724\n",
      "iteration 500 / 3000: loss 1.642941\n",
      "iteration 600 / 3000: loss 1.686138\n",
      "iteration 700 / 3000: loss 1.622988\n",
      "iteration 800 / 3000: loss 1.576242\n",
      "iteration 900 / 3000: loss 1.653382\n",
      "iteration 1000 / 3000: loss 1.563042\n",
      "iteration 1100 / 3000: loss 1.692681\n",
      "iteration 1200 / 3000: loss 1.682192\n",
      "iteration 1300 / 3000: loss 1.631950\n",
      "iteration 1400 / 3000: loss 1.594203\n",
      "iteration 1500 / 3000: loss 1.608889\n",
      "iteration 1600 / 3000: loss 1.586164\n",
      "iteration 1700 / 3000: loss 1.666594\n",
      "iteration 1800 / 3000: loss 1.634681\n",
      "iteration 1900 / 3000: loss 1.653334\n",
      "iteration 2000 / 3000: loss 1.656697\n",
      "iteration 2100 / 3000: loss 1.600385\n",
      "iteration 2200 / 3000: loss 1.551725\n",
      "iteration 2300 / 3000: loss 1.653109\n",
      "iteration 2400 / 3000: loss 1.630132\n",
      "iteration 2500 / 3000: loss 1.612654\n",
      "iteration 2600 / 3000: loss 1.587920\n",
      "iteration 2700 / 3000: loss 1.683669\n",
      "iteration 2800 / 3000: loss 1.539791\n",
      "iteration 2900 / 3000: loss 1.691546\n",
      "iteration 0 / 3000: loss 1.999243\n",
      "iteration 100 / 3000: loss 0.650414\n",
      "iteration 200 / 3000: loss 0.673560\n",
      "iteration 300 / 3000: loss 0.663062\n",
      "iteration 400 / 3000: loss 0.635722\n",
      "iteration 500 / 3000: loss 0.648732\n",
      "iteration 600 / 3000: loss 0.611468\n",
      "iteration 700 / 3000: loss 0.665859\n",
      "iteration 800 / 3000: loss 0.650030\n",
      "iteration 900 / 3000: loss 0.700163\n",
      "iteration 1000 / 3000: loss 0.675167\n",
      "iteration 1100 / 3000: loss 0.693658\n",
      "iteration 1200 / 3000: loss 0.634383\n",
      "iteration 1300 / 3000: loss 0.644331\n",
      "iteration 1400 / 3000: loss 0.655953\n",
      "iteration 1500 / 3000: loss 0.685767\n",
      "iteration 1600 / 3000: loss 0.680795\n",
      "iteration 1700 / 3000: loss 0.624121\n",
      "iteration 1800 / 3000: loss 0.666576\n",
      "iteration 1900 / 3000: loss 0.670377\n",
      "iteration 2000 / 3000: loss 0.693221\n",
      "iteration 2100 / 3000: loss 0.638362\n",
      "iteration 2200 / 3000: loss 0.712870\n",
      "iteration 2300 / 3000: loss 0.650098\n",
      "iteration 2400 / 3000: loss 0.647261\n",
      "iteration 2500 / 3000: loss 0.637399\n",
      "iteration 2600 / 3000: loss 0.675533\n",
      "iteration 2700 / 3000: loss 0.665072\n",
      "iteration 2800 / 3000: loss 0.670297\n",
      "iteration 2900 / 3000: loss 0.722645\n",
      "iteration 0 / 3000: loss 1.997795\n",
      "iteration 100 / 3000: loss 2772840725207509903611305787795505054902069544702016201034901216474429386640433700439561891687178543218209753729949817672402948225499321891553280.000000\n",
      "iteration 200 / 3000: loss 50071850014889675345137992602173771822415828733315655014127655451627005026574285782300952021742880566239024119684511665477653078299701324422236732865816171992214969656871873789723042794809025394954029271087024456665003437240193217671066554712461810060387505516700979046407233221220135600128.000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/masterbin-iiau/考试题目/1/cs231n/classifiers/linear_svm.py:110: RuntimeWarning: overflow encountered in double_scalars\n",
      "  loss=np.sum(dists_p)/N+reg*np.sum(W*W)\n",
      "/home/masterbin-iiau/考试题目/1/cs231n/classifiers/linear_svm.py:110: RuntimeWarning: overflow encountered in multiply\n",
      "  loss=np.sum(dists_p)/N+reg*np.sum(W*W)\n",
      "/home/masterbin-iiau/anaconda3/lib/python3.6/site-packages/numpy/core/_methods.py:32: RuntimeWarning: overflow encountered in reduce\n",
      "  return umr_sum(a, axis, dtype, out, keepdims)\n",
      "/home/masterbin-iiau/考试题目/1/cs231n/classifiers/linear_svm.py:104: RuntimeWarning: overflow encountered in subtract\n",
      "  dists=score-correct_score+delta\n",
      "/home/masterbin-iiau/考试题目/1/cs231n/classifiers/linear_svm.py:108: RuntimeWarning: invalid value encountered in multiply\n",
      "  dists_p=dists*mask\n",
      "/home/masterbin-iiau/考试题目/1/cs231n/classifiers/linear_svm.py:119: RuntimeWarning: overflow encountered in multiply\n",
      "  dW=dW/N +2*reg*W\n",
      "/home/masterbin-iiau/考试题目/1/cs231n/classifiers/linear_svm.py:104: RuntimeWarning: invalid value encountered in subtract\n",
      "  dists=score-correct_score+delta\n",
      "/home/masterbin-iiau/考试题目/1/cs231n/classifiers/linear_svm.py:106: RuntimeWarning: invalid value encountered in greater\n",
      "  mask=(dists)>0\n",
      "/home/masterbin-iiau/考试题目/1/cs231n/classifiers/linear_classifier.py:70: RuntimeWarning: invalid value encountered in subtract\n",
      "  self.W-=learning_rate*grad\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration 300 / 3000: loss inf\n",
      "iteration 400 / 3000: loss inf\n",
      "iteration 500 / 3000: loss nan\n",
      "iteration 600 / 3000: loss nan\n",
      "iteration 700 / 3000: loss nan\n",
      "iteration 800 / 3000: loss nan\n",
      "iteration 900 / 3000: loss nan\n",
      "iteration 1000 / 3000: loss nan\n",
      "iteration 1100 / 3000: loss nan\n",
      "iteration 1200 / 3000: loss nan\n",
      "iteration 1300 / 3000: loss nan\n",
      "iteration 1400 / 3000: loss nan\n",
      "iteration 1500 / 3000: loss nan\n",
      "iteration 1600 / 3000: loss nan\n",
      "iteration 1700 / 3000: loss nan\n",
      "iteration 1800 / 3000: loss nan\n",
      "iteration 1900 / 3000: loss nan\n",
      "iteration 2000 / 3000: loss nan\n",
      "iteration 2100 / 3000: loss nan\n",
      "iteration 2200 / 3000: loss nan\n",
      "iteration 2300 / 3000: loss nan\n",
      "iteration 2400 / 3000: loss nan\n",
      "iteration 2500 / 3000: loss nan\n",
      "iteration 2600 / 3000: loss nan\n",
      "iteration 2700 / 3000: loss nan\n",
      "iteration 2800 / 3000: loss nan\n",
      "iteration 2900 / 3000: loss nan\n",
      "iteration 0 / 3000: loss 2.003072\n",
      "iteration 100 / 3000: loss 0.272144\n",
      "iteration 200 / 3000: loss 0.280598\n",
      "iteration 300 / 3000: loss 0.362857\n",
      "iteration 400 / 3000: loss 0.365236\n",
      "iteration 500 / 3000: loss 0.375182\n",
      "iteration 600 / 3000: loss 0.313014\n",
      "iteration 700 / 3000: loss 0.294217\n",
      "iteration 800 / 3000: loss 0.274373\n",
      "iteration 900 / 3000: loss 0.268770\n",
      "iteration 1000 / 3000: loss 0.260363\n",
      "iteration 1100 / 3000: loss 0.326996\n",
      "iteration 1200 / 3000: loss 0.295504\n",
      "iteration 1300 / 3000: loss 0.340334\n",
      "iteration 1400 / 3000: loss 0.182387\n",
      "iteration 1500 / 3000: loss 0.207917\n",
      "iteration 1600 / 3000: loss 0.209588\n",
      "iteration 1700 / 3000: loss 0.219484\n",
      "iteration 1800 / 3000: loss 0.321023\n",
      "iteration 1900 / 3000: loss 0.241203\n",
      "iteration 2000 / 3000: loss 0.209607\n",
      "iteration 2100 / 3000: loss 0.311462\n",
      "iteration 2200 / 3000: loss 0.199774\n",
      "iteration 2300 / 3000: loss 0.342767\n",
      "iteration 2400 / 3000: loss 0.301398\n",
      "iteration 2500 / 3000: loss 0.282761\n",
      "iteration 2600 / 3000: loss 0.295503\n",
      "iteration 2700 / 3000: loss 0.260025\n",
      "iteration 2800 / 3000: loss 0.282218\n",
      "iteration 2900 / 3000: loss 0.259070\n",
      "iteration 0 / 3000: loss 2.003730\n",
      "iteration 100 / 3000: loss 0.369167\n",
      "iteration 200 / 3000: loss 0.244841\n",
      "iteration 300 / 3000: loss 0.322160\n",
      "iteration 400 / 3000: loss 0.339059\n",
      "iteration 500 / 3000: loss 0.290874\n",
      "iteration 600 / 3000: loss 0.263951\n",
      "iteration 700 / 3000: loss 0.297128\n",
      "iteration 800 / 3000: loss 0.308497\n",
      "iteration 900 / 3000: loss 0.278544\n",
      "iteration 1000 / 3000: loss 0.204530\n",
      "iteration 1100 / 3000: loss 0.251919\n",
      "iteration 1200 / 3000: loss 0.285151\n",
      "iteration 1300 / 3000: loss 0.289645\n",
      "iteration 1400 / 3000: loss 0.280161\n",
      "iteration 1500 / 3000: loss 0.240951\n",
      "iteration 1600 / 3000: loss 0.265707\n",
      "iteration 1700 / 3000: loss 0.256799\n",
      "iteration 1800 / 3000: loss 0.237193\n",
      "iteration 1900 / 3000: loss 0.271871\n",
      "iteration 2000 / 3000: loss 0.284957\n",
      "iteration 2100 / 3000: loss 0.271849\n",
      "iteration 2200 / 3000: loss 0.312709\n",
      "iteration 2300 / 3000: loss 0.241501\n",
      "iteration 2400 / 3000: loss 0.276505\n",
      "iteration 2500 / 3000: loss 0.296485\n",
      "iteration 2600 / 3000: loss 0.373958\n",
      "iteration 2700 / 3000: loss 0.307096\n",
      "iteration 2800 / 3000: loss 0.250946\n",
      "iteration 2900 / 3000: loss 0.160226\n",
      "iteration 0 / 3000: loss 1.999570\n",
      "iteration 100 / 3000: loss 0.484938\n",
      "iteration 200 / 3000: loss 0.460015\n",
      "iteration 300 / 3000: loss 0.498572\n",
      "iteration 400 / 3000: loss 0.471844\n",
      "iteration 500 / 3000: loss 0.561000\n",
      "iteration 600 / 3000: loss 0.524993\n",
      "iteration 700 / 3000: loss 0.472242\n",
      "iteration 800 / 3000: loss 0.448454\n",
      "iteration 900 / 3000: loss 0.469587\n",
      "iteration 1000 / 3000: loss 0.488900\n",
      "iteration 1100 / 3000: loss 0.505324\n",
      "iteration 1200 / 3000: loss 0.416444\n",
      "iteration 1300 / 3000: loss 0.508408\n",
      "iteration 1400 / 3000: loss 0.562381\n",
      "iteration 1500 / 3000: loss 0.515118\n",
      "iteration 1600 / 3000: loss 0.540145\n",
      "iteration 1700 / 3000: loss 0.411113\n",
      "iteration 1800 / 3000: loss 0.499126\n",
      "iteration 1900 / 3000: loss 0.482023\n",
      "iteration 2000 / 3000: loss 0.561525\n",
      "iteration 2100 / 3000: loss 0.561941\n",
      "iteration 2200 / 3000: loss 0.472651\n",
      "iteration 2300 / 3000: loss 0.576993\n",
      "iteration 2400 / 3000: loss 0.479507\n",
      "iteration 2500 / 3000: loss 0.447805\n",
      "iteration 2600 / 3000: loss 0.396827\n",
      "iteration 2700 / 3000: loss 0.549077\n",
      "iteration 2800 / 3000: loss 0.459209\n",
      "iteration 2900 / 3000: loss 0.518878\n",
      "iteration 0 / 3000: loss 2.001165\n",
      "iteration 100 / 3000: loss 0.916611\n",
      "iteration 200 / 3000: loss 0.990365\n",
      "iteration 300 / 3000: loss 0.884909\n",
      "iteration 400 / 3000: loss 0.882618\n",
      "iteration 500 / 3000: loss 0.936378\n",
      "iteration 600 / 3000: loss 0.983338\n",
      "iteration 700 / 3000: loss 0.925931\n",
      "iteration 800 / 3000: loss 0.904925\n",
      "iteration 900 / 3000: loss 0.971441\n",
      "iteration 1000 / 3000: loss 0.941303\n",
      "iteration 1100 / 3000: loss 0.959283\n",
      "iteration 1200 / 3000: loss 0.964110\n",
      "iteration 1300 / 3000: loss 0.911300\n",
      "iteration 1400 / 3000: loss 0.886962\n",
      "iteration 1500 / 3000: loss 0.952924\n",
      "iteration 1600 / 3000: loss 0.959773\n",
      "iteration 1700 / 3000: loss 0.948709\n",
      "iteration 1800 / 3000: loss 0.957198\n",
      "iteration 1900 / 3000: loss 0.925717\n",
      "iteration 2000 / 3000: loss 0.884743\n",
      "iteration 2100 / 3000: loss 0.948280\n",
      "iteration 2200 / 3000: loss 0.938974\n",
      "iteration 2300 / 3000: loss 0.867475\n",
      "iteration 2400 / 3000: loss 0.935815\n",
      "iteration 2500 / 3000: loss 1.022273\n",
      "iteration 2600 / 3000: loss 0.924094\n",
      "iteration 2700 / 3000: loss 0.945766\n",
      "iteration 2800 / 3000: loss 0.914902\n",
      "iteration 2900 / 3000: loss 0.887174\n",
      "iteration 0 / 3000: loss 2.002256\n",
      "iteration 100 / 3000: loss 0.382596\n",
      "iteration 200 / 3000: loss 0.380805\n",
      "iteration 300 / 3000: loss 0.401443\n",
      "iteration 400 / 3000: loss 0.390803\n",
      "iteration 500 / 3000: loss 0.291573\n",
      "iteration 600 / 3000: loss 0.337638\n",
      "iteration 700 / 3000: loss 0.421283\n",
      "iteration 800 / 3000: loss 0.433628\n",
      "iteration 900 / 3000: loss 0.330572\n",
      "iteration 1000 / 3000: loss 0.386469\n",
      "iteration 1100 / 3000: loss 0.367535\n",
      "iteration 1200 / 3000: loss 0.439292\n",
      "iteration 1300 / 3000: loss 0.326992\n",
      "iteration 1400 / 3000: loss 0.447253\n",
      "iteration 1500 / 3000: loss 0.408836\n",
      "iteration 1600 / 3000: loss 0.438910\n",
      "iteration 1700 / 3000: loss 0.387777\n",
      "iteration 1800 / 3000: loss 0.350954\n",
      "iteration 1900 / 3000: loss 0.421428\n",
      "iteration 2000 / 3000: loss 0.362008\n",
      "iteration 2100 / 3000: loss 0.405944\n",
      "iteration 2200 / 3000: loss 0.313397\n",
      "iteration 2300 / 3000: loss 0.378449\n",
      "iteration 2400 / 3000: loss 0.429560\n",
      "iteration 2500 / 3000: loss 0.350077\n",
      "iteration 2600 / 3000: loss 0.420616\n",
      "iteration 2700 / 3000: loss 0.334905\n",
      "iteration 2800 / 3000: loss 0.420570\n",
      "iteration 2900 / 3000: loss 0.396178\n",
      "iteration 0 / 3000: loss 2.003504\n",
      "iteration 100 / 3000: loss 0.346333\n",
      "iteration 200 / 3000: loss 0.390493\n",
      "iteration 300 / 3000: loss 0.337066\n",
      "iteration 400 / 3000: loss 0.308513\n",
      "iteration 500 / 3000: loss 0.333446\n",
      "iteration 600 / 3000: loss 0.330044\n",
      "iteration 700 / 3000: loss 0.372039\n",
      "iteration 800 / 3000: loss 0.285691\n",
      "iteration 900 / 3000: loss 0.384415\n",
      "iteration 1000 / 3000: loss 0.286591\n",
      "iteration 1100 / 3000: loss 0.343190\n",
      "iteration 1200 / 3000: loss 0.385964\n",
      "iteration 1300 / 3000: loss 0.326287\n",
      "iteration 1400 / 3000: loss 0.324366\n",
      "iteration 1500 / 3000: loss 0.333705\n",
      "iteration 1600 / 3000: loss 0.345907\n",
      "iteration 1700 / 3000: loss 0.309509\n",
      "iteration 1800 / 3000: loss 0.320856\n",
      "iteration 1900 / 3000: loss 0.427257\n",
      "iteration 2000 / 3000: loss 0.393011\n",
      "iteration 2100 / 3000: loss 0.303090\n",
      "iteration 2200 / 3000: loss 0.332898\n",
      "iteration 2300 / 3000: loss 0.252163\n",
      "iteration 2400 / 3000: loss 0.285015\n",
      "iteration 2500 / 3000: loss 0.279915\n",
      "iteration 2600 / 3000: loss 0.305256\n",
      "iteration 2700 / 3000: loss 0.318735\n",
      "iteration 2800 / 3000: loss 0.336581\n",
      "iteration 2900 / 3000: loss 0.307536\n",
      "iteration 0 / 3000: loss 2.001703\n",
      "iteration 100 / 3000: loss 1.330084\n",
      "iteration 200 / 3000: loss 1.288844\n",
      "iteration 300 / 3000: loss 1.201644\n",
      "iteration 400 / 3000: loss 1.216251\n",
      "iteration 500 / 3000: loss 1.286005\n",
      "iteration 600 / 3000: loss 1.211527\n",
      "iteration 700 / 3000: loss 1.285595\n",
      "iteration 800 / 3000: loss 1.246562\n",
      "iteration 900 / 3000: loss 1.242506\n",
      "iteration 1000 / 3000: loss 1.316386\n",
      "iteration 1100 / 3000: loss 1.316541\n",
      "iteration 1200 / 3000: loss 1.348439\n",
      "iteration 1300 / 3000: loss 1.222738\n",
      "iteration 1400 / 3000: loss 1.278447\n",
      "iteration 1500 / 3000: loss 1.382492\n",
      "iteration 1600 / 3000: loss 1.299735\n",
      "iteration 1700 / 3000: loss 1.226745\n",
      "iteration 1800 / 3000: loss 1.265002\n",
      "iteration 1900 / 3000: loss 1.285901\n",
      "iteration 2000 / 3000: loss 1.284544\n",
      "iteration 2100 / 3000: loss 1.232557\n",
      "iteration 2200 / 3000: loss 1.257660\n",
      "iteration 2300 / 3000: loss 1.268533\n",
      "iteration 2400 / 3000: loss 1.260169\n",
      "iteration 2500 / 3000: loss 1.343934\n",
      "iteration 2600 / 3000: loss 1.241053\n",
      "iteration 2700 / 3000: loss 1.270367\n",
      "iteration 2800 / 3000: loss 1.149296\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration 2900 / 3000: loss 1.239793\n",
      "iteration 0 / 3000: loss 2.002186\n",
      "iteration 100 / 3000: loss 11.131561\n",
      "iteration 200 / 3000: loss 11.395680\n",
      "iteration 300 / 3000: loss 11.782408\n",
      "iteration 400 / 3000: loss 11.252688\n",
      "iteration 500 / 3000: loss 11.392756\n",
      "iteration 600 / 3000: loss 11.626854\n",
      "iteration 700 / 3000: loss 11.061445\n",
      "iteration 800 / 3000: loss 11.748031\n",
      "iteration 900 / 3000: loss 11.144211\n",
      "iteration 1000 / 3000: loss 11.469313\n",
      "iteration 1100 / 3000: loss 11.968446\n",
      "iteration 1200 / 3000: loss 11.634964\n",
      "iteration 1300 / 3000: loss 12.039000\n",
      "iteration 1400 / 3000: loss 11.671348\n",
      "iteration 1500 / 3000: loss 11.794362\n",
      "iteration 1600 / 3000: loss 10.218463\n",
      "iteration 1700 / 3000: loss 10.868138\n",
      "iteration 1800 / 3000: loss 10.342094\n",
      "iteration 1900 / 3000: loss 11.729817\n",
      "iteration 2000 / 3000: loss 10.617890\n",
      "iteration 2100 / 3000: loss 10.752226\n",
      "iteration 2200 / 3000: loss 10.521413\n",
      "iteration 2300 / 3000: loss 11.916141\n",
      "iteration 2400 / 3000: loss 10.136950\n",
      "iteration 2500 / 3000: loss 11.428260\n",
      "iteration 2600 / 3000: loss 11.448219\n",
      "iteration 2700 / 3000: loss 11.208337\n",
      "iteration 2800 / 3000: loss 11.272506\n",
      "iteration 2900 / 3000: loss 10.966366\n",
      "iteration 0 / 3000: loss 1.996684\n",
      "iteration 100 / 3000: loss 0.666765\n",
      "iteration 200 / 3000: loss 0.711943\n",
      "iteration 300 / 3000: loss 0.664782\n",
      "iteration 400 / 3000: loss 0.653023\n",
      "iteration 500 / 3000: loss 0.655962\n",
      "iteration 600 / 3000: loss 0.737656\n",
      "iteration 700 / 3000: loss 0.659068\n",
      "iteration 800 / 3000: loss 0.770903\n",
      "iteration 900 / 3000: loss 0.657233\n",
      "iteration 1000 / 3000: loss 0.669246\n",
      "iteration 1100 / 3000: loss 0.755834\n",
      "iteration 1200 / 3000: loss 0.772746\n",
      "iteration 1300 / 3000: loss 0.693412\n",
      "iteration 1400 / 3000: loss 0.688008\n",
      "iteration 1500 / 3000: loss 0.667748\n",
      "iteration 1600 / 3000: loss 0.714309\n",
      "iteration 1700 / 3000: loss 0.688325\n",
      "iteration 1800 / 3000: loss 0.657676\n",
      "iteration 1900 / 3000: loss 0.650626\n",
      "iteration 2000 / 3000: loss 0.619394\n",
      "iteration 2100 / 3000: loss 0.721521\n",
      "iteration 2200 / 3000: loss 0.671191\n",
      "iteration 2300 / 3000: loss 0.693918\n",
      "iteration 2400 / 3000: loss 0.782914\n",
      "iteration 2500 / 3000: loss 0.689443\n",
      "iteration 2600 / 3000: loss 0.661263\n",
      "iteration 2700 / 3000: loss 0.658590\n",
      "iteration 2800 / 3000: loss 0.702978\n",
      "iteration 2900 / 3000: loss 0.704598\n",
      "iteration 0 / 3000: loss 2.001379\n",
      "iteration 100 / 3000: loss 681161586594480904130109313164408636280310510679829305957487130954077297865215610880562202773822905877480265018673133962377735720011415964389651203261342880746240708667469317979602488308377609993163366246436997977705637336155723869209850433721087505203200.000000\n",
      "iteration 200 / 3000: loss inf\n",
      "iteration 300 / 3000: loss nan\n",
      "iteration 400 / 3000: loss nan\n",
      "iteration 500 / 3000: loss nan\n",
      "iteration 600 / 3000: loss nan\n",
      "iteration 700 / 3000: loss nan\n",
      "iteration 800 / 3000: loss nan\n",
      "iteration 900 / 3000: loss nan\n",
      "iteration 1000 / 3000: loss nan\n",
      "iteration 1100 / 3000: loss nan\n",
      "iteration 1200 / 3000: loss nan\n",
      "iteration 1300 / 3000: loss nan\n",
      "iteration 1400 / 3000: loss nan\n",
      "iteration 1500 / 3000: loss nan\n",
      "iteration 1600 / 3000: loss nan\n",
      "iteration 1700 / 3000: loss nan\n",
      "iteration 1800 / 3000: loss nan\n",
      "iteration 1900 / 3000: loss nan\n",
      "iteration 2000 / 3000: loss nan\n",
      "iteration 2100 / 3000: loss nan\n",
      "iteration 2200 / 3000: loss nan\n",
      "iteration 2300 / 3000: loss nan\n",
      "iteration 2400 / 3000: loss nan\n",
      "iteration 2500 / 3000: loss nan\n",
      "iteration 2600 / 3000: loss nan\n",
      "iteration 2700 / 3000: loss nan\n",
      "iteration 2800 / 3000: loss nan\n",
      "iteration 2900 / 3000: loss nan\n",
      "iteration 0 / 3000: loss 1.999199\n",
      "iteration 100 / 3000: loss 0.285995\n",
      "iteration 200 / 3000: loss 0.291341\n",
      "iteration 300 / 3000: loss 0.278974\n",
      "iteration 400 / 3000: loss 0.313399\n",
      "iteration 500 / 3000: loss 0.267595\n",
      "iteration 600 / 3000: loss 0.330814\n",
      "iteration 700 / 3000: loss 0.319698\n",
      "iteration 800 / 3000: loss 0.355772\n",
      "iteration 900 / 3000: loss 0.375172\n",
      "iteration 1000 / 3000: loss 0.285748\n",
      "iteration 1100 / 3000: loss 0.243890\n",
      "iteration 1200 / 3000: loss 0.276852\n",
      "iteration 1300 / 3000: loss 0.310032\n",
      "iteration 1400 / 3000: loss 0.293197\n",
      "iteration 1500 / 3000: loss 0.322450\n",
      "iteration 1600 / 3000: loss 0.213395\n",
      "iteration 1700 / 3000: loss 0.204835\n",
      "iteration 1800 / 3000: loss 0.280726\n",
      "iteration 1900 / 3000: loss 0.226487\n",
      "iteration 2000 / 3000: loss 0.327849\n",
      "iteration 2100 / 3000: loss 0.288881\n",
      "iteration 2200 / 3000: loss 0.296241\n",
      "iteration 2300 / 3000: loss 0.234543\n",
      "iteration 2400 / 3000: loss 0.341445\n",
      "iteration 2500 / 3000: loss 0.260722\n",
      "iteration 2600 / 3000: loss 0.327313\n",
      "iteration 2700 / 3000: loss 0.291337\n",
      "iteration 2800 / 3000: loss 0.372282\n",
      "iteration 2900 / 3000: loss 0.301770\n",
      "iteration 0 / 3000: loss 1.996777\n",
      "iteration 100 / 3000: loss 0.234755\n",
      "iteration 200 / 3000: loss 0.300611\n",
      "iteration 300 / 3000: loss 0.294709\n",
      "iteration 400 / 3000: loss 0.280008\n",
      "iteration 500 / 3000: loss 0.333310\n",
      "iteration 600 / 3000: loss 0.170742\n",
      "iteration 700 / 3000: loss 0.299311\n",
      "iteration 800 / 3000: loss 0.365737\n",
      "iteration 900 / 3000: loss 0.269619\n",
      "iteration 1000 / 3000: loss 0.323292\n",
      "iteration 1100 / 3000: loss 0.262870\n",
      "iteration 1200 / 3000: loss 0.215199\n",
      "iteration 1300 / 3000: loss 0.285731\n",
      "iteration 1400 / 3000: loss 0.254392\n",
      "iteration 1500 / 3000: loss 0.248367\n",
      "iteration 1600 / 3000: loss 0.206477\n",
      "iteration 1700 / 3000: loss 0.320505\n",
      "iteration 1800 / 3000: loss 0.266537\n",
      "iteration 1900 / 3000: loss 0.276267\n",
      "iteration 2000 / 3000: loss 0.226659\n",
      "iteration 2100 / 3000: loss 0.233723\n",
      "iteration 2200 / 3000: loss 0.266946\n",
      "iteration 2300 / 3000: loss 0.341450\n",
      "iteration 2400 / 3000: loss 0.247457\n",
      "iteration 2500 / 3000: loss 0.327584\n",
      "iteration 2600 / 3000: loss 0.316085\n",
      "iteration 2700 / 3000: loss 0.257874\n",
      "iteration 2800 / 3000: loss 0.207466\n",
      "iteration 2900 / 3000: loss 0.322258\n",
      "iteration 0 / 3000: loss 2.001902\n",
      "iteration 100 / 3000: loss 0.473495\n",
      "iteration 200 / 3000: loss 0.489070\n",
      "iteration 300 / 3000: loss 0.547339\n",
      "iteration 400 / 3000: loss 0.512416\n",
      "iteration 500 / 3000: loss 0.505146\n",
      "iteration 600 / 3000: loss 0.511380\n",
      "iteration 700 / 3000: loss 0.447850\n",
      "iteration 800 / 3000: loss 0.480880\n",
      "iteration 900 / 3000: loss 0.470748\n",
      "iteration 1000 / 3000: loss 0.584002\n",
      "iteration 1100 / 3000: loss 0.523498\n",
      "iteration 1200 / 3000: loss 0.531791\n",
      "iteration 1300 / 3000: loss 0.467053\n",
      "iteration 1400 / 3000: loss 0.493728\n",
      "iteration 1500 / 3000: loss 0.445884\n",
      "iteration 1600 / 3000: loss 0.582241\n",
      "iteration 1700 / 3000: loss 0.504791\n",
      "iteration 1800 / 3000: loss 0.481486\n",
      "iteration 1900 / 3000: loss 0.451752\n",
      "iteration 2000 / 3000: loss 0.511765\n",
      "iteration 2100 / 3000: loss 0.549235\n",
      "iteration 2200 / 3000: loss 0.455712\n",
      "iteration 2300 / 3000: loss 0.469043\n",
      "iteration 2400 / 3000: loss 0.538269\n",
      "iteration 2500 / 3000: loss 0.539896\n",
      "iteration 2600 / 3000: loss 0.596499\n",
      "iteration 2700 / 3000: loss 0.556410\n",
      "iteration 2800 / 3000: loss 0.504961\n",
      "iteration 2900 / 3000: loss 0.473378\n",
      "iteration 0 / 3000: loss 2.000392\n",
      "iteration 100 / 3000: loss 0.958669\n",
      "iteration 200 / 3000: loss 1.086736\n",
      "iteration 300 / 3000: loss 1.016836\n",
      "iteration 400 / 3000: loss 1.076693\n",
      "iteration 500 / 3000: loss 1.171966\n",
      "iteration 600 / 3000: loss 1.052667\n",
      "iteration 700 / 3000: loss 1.164406\n",
      "iteration 800 / 3000: loss 1.112462\n",
      "iteration 900 / 3000: loss 1.250346\n",
      "iteration 1000 / 3000: loss 0.976670\n",
      "iteration 1100 / 3000: loss 1.090917\n",
      "iteration 1200 / 3000: loss 1.166230\n",
      "iteration 1300 / 3000: loss 1.206306\n",
      "iteration 1400 / 3000: loss 1.002674\n",
      "iteration 1500 / 3000: loss 1.051625\n",
      "iteration 1600 / 3000: loss 1.019841\n",
      "iteration 1700 / 3000: loss 1.147246\n",
      "iteration 1800 / 3000: loss 1.086061\n",
      "iteration 1900 / 3000: loss 1.019580\n",
      "iteration 2000 / 3000: loss 1.072173\n",
      "iteration 2100 / 3000: loss 1.295380\n",
      "iteration 2200 / 3000: loss 1.042857\n",
      "iteration 2300 / 3000: loss 0.996434\n",
      "iteration 2400 / 3000: loss 1.091857\n",
      "iteration 2500 / 3000: loss 1.151384\n",
      "iteration 2600 / 3000: loss 1.138702\n",
      "iteration 2700 / 3000: loss 1.249292\n",
      "iteration 2800 / 3000: loss 1.166519\n",
      "iteration 2900 / 3000: loss 1.042621\n",
      "iteration 0 / 3000: loss 2.001110\n",
      "iteration 100 / 3000: loss 0.394600\n",
      "iteration 200 / 3000: loss 0.398835\n",
      "iteration 300 / 3000: loss 0.416063\n",
      "iteration 400 / 3000: loss 0.259644\n",
      "iteration 500 / 3000: loss 0.445152\n",
      "iteration 600 / 3000: loss 0.446643\n",
      "iteration 700 / 3000: loss 0.393386\n",
      "iteration 800 / 3000: loss 0.345043\n",
      "iteration 900 / 3000: loss 0.451804\n",
      "iteration 1000 / 3000: loss 0.428086\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration 1100 / 3000: loss 0.332803\n",
      "iteration 1200 / 3000: loss 0.353819\n",
      "iteration 1300 / 3000: loss 0.366922\n",
      "iteration 1400 / 3000: loss 0.422283\n",
      "iteration 1500 / 3000: loss 0.502958\n",
      "iteration 1600 / 3000: loss 0.399897\n",
      "iteration 1700 / 3000: loss 0.316488\n",
      "iteration 1800 / 3000: loss 0.419360\n",
      "iteration 1900 / 3000: loss 0.408566\n",
      "iteration 2000 / 3000: loss 0.317431\n",
      "iteration 2100 / 3000: loss 0.312912\n",
      "iteration 2200 / 3000: loss 0.400854\n",
      "iteration 2300 / 3000: loss 0.307689\n",
      "iteration 2400 / 3000: loss 0.447615\n",
      "iteration 2500 / 3000: loss 0.441288\n",
      "iteration 2600 / 3000: loss 0.371355\n",
      "iteration 2700 / 3000: loss 0.345399\n",
      "iteration 2800 / 3000: loss 0.444856\n",
      "iteration 2900 / 3000: loss 0.399130\n",
      "iteration 0 / 3000: loss 2.002544\n",
      "iteration 100 / 3000: loss 0.315958\n",
      "iteration 200 / 3000: loss 0.253084\n",
      "iteration 300 / 3000: loss 0.363972\n",
      "iteration 400 / 3000: loss 0.315487\n",
      "iteration 500 / 3000: loss 0.365556\n",
      "iteration 600 / 3000: loss 0.357066\n",
      "iteration 700 / 3000: loss 0.298853\n",
      "iteration 800 / 3000: loss 0.248935\n",
      "iteration 900 / 3000: loss 0.338298\n",
      "iteration 1000 / 3000: loss 0.355973\n",
      "iteration 1100 / 3000: loss 0.360762\n",
      "iteration 1200 / 3000: loss 0.367089\n",
      "iteration 1300 / 3000: loss 0.374000\n",
      "iteration 1400 / 3000: loss 0.376000\n",
      "iteration 1500 / 3000: loss 0.315353\n",
      "iteration 1600 / 3000: loss 0.318139\n",
      "iteration 1700 / 3000: loss 0.351889\n",
      "iteration 1800 / 3000: loss 0.335516\n",
      "iteration 1900 / 3000: loss 0.244013\n",
      "iteration 2000 / 3000: loss 0.331737\n",
      "iteration 2100 / 3000: loss 0.332010\n",
      "iteration 2200 / 3000: loss 0.320183\n",
      "iteration 2300 / 3000: loss 0.364518\n",
      "iteration 2400 / 3000: loss 0.346445\n",
      "iteration 2500 / 3000: loss 0.345483\n",
      "iteration 2600 / 3000: loss 0.365748\n",
      "iteration 2700 / 3000: loss 0.283335\n",
      "iteration 2800 / 3000: loss 0.293115\n",
      "iteration 2900 / 3000: loss 0.315902\n",
      "iteration 0 / 3000: loss 1.998966\n",
      "iteration 100 / 3000: loss 10.371322\n",
      "iteration 200 / 3000: loss 11.228153\n",
      "iteration 300 / 3000: loss 10.666288\n",
      "iteration 400 / 3000: loss 10.850935\n",
      "iteration 500 / 3000: loss 10.049626\n",
      "iteration 600 / 3000: loss 10.968841\n",
      "iteration 700 / 3000: loss 11.159442\n",
      "iteration 800 / 3000: loss 10.424362\n",
      "iteration 900 / 3000: loss 11.326145\n",
      "iteration 1000 / 3000: loss 10.782579\n",
      "iteration 1100 / 3000: loss 10.773690\n",
      "iteration 1200 / 3000: loss 10.872390\n",
      "iteration 1300 / 3000: loss 11.086923\n",
      "iteration 1400 / 3000: loss 10.566104\n",
      "iteration 1500 / 3000: loss 11.101578\n",
      "iteration 1600 / 3000: loss 10.514183\n",
      "iteration 1700 / 3000: loss 10.157713\n",
      "iteration 1800 / 3000: loss 10.679063\n",
      "iteration 1900 / 3000: loss 11.478650\n",
      "iteration 2000 / 3000: loss 10.344512\n",
      "iteration 2100 / 3000: loss 10.552097\n",
      "iteration 2200 / 3000: loss 11.073060\n",
      "iteration 2300 / 3000: loss 11.801095\n",
      "iteration 2400 / 3000: loss 11.178767\n",
      "iteration 2500 / 3000: loss 10.775368\n",
      "iteration 2600 / 3000: loss 10.698468\n",
      "iteration 2700 / 3000: loss 12.846797\n",
      "iteration 2800 / 3000: loss 11.776390\n",
      "iteration 2900 / 3000: loss 10.987291\n",
      "iteration 0 / 3000: loss 2.002198\n",
      "iteration 100 / 3000: loss 592045990155870125665452279811671256028015916105574547349949228560509995145726860814642071378103688266085239060436987450355705970688.000000\n",
      "iteration 200 / 3000: loss 460015321738861535659232967177180479660114406763346145640668500472045023873281861668787150251337279985272930261645740581395440248045313719834579360557258839820388255050525681827952904874452482608924165450003175802585631385662064317090574109246015205880094959599616.000000\n",
      "iteration 300 / 3000: loss inf\n",
      "iteration 400 / 3000: loss inf\n",
      "iteration 500 / 3000: loss nan\n",
      "iteration 600 / 3000: loss nan\n",
      "iteration 700 / 3000: loss nan\n",
      "iteration 800 / 3000: loss nan\n",
      "iteration 900 / 3000: loss nan\n",
      "iteration 1000 / 3000: loss nan\n",
      "iteration 1100 / 3000: loss nan\n",
      "iteration 1200 / 3000: loss nan\n",
      "iteration 1300 / 3000: loss nan\n",
      "iteration 1400 / 3000: loss nan\n",
      "iteration 1500 / 3000: loss nan\n",
      "iteration 1600 / 3000: loss nan\n",
      "iteration 1700 / 3000: loss nan\n",
      "iteration 1800 / 3000: loss nan\n",
      "iteration 1900 / 3000: loss nan\n",
      "iteration 2000 / 3000: loss nan\n",
      "iteration 2100 / 3000: loss nan\n",
      "iteration 2200 / 3000: loss nan\n",
      "iteration 2300 / 3000: loss nan\n",
      "iteration 2400 / 3000: loss nan\n",
      "iteration 2500 / 3000: loss nan\n",
      "iteration 2600 / 3000: loss nan\n",
      "iteration 2700 / 3000: loss nan\n",
      "iteration 2800 / 3000: loss nan\n",
      "iteration 2900 / 3000: loss nan\n",
      "iteration 0 / 3000: loss 1.998626\n",
      "iteration 100 / 3000: loss 1.578076\n",
      "iteration 200 / 3000: loss 1.654474\n",
      "iteration 300 / 3000: loss 1.635858\n",
      "iteration 400 / 3000: loss 1.889532\n",
      "iteration 500 / 3000: loss 1.696969\n",
      "iteration 600 / 3000: loss 1.351863\n",
      "iteration 700 / 3000: loss 1.825221\n",
      "iteration 800 / 3000: loss 2.020095\n",
      "iteration 900 / 3000: loss 1.541356\n",
      "iteration 1000 / 3000: loss 1.520644\n",
      "iteration 1100 / 3000: loss 1.696574\n",
      "iteration 1200 / 3000: loss 1.527843\n",
      "iteration 1300 / 3000: loss 1.602799\n",
      "iteration 1400 / 3000: loss 1.626475\n",
      "iteration 1500 / 3000: loss 1.718299\n",
      "iteration 1600 / 3000: loss 1.486432\n",
      "iteration 1700 / 3000: loss 1.448869\n",
      "iteration 1800 / 3000: loss 1.500759\n",
      "iteration 1900 / 3000: loss 1.618669\n",
      "iteration 2000 / 3000: loss 1.696155\n",
      "iteration 2100 / 3000: loss 1.784709\n",
      "iteration 2200 / 3000: loss 1.657490\n",
      "iteration 2300 / 3000: loss 1.515388\n",
      "iteration 2400 / 3000: loss 2.207603\n",
      "iteration 2500 / 3000: loss 1.784677\n",
      "iteration 2600 / 3000: loss 0.963697\n",
      "iteration 2700 / 3000: loss 1.921140\n",
      "iteration 2800 / 3000: loss 1.768658\n",
      "iteration 2900 / 3000: loss 2.058971\n",
      "iteration 0 / 3000: loss 1.999794\n",
      "iteration 100 / 3000: loss inf\n",
      "iteration 200 / 3000: loss nan\n",
      "iteration 300 / 3000: loss nan\n",
      "iteration 400 / 3000: loss nan\n",
      "iteration 500 / 3000: loss nan\n",
      "iteration 600 / 3000: loss nan\n",
      "iteration 700 / 3000: loss nan\n",
      "iteration 800 / 3000: loss nan\n",
      "iteration 900 / 3000: loss nan\n",
      "iteration 1000 / 3000: loss nan\n",
      "iteration 1100 / 3000: loss nan\n",
      "iteration 1200 / 3000: loss nan\n",
      "iteration 1300 / 3000: loss nan\n",
      "iteration 1400 / 3000: loss nan\n",
      "iteration 1500 / 3000: loss nan\n",
      "iteration 1600 / 3000: loss nan\n",
      "iteration 1700 / 3000: loss nan\n",
      "iteration 1800 / 3000: loss nan\n",
      "iteration 1900 / 3000: loss nan\n",
      "iteration 2000 / 3000: loss nan\n",
      "iteration 2100 / 3000: loss nan\n",
      "iteration 2200 / 3000: loss nan\n",
      "iteration 2300 / 3000: loss nan\n",
      "iteration 2400 / 3000: loss nan\n",
      "iteration 2500 / 3000: loss nan\n",
      "iteration 2600 / 3000: loss nan\n",
      "iteration 2700 / 3000: loss nan\n",
      "iteration 2800 / 3000: loss nan\n",
      "iteration 2900 / 3000: loss nan\n",
      "iteration 0 / 3000: loss 2.002870\n",
      "iteration 100 / 3000: loss 0.297791\n",
      "iteration 200 / 3000: loss 0.376773\n",
      "iteration 300 / 3000: loss 0.270585\n",
      "iteration 400 / 3000: loss 0.264866\n",
      "iteration 500 / 3000: loss 0.337919\n",
      "iteration 600 / 3000: loss 0.368142\n",
      "iteration 700 / 3000: loss 0.319696\n",
      "iteration 800 / 3000: loss 0.354034\n",
      "iteration 900 / 3000: loss 0.381598\n",
      "iteration 1000 / 3000: loss 0.355281\n",
      "iteration 1100 / 3000: loss 0.398919\n",
      "iteration 1200 / 3000: loss 0.331165\n",
      "iteration 1300 / 3000: loss 0.294903\n",
      "iteration 1400 / 3000: loss 0.401785\n",
      "iteration 1500 / 3000: loss 0.256150\n",
      "iteration 1600 / 3000: loss 0.361791\n",
      "iteration 1700 / 3000: loss 0.225218\n",
      "iteration 1800 / 3000: loss 0.261414\n",
      "iteration 1900 / 3000: loss 0.360086\n",
      "iteration 2000 / 3000: loss 0.275496\n",
      "iteration 2100 / 3000: loss 0.273340\n",
      "iteration 2200 / 3000: loss 0.322169\n",
      "iteration 2300 / 3000: loss 0.382042\n",
      "iteration 2400 / 3000: loss 0.264318\n",
      "iteration 2500 / 3000: loss 0.388191\n",
      "iteration 2600 / 3000: loss 0.460025\n",
      "iteration 2700 / 3000: loss 0.508295\n",
      "iteration 2800 / 3000: loss 0.334040\n",
      "iteration 2900 / 3000: loss 0.316938\n",
      "iteration 0 / 3000: loss 1.998638\n",
      "iteration 100 / 3000: loss 0.276079\n",
      "iteration 200 / 3000: loss 0.226485\n",
      "iteration 300 / 3000: loss 0.297315\n",
      "iteration 400 / 3000: loss 0.320766\n",
      "iteration 500 / 3000: loss 0.303061\n",
      "iteration 600 / 3000: loss 0.306637\n",
      "iteration 700 / 3000: loss 0.261925\n",
      "iteration 800 / 3000: loss 0.295476\n",
      "iteration 900 / 3000: loss 0.203021\n",
      "iteration 1000 / 3000: loss 0.157604\n",
      "iteration 1100 / 3000: loss 0.321997\n",
      "iteration 1200 / 3000: loss 0.263165\n",
      "iteration 1300 / 3000: loss 0.427861\n",
      "iteration 1400 / 3000: loss 0.299583\n",
      "iteration 1500 / 3000: loss 0.362093\n",
      "iteration 1600 / 3000: loss 0.320633\n",
      "iteration 1700 / 3000: loss 0.263210\n",
      "iteration 1800 / 3000: loss 0.356964\n",
      "iteration 1900 / 3000: loss 0.193821\n",
      "iteration 2000 / 3000: loss 0.347003\n",
      "iteration 2100 / 3000: loss 0.255809\n",
      "iteration 2200 / 3000: loss 0.260636\n",
      "iteration 2300 / 3000: loss 0.292193\n",
      "iteration 2400 / 3000: loss 0.334794\n",
      "iteration 2500 / 3000: loss 0.312023\n",
      "iteration 2600 / 3000: loss 0.208824\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration 2700 / 3000: loss 0.266988\n",
      "iteration 2800 / 3000: loss 0.307398\n",
      "iteration 2900 / 3000: loss 0.230700\n",
      "iteration 0 / 3000: loss 1.999483\n",
      "iteration 100 / 3000: loss 1.035486\n",
      "iteration 200 / 3000: loss 0.811694\n",
      "iteration 300 / 3000: loss 1.061656\n",
      "iteration 400 / 3000: loss 0.730275\n",
      "iteration 500 / 3000: loss 0.949234\n",
      "iteration 600 / 3000: loss 0.571783\n",
      "iteration 700 / 3000: loss 0.702019\n",
      "iteration 800 / 3000: loss 0.606467\n",
      "iteration 900 / 3000: loss 0.622066\n",
      "iteration 1000 / 3000: loss 0.631645\n",
      "iteration 1100 / 3000: loss 0.665265\n",
      "iteration 1200 / 3000: loss 0.573715\n",
      "iteration 1300 / 3000: loss 0.735915\n",
      "iteration 1400 / 3000: loss 0.513508\n",
      "iteration 1500 / 3000: loss 0.597662\n",
      "iteration 1600 / 3000: loss 0.622962\n",
      "iteration 1700 / 3000: loss 0.636748\n",
      "iteration 1800 / 3000: loss 0.580274\n",
      "iteration 1900 / 3000: loss 0.618997\n",
      "iteration 2000 / 3000: loss 0.799216\n",
      "iteration 2100 / 3000: loss 0.621917\n",
      "iteration 2200 / 3000: loss 0.530982\n",
      "iteration 2300 / 3000: loss 0.847939\n",
      "iteration 2400 / 3000: loss 0.591391\n",
      "iteration 2500 / 3000: loss 0.661167\n",
      "iteration 2600 / 3000: loss 1.019592\n",
      "iteration 2700 / 3000: loss 0.583075\n",
      "iteration 2800 / 3000: loss 0.888078\n",
      "iteration 2900 / 3000: loss 0.665344\n",
      "iteration 0 / 3000: loss 2.003623\n",
      "iteration 100 / 3000: loss 16.022434\n",
      "iteration 200 / 3000: loss 13.787838\n",
      "iteration 300 / 3000: loss 15.714106\n",
      "iteration 400 / 3000: loss 15.591896\n",
      "iteration 500 / 3000: loss 16.184629\n",
      "iteration 600 / 3000: loss 15.407984\n",
      "iteration 700 / 3000: loss 14.740909\n",
      "iteration 800 / 3000: loss 17.491188\n",
      "iteration 900 / 3000: loss 14.247521\n",
      "iteration 1000 / 3000: loss 15.194078\n",
      "iteration 1100 / 3000: loss 14.838488\n",
      "iteration 1200 / 3000: loss 16.363948\n",
      "iteration 1300 / 3000: loss 17.252401\n",
      "iteration 1400 / 3000: loss 14.812000\n",
      "iteration 1500 / 3000: loss 15.616808\n",
      "iteration 1600 / 3000: loss 16.562163\n",
      "iteration 1700 / 3000: loss 15.529035\n",
      "iteration 1800 / 3000: loss 15.292619\n",
      "iteration 1900 / 3000: loss 14.695523\n",
      "iteration 2000 / 3000: loss 16.800045\n",
      "iteration 2100 / 3000: loss 15.592566\n",
      "iteration 2200 / 3000: loss 15.512176\n",
      "iteration 2300 / 3000: loss 17.273209\n",
      "iteration 2400 / 3000: loss 15.054670\n",
      "iteration 2500 / 3000: loss 14.387297\n",
      "iteration 2600 / 3000: loss 16.440866\n",
      "iteration 2700 / 3000: loss 16.830417\n",
      "iteration 2800 / 3000: loss 16.177781\n",
      "iteration 2900 / 3000: loss 17.068827\n",
      "iteration 0 / 3000: loss 2.000379\n",
      "iteration 100 / 3000: loss 0.442333\n",
      "iteration 200 / 3000: loss 0.365427\n",
      "iteration 300 / 3000: loss 0.548799\n",
      "iteration 400 / 3000: loss 0.533716\n",
      "iteration 500 / 3000: loss 0.768840\n",
      "iteration 600 / 3000: loss 0.358987\n",
      "iteration 700 / 3000: loss 0.351671\n",
      "iteration 800 / 3000: loss 0.351940\n",
      "iteration 900 / 3000: loss 0.401702\n",
      "iteration 1000 / 3000: loss 0.447271\n",
      "iteration 1100 / 3000: loss 0.518151\n",
      "iteration 1200 / 3000: loss 0.385308\n",
      "iteration 1300 / 3000: loss 0.465497\n",
      "iteration 1400 / 3000: loss 0.343600\n",
      "iteration 1500 / 3000: loss 0.753627\n",
      "iteration 1600 / 3000: loss 0.472267\n",
      "iteration 1700 / 3000: loss 0.523032\n",
      "iteration 1800 / 3000: loss 0.673995\n",
      "iteration 1900 / 3000: loss 0.536532\n",
      "iteration 2000 / 3000: loss 0.397709\n",
      "iteration 2100 / 3000: loss 0.468971\n",
      "iteration 2200 / 3000: loss 0.460313\n",
      "iteration 2300 / 3000: loss 0.724525\n",
      "iteration 2400 / 3000: loss 0.484300\n",
      "iteration 2500 / 3000: loss 0.490409\n",
      "iteration 2600 / 3000: loss 0.379241\n",
      "iteration 2700 / 3000: loss 0.419114\n",
      "iteration 2800 / 3000: loss 0.402024\n",
      "iteration 2900 / 3000: loss 0.667730\n",
      "iteration 0 / 3000: loss 2.002336\n",
      "iteration 100 / 3000: loss 0.301761\n",
      "iteration 200 / 3000: loss 0.350278\n",
      "iteration 300 / 3000: loss 0.315433\n",
      "iteration 400 / 3000: loss 0.365883\n",
      "iteration 500 / 3000: loss 0.239189\n",
      "iteration 600 / 3000: loss 0.575554\n",
      "iteration 700 / 3000: loss 0.240083\n",
      "iteration 800 / 3000: loss 0.270324\n",
      "iteration 900 / 3000: loss 0.415704\n",
      "iteration 1000 / 3000: loss 0.388447\n",
      "iteration 1100 / 3000: loss 0.392571\n",
      "iteration 1200 / 3000: loss 0.408642\n",
      "iteration 1300 / 3000: loss 0.366815\n",
      "iteration 1400 / 3000: loss 0.387183\n",
      "iteration 1500 / 3000: loss 0.259274\n",
      "iteration 1600 / 3000: loss 0.268670\n",
      "iteration 1700 / 3000: loss 0.393861\n",
      "iteration 1800 / 3000: loss 0.433748\n",
      "iteration 1900 / 3000: loss 0.440792\n",
      "iteration 2000 / 3000: loss 0.346559\n",
      "iteration 2100 / 3000: loss 0.305597\n",
      "iteration 2200 / 3000: loss 0.457005\n",
      "iteration 2300 / 3000: loss 0.369976\n",
      "iteration 2400 / 3000: loss 0.357726\n",
      "iteration 2500 / 3000: loss 0.318966\n",
      "iteration 2600 / 3000: loss 0.381166\n",
      "iteration 2700 / 3000: loss 0.380426\n",
      "iteration 2800 / 3000: loss 0.436548\n",
      "iteration 2900 / 3000: loss 0.432881\n",
      "iteration 0 / 3000: loss 2.001352\n",
      "iteration 100 / 3000: loss 38537178434332112700272496357986824343668653688646611680344772068358116169961394093820747612001951321872215928710627328.000000\n",
      "iteration 200 / 3000: loss 535971096370284814375953014807959730732106545363563048818315094819194552590535677968231025073269503446281498596726749473551098724363946042756412160751868569724202179036102813686211794145647905488238651237362030624984244237709640567095296.000000\n",
      "iteration 300 / 3000: loss inf\n",
      "iteration 400 / 3000: loss inf\n",
      "iteration 500 / 3000: loss inf\n",
      "iteration 600 / 3000: loss nan\n",
      "iteration 700 / 3000: loss nan\n",
      "iteration 800 / 3000: loss nan\n",
      "iteration 900 / 3000: loss nan\n",
      "iteration 1000 / 3000: loss nan\n",
      "iteration 1100 / 3000: loss nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/masterbin-iiau/考试题目/1/cs231n/classifiers/linear_classifier.py:70: RuntimeWarning: overflow encountered in multiply\n",
      "  self.W-=learning_rate*grad\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration 1200 / 3000: loss nan\n",
      "iteration 1300 / 3000: loss nan\n",
      "iteration 1400 / 3000: loss nan\n",
      "iteration 1500 / 3000: loss nan\n",
      "iteration 1600 / 3000: loss nan\n",
      "iteration 1700 / 3000: loss nan\n",
      "iteration 1800 / 3000: loss nan\n",
      "iteration 1900 / 3000: loss nan\n",
      "iteration 2000 / 3000: loss nan\n",
      "iteration 2100 / 3000: loss nan\n",
      "iteration 2200 / 3000: loss nan\n",
      "iteration 2300 / 3000: loss nan\n",
      "iteration 2400 / 3000: loss nan\n",
      "iteration 2500 / 3000: loss nan\n",
      "iteration 2600 / 3000: loss nan\n",
      "iteration 2700 / 3000: loss nan\n",
      "iteration 2800 / 3000: loss nan\n",
      "iteration 2900 / 3000: loss nan\n",
      "iteration 0 / 3000: loss 1.997658\n",
      "iteration 100 / 3000: loss 4717284802897347273806894304155151728435181992551763338485004406012964787982517241130026595343828750074343880508396856789040269962974658620669730491496822578342470277873046272086010786975324763744178199462911026938313779297833196162812831858688.000000\n",
      "iteration 200 / 3000: loss inf\n",
      "iteration 300 / 3000: loss nan\n",
      "iteration 400 / 3000: loss nan\n",
      "iteration 500 / 3000: loss nan\n",
      "iteration 600 / 3000: loss nan\n",
      "iteration 700 / 3000: loss nan\n",
      "iteration 800 / 3000: loss nan\n",
      "iteration 900 / 3000: loss nan\n",
      "iteration 1000 / 3000: loss nan\n",
      "iteration 1100 / 3000: loss nan\n",
      "iteration 1200 / 3000: loss nan\n",
      "iteration 1300 / 3000: loss nan\n",
      "iteration 1400 / 3000: loss nan\n",
      "iteration 1500 / 3000: loss nan\n",
      "iteration 1600 / 3000: loss nan\n",
      "iteration 1700 / 3000: loss nan\n",
      "iteration 1800 / 3000: loss nan\n",
      "iteration 1900 / 3000: loss nan\n",
      "iteration 2000 / 3000: loss nan\n",
      "iteration 2100 / 3000: loss nan\n",
      "iteration 2200 / 3000: loss nan\n",
      "iteration 2300 / 3000: loss nan\n",
      "iteration 2400 / 3000: loss nan\n",
      "iteration 2500 / 3000: loss nan\n",
      "iteration 2600 / 3000: loss nan\n",
      "iteration 2700 / 3000: loss nan\n",
      "iteration 2800 / 3000: loss nan\n",
      "iteration 2900 / 3000: loss nan\n",
      "iteration 0 / 3000: loss 2.000062\n",
      "iteration 100 / 3000: loss 25.251041\n",
      "iteration 200 / 3000: loss 30.515844\n",
      "iteration 300 / 3000: loss 22.461893\n",
      "iteration 400 / 3000: loss 26.018653\n",
      "iteration 500 / 3000: loss 25.080906\n",
      "iteration 600 / 3000: loss 26.377963\n",
      "iteration 700 / 3000: loss 24.113994\n",
      "iteration 800 / 3000: loss 24.983459\n",
      "iteration 900 / 3000: loss 24.475635\n",
      "iteration 1000 / 3000: loss 26.221531\n",
      "iteration 1100 / 3000: loss 26.621263\n",
      "iteration 1200 / 3000: loss 22.157332\n",
      "iteration 1300 / 3000: loss 25.922889\n",
      "iteration 1400 / 3000: loss 23.408830\n",
      "iteration 1500 / 3000: loss 25.805805\n",
      "iteration 1600 / 3000: loss 25.583131\n",
      "iteration 1700 / 3000: loss 25.215934\n",
      "iteration 1800 / 3000: loss 27.991860\n",
      "iteration 1900 / 3000: loss 23.987651\n",
      "iteration 2000 / 3000: loss 24.438428\n",
      "iteration 2100 / 3000: loss 28.321859\n",
      "iteration 2200 / 3000: loss 22.216960\n",
      "iteration 2300 / 3000: loss 25.251017\n",
      "iteration 2400 / 3000: loss 23.621188\n",
      "iteration 2500 / 3000: loss 23.846801\n",
      "iteration 2600 / 3000: loss 24.775882\n",
      "iteration 2700 / 3000: loss 21.743583\n",
      "iteration 2800 / 3000: loss 25.904315\n",
      "iteration 2900 / 3000: loss 26.618571\n",
      "iteration 0 / 3000: loss 1.996873\n",
      "iteration 100 / 3000: loss inf\n",
      "iteration 200 / 3000: loss nan\n",
      "iteration 300 / 3000: loss nan\n",
      "iteration 400 / 3000: loss nan\n",
      "iteration 500 / 3000: loss nan\n",
      "iteration 600 / 3000: loss nan\n",
      "iteration 700 / 3000: loss nan\n",
      "iteration 800 / 3000: loss nan\n",
      "iteration 900 / 3000: loss nan\n",
      "iteration 1000 / 3000: loss nan\n",
      "iteration 1100 / 3000: loss nan\n",
      "iteration 1200 / 3000: loss nan\n",
      "iteration 1300 / 3000: loss nan\n",
      "iteration 1400 / 3000: loss nan\n",
      "iteration 1500 / 3000: loss nan\n",
      "iteration 1600 / 3000: loss nan\n",
      "iteration 1700 / 3000: loss nan\n",
      "iteration 1800 / 3000: loss nan\n",
      "iteration 1900 / 3000: loss nan\n",
      "iteration 2000 / 3000: loss nan\n",
      "iteration 2100 / 3000: loss nan\n",
      "iteration 2200 / 3000: loss nan\n",
      "iteration 2300 / 3000: loss nan\n",
      "iteration 2400 / 3000: loss nan\n",
      "iteration 2500 / 3000: loss nan\n",
      "iteration 2600 / 3000: loss nan\n",
      "iteration 2700 / 3000: loss nan\n",
      "iteration 2800 / 3000: loss nan\n",
      "iteration 2900 / 3000: loss nan\n",
      "iteration 0 / 3000: loss 1.999677\n",
      "iteration 100 / 3000: loss 0.541307\n",
      "iteration 200 / 3000: loss 1.032273\n",
      "iteration 300 / 3000: loss 0.565499\n",
      "iteration 400 / 3000: loss 0.502335\n",
      "iteration 500 / 3000: loss 0.477524\n",
      "iteration 600 / 3000: loss 1.673628\n",
      "iteration 700 / 3000: loss 0.427427\n",
      "iteration 800 / 3000: loss 1.149574\n",
      "iteration 900 / 3000: loss 0.627143\n",
      "iteration 1000 / 3000: loss 2.102163\n",
      "iteration 1100 / 3000: loss 0.468110\n",
      "iteration 1200 / 3000: loss 0.733774\n",
      "iteration 1300 / 3000: loss 0.322756\n",
      "iteration 1400 / 3000: loss 1.828650\n",
      "iteration 1500 / 3000: loss 1.606416\n",
      "iteration 1600 / 3000: loss 0.430116\n",
      "iteration 1700 / 3000: loss 0.478467\n",
      "iteration 1800 / 3000: loss 0.474479\n",
      "iteration 1900 / 3000: loss 0.675768\n",
      "iteration 2000 / 3000: loss 0.529605\n",
      "iteration 2100 / 3000: loss 0.534052\n",
      "iteration 2200 / 3000: loss 0.475212\n",
      "iteration 2300 / 3000: loss 0.468688\n",
      "iteration 2400 / 3000: loss 0.393608\n",
      "iteration 2500 / 3000: loss 0.492393\n",
      "iteration 2600 / 3000: loss 0.530452\n",
      "iteration 2700 / 3000: loss 0.787958\n",
      "iteration 2800 / 3000: loss 0.460371\n",
      "iteration 2900 / 3000: loss 0.970229\n",
      "iteration 0 / 3000: loss 1.999743\n",
      "iteration 100 / 3000: loss 0.940265\n",
      "iteration 200 / 3000: loss 0.295257\n",
      "iteration 300 / 3000: loss 0.468364\n",
      "iteration 400 / 3000: loss 0.276837\n",
      "iteration 500 / 3000: loss 0.470090\n",
      "iteration 600 / 3000: loss 0.526343\n",
      "iteration 700 / 3000: loss 0.423504\n",
      "iteration 800 / 3000: loss 0.456259\n",
      "iteration 900 / 3000: loss 0.535587\n",
      "iteration 1000 / 3000: loss 0.597606\n",
      "iteration 1100 / 3000: loss 0.500401\n",
      "iteration 1200 / 3000: loss 1.239083\n",
      "iteration 1300 / 3000: loss 0.265767\n",
      "iteration 1400 / 3000: loss 0.493562\n",
      "iteration 1500 / 3000: loss 0.178294\n",
      "iteration 1600 / 3000: loss 0.415346\n",
      "iteration 1700 / 3000: loss 0.392925\n",
      "iteration 1800 / 3000: loss 0.425731\n",
      "iteration 1900 / 3000: loss 1.145449\n",
      "iteration 2000 / 3000: loss 0.508172\n",
      "iteration 2100 / 3000: loss 0.290460\n",
      "iteration 2200 / 3000: loss 0.351296\n",
      "iteration 2300 / 3000: loss 0.412996\n",
      "iteration 2400 / 3000: loss 0.980206\n",
      "iteration 2500 / 3000: loss 0.318832\n",
      "iteration 2600 / 3000: loss 0.518499\n",
      "iteration 2700 / 3000: loss 0.668629\n",
      "iteration 2800 / 3000: loss 0.403515\n",
      "iteration 2900 / 3000: loss 0.359068\n",
      "iteration 0 / 3000: loss 2.002480\n",
      "iteration 100 / 3000: loss 3.619564\n",
      "iteration 200 / 3000: loss 3.709166\n",
      "iteration 300 / 3000: loss 4.038425\n",
      "iteration 400 / 3000: loss 2.698897\n",
      "iteration 500 / 3000: loss 3.959959\n",
      "iteration 600 / 3000: loss 2.888109\n",
      "iteration 700 / 3000: loss 0.979457\n",
      "iteration 800 / 3000: loss 4.566537\n",
      "iteration 900 / 3000: loss 2.442174\n",
      "iteration 1000 / 3000: loss 4.867157\n",
      "iteration 1100 / 3000: loss 1.936530\n",
      "iteration 1200 / 3000: loss 1.556770\n",
      "iteration 1300 / 3000: loss 3.267897\n",
      "iteration 1400 / 3000: loss 6.234663\n",
      "iteration 1500 / 3000: loss 1.731305\n",
      "iteration 1600 / 3000: loss 3.182724\n",
      "iteration 1700 / 3000: loss 5.711921\n",
      "iteration 1800 / 3000: loss 0.970228\n",
      "iteration 1900 / 3000: loss 2.931665\n",
      "iteration 2000 / 3000: loss 3.123297\n",
      "iteration 2100 / 3000: loss 5.258935\n",
      "iteration 2200 / 3000: loss 4.223854\n",
      "iteration 2300 / 3000: loss 3.507691\n",
      "iteration 2400 / 3000: loss 2.718713\n",
      "iteration 2500 / 3000: loss 3.032961\n",
      "iteration 2600 / 3000: loss 3.507993\n",
      "iteration 2700 / 3000: loss 4.260047\n",
      "iteration 2800 / 3000: loss 3.258250\n",
      "iteration 2900 / 3000: loss 1.881085\n",
      "iteration 0 / 3000: loss 2.001483\n",
      "iteration 100 / 3000: loss 889118553774220394211073265776517226457980452054654775391720087871020979495108529532098129189712701685760.000000\n",
      "iteration 200 / 3000: loss 76715718502708136211971842172951023083156691351144871318948110968514730924818561550748026181598032156178819088304841039508581940141198027029090554066036175082075699191496735856183013974785367953433456187277312.000000\n",
      "iteration 300 / 3000: loss inf\n",
      "iteration 400 / 3000: loss inf\n",
      "iteration 500 / 3000: loss inf\n",
      "iteration 600 / 3000: loss nan\n",
      "iteration 700 / 3000: loss nan\n",
      "iteration 800 / 3000: loss nan\n",
      "iteration 900 / 3000: loss nan\n",
      "iteration 1000 / 3000: loss nan\n",
      "iteration 1100 / 3000: loss nan\n",
      "iteration 1200 / 3000: loss nan\n",
      "iteration 1300 / 3000: loss nan\n",
      "iteration 1400 / 3000: loss nan\n",
      "iteration 1500 / 3000: loss nan\n",
      "iteration 1600 / 3000: loss nan\n",
      "iteration 1700 / 3000: loss nan\n",
      "iteration 1800 / 3000: loss nan\n",
      "iteration 1900 / 3000: loss nan\n",
      "iteration 2000 / 3000: loss nan\n",
      "iteration 2100 / 3000: loss nan\n",
      "iteration 2200 / 3000: loss nan\n",
      "iteration 2300 / 3000: loss nan\n",
      "iteration 2400 / 3000: loss nan\n",
      "iteration 2500 / 3000: loss nan\n",
      "iteration 2600 / 3000: loss nan\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration 2700 / 3000: loss nan\n",
      "iteration 2800 / 3000: loss nan\n",
      "iteration 2900 / 3000: loss nan\n",
      "iteration 0 / 3000: loss 1.999880\n",
      "iteration 100 / 3000: loss 1.157546\n",
      "iteration 200 / 3000: loss 2.698476\n",
      "iteration 300 / 3000: loss 1.760611\n",
      "iteration 400 / 3000: loss 2.106645\n",
      "iteration 500 / 3000: loss 2.139890\n",
      "iteration 600 / 3000: loss 3.347858\n",
      "iteration 700 / 3000: loss 3.534207\n",
      "iteration 800 / 3000: loss 1.619746\n",
      "iteration 900 / 3000: loss 2.219942\n",
      "iteration 1000 / 3000: loss 1.646773\n",
      "iteration 1100 / 3000: loss 1.164680\n",
      "iteration 1200 / 3000: loss 1.796331\n",
      "iteration 1300 / 3000: loss 3.162156\n",
      "iteration 1400 / 3000: loss 0.632445\n",
      "iteration 1500 / 3000: loss 1.081569\n",
      "iteration 1600 / 3000: loss 0.802846\n",
      "iteration 1700 / 3000: loss 2.772981\n",
      "iteration 1800 / 3000: loss 2.507096\n",
      "iteration 1900 / 3000: loss 1.884811\n",
      "iteration 2000 / 3000: loss 1.867212\n",
      "iteration 2100 / 3000: loss 3.738914\n",
      "iteration 2200 / 3000: loss 0.626421\n",
      "iteration 2300 / 3000: loss 1.189264\n",
      "iteration 2400 / 3000: loss 1.318452\n",
      "iteration 2500 / 3000: loss 2.229286\n",
      "iteration 2600 / 3000: loss 1.587468\n",
      "iteration 2700 / 3000: loss 0.952870\n",
      "iteration 2800 / 3000: loss 0.812435\n",
      "iteration 2900 / 3000: loss 0.631729\n",
      "iteration 0 / 3000: loss 1.999041\n",
      "iteration 100 / 3000: loss 0.663130\n",
      "iteration 200 / 3000: loss 0.975840\n",
      "iteration 300 / 3000: loss 0.440847\n",
      "iteration 400 / 3000: loss 0.964851\n",
      "iteration 500 / 3000: loss 0.594518\n",
      "iteration 600 / 3000: loss 1.177558\n",
      "iteration 700 / 3000: loss 1.356923\n",
      "iteration 800 / 3000: loss 0.454800\n",
      "iteration 900 / 3000: loss 0.518467\n",
      "iteration 1000 / 3000: loss 0.821989\n",
      "iteration 1100 / 3000: loss 0.736506\n",
      "iteration 1200 / 3000: loss 0.704884\n",
      "iteration 1300 / 3000: loss 0.497753\n",
      "iteration 1400 / 3000: loss 0.544685\n",
      "iteration 1500 / 3000: loss 0.631404\n",
      "iteration 1600 / 3000: loss 0.521292\n",
      "iteration 1700 / 3000: loss 0.906837\n",
      "iteration 1800 / 3000: loss 0.555460\n",
      "iteration 1900 / 3000: loss 0.917207\n",
      "iteration 2000 / 3000: loss 0.313495\n",
      "iteration 2100 / 3000: loss 2.190833\n",
      "iteration 2200 / 3000: loss 1.034156\n",
      "iteration 2300 / 3000: loss 0.482133\n",
      "iteration 2400 / 3000: loss 0.843618\n",
      "iteration 2500 / 3000: loss 0.889916\n",
      "iteration 2600 / 3000: loss 0.866654\n",
      "iteration 2700 / 3000: loss 0.664402\n",
      "iteration 2800 / 3000: loss 0.813519\n",
      "iteration 2900 / 3000: loss 0.608772\n",
      "iteration 0 / 3000: loss 1.998940\n",
      "iteration 100 / 3000: loss 23162977823113796788495244798426196588843181175212739920755862198872812867835133912602618103604853634215226615557212894444873729145093812445669578503019319463702266818163333018208341330382180825625658029676490649461110189078788177920.000000\n",
      "iteration 200 / 3000: loss inf\n",
      "iteration 300 / 3000: loss nan\n",
      "iteration 400 / 3000: loss nan\n",
      "iteration 500 / 3000: loss nan\n",
      "iteration 600 / 3000: loss nan\n",
      "iteration 700 / 3000: loss nan\n",
      "iteration 800 / 3000: loss nan\n",
      "iteration 900 / 3000: loss nan\n",
      "iteration 1000 / 3000: loss nan\n",
      "iteration 1100 / 3000: loss nan\n",
      "iteration 1200 / 3000: loss nan\n",
      "iteration 1300 / 3000: loss nan\n",
      "iteration 1400 / 3000: loss nan\n",
      "iteration 1500 / 3000: loss nan\n",
      "iteration 1600 / 3000: loss nan\n",
      "iteration 1700 / 3000: loss nan\n",
      "iteration 1800 / 3000: loss nan\n",
      "iteration 1900 / 3000: loss nan\n",
      "iteration 2000 / 3000: loss nan\n",
      "iteration 2100 / 3000: loss nan\n",
      "iteration 2200 / 3000: loss nan\n",
      "iteration 2300 / 3000: loss nan\n",
      "iteration 2400 / 3000: loss nan\n",
      "iteration 2500 / 3000: loss nan\n",
      "iteration 2600 / 3000: loss nan\n",
      "iteration 2700 / 3000: loss nan\n",
      "iteration 2800 / 3000: loss nan\n",
      "iteration 2900 / 3000: loss nan\n",
      "iteration 0 / 3000: loss 1.998167\n",
      "iteration 100 / 3000: loss inf\n",
      "iteration 200 / 3000: loss nan\n",
      "iteration 300 / 3000: loss nan\n",
      "iteration 400 / 3000: loss nan\n",
      "iteration 500 / 3000: loss nan\n",
      "iteration 600 / 3000: loss nan\n",
      "iteration 700 / 3000: loss nan\n",
      "iteration 800 / 3000: loss nan\n",
      "iteration 900 / 3000: loss nan\n",
      "iteration 1000 / 3000: loss nan\n",
      "iteration 1100 / 3000: loss nan\n",
      "iteration 1200 / 3000: loss nan\n",
      "iteration 1300 / 3000: loss nan\n",
      "iteration 1400 / 3000: loss nan\n",
      "iteration 1500 / 3000: loss nan\n",
      "iteration 1600 / 3000: loss nan\n",
      "iteration 1700 / 3000: loss nan\n",
      "iteration 1800 / 3000: loss nan\n",
      "iteration 1900 / 3000: loss nan\n",
      "iteration 2000 / 3000: loss nan\n",
      "iteration 2100 / 3000: loss nan\n",
      "iteration 2200 / 3000: loss nan\n",
      "iteration 2300 / 3000: loss nan\n",
      "iteration 2400 / 3000: loss nan\n",
      "iteration 2500 / 3000: loss nan\n",
      "iteration 2600 / 3000: loss nan\n",
      "iteration 2700 / 3000: loss nan\n",
      "iteration 2800 / 3000: loss nan\n",
      "iteration 2900 / 3000: loss nan\n",
      "lr 3.162278e-04 reg 1.000000e-04 train accuracy: 0.693333\n",
      "lr 3.162278e-04 reg 3.593814e-04 train accuracy: 0.693333\n",
      "lr 3.162278e-04 reg 1.291550e-03 train accuracy: 0.693333\n",
      "lr 3.162278e-04 reg 4.641589e-03 train accuracy: 0.693333\n",
      "lr 3.162278e-04 reg 1.668101e-02 train accuracy: 0.693333\n",
      "lr 3.162278e-04 reg 5.994843e-02 train accuracy: 0.706667\n",
      "lr 3.162278e-04 reg 2.154435e-01 train accuracy: 0.693333\n",
      "lr 3.162278e-04 reg 7.742637e-01 train accuracy: 0.653333\n",
      "lr 3.162278e-04 reg 2.782559e+00 train accuracy: 0.653333\n",
      "lr 3.162278e-04 reg 1.000000e+01 train accuracy: 0.653333\n",
      "lr 1.000000e-03 reg 1.000000e-04 train accuracy: 0.866667\n",
      "lr 1.000000e-03 reg 3.593814e-04 train accuracy: 0.853333\n",
      "lr 1.000000e-03 reg 1.291550e-03 train accuracy: 0.866667\n",
      "lr 1.000000e-03 reg 4.641589e-03 train accuracy: 0.866667\n",
      "lr 1.000000e-03 reg 1.668101e-02 train accuracy: 0.866667\n",
      "lr 1.000000e-03 reg 5.994843e-02 train accuracy: 0.853333\n",
      "lr 1.000000e-03 reg 2.154435e-01 train accuracy: 0.813333\n",
      "lr 1.000000e-03 reg 7.742637e-01 train accuracy: 0.666667\n",
      "lr 1.000000e-03 reg 2.782559e+00 train accuracy: 0.653333\n",
      "lr 1.000000e-03 reg 1.000000e+01 train accuracy: 0.653333\n",
      "lr 3.162278e-03 reg 1.000000e-04 train accuracy: 0.866667\n",
      "lr 3.162278e-03 reg 3.593814e-04 train accuracy: 0.866667\n",
      "lr 3.162278e-03 reg 1.291550e-03 train accuracy: 0.866667\n",
      "lr 3.162278e-03 reg 4.641589e-03 train accuracy: 0.866667\n",
      "lr 3.162278e-03 reg 1.668101e-02 train accuracy: 0.880000\n",
      "lr 3.162278e-03 reg 5.994843e-02 train accuracy: 0.893333\n",
      "lr 3.162278e-03 reg 2.154435e-01 train accuracy: 0.853333\n",
      "lr 3.162278e-03 reg 7.742637e-01 train accuracy: 0.653333\n",
      "lr 3.162278e-03 reg 2.782559e+00 train accuracy: 0.653333\n",
      "lr 3.162278e-03 reg 1.000000e+01 train accuracy: 0.666667\n",
      "lr 1.000000e-02 reg 1.000000e-04 train accuracy: 0.880000\n",
      "lr 1.000000e-02 reg 3.593814e-04 train accuracy: 0.893333\n",
      "lr 1.000000e-02 reg 1.291550e-03 train accuracy: 0.880000\n",
      "lr 1.000000e-02 reg 4.641589e-03 train accuracy: 0.893333\n",
      "lr 1.000000e-02 reg 1.668101e-02 train accuracy: 0.880000\n",
      "lr 1.000000e-02 reg 5.994843e-02 train accuracy: 0.906667\n",
      "lr 1.000000e-02 reg 2.154435e-01 train accuracy: 0.853333\n",
      "lr 1.000000e-02 reg 7.742637e-01 train accuracy: 0.680000\n",
      "lr 1.000000e-02 reg 2.782559e+00 train accuracy: 0.666667\n",
      "lr 1.000000e-02 reg 1.000000e+01 train accuracy: 0.653333\n",
      "lr 3.162278e-02 reg 1.000000e-04 train accuracy: 0.893333\n",
      "lr 3.162278e-02 reg 3.593814e-04 train accuracy: 0.893333\n",
      "lr 3.162278e-02 reg 1.291550e-03 train accuracy: 0.893333\n",
      "lr 3.162278e-02 reg 4.641589e-03 train accuracy: 0.893333\n",
      "lr 3.162278e-02 reg 1.668101e-02 train accuracy: 0.880000\n",
      "lr 3.162278e-02 reg 5.994843e-02 train accuracy: 0.893333\n",
      "lr 3.162278e-02 reg 2.154435e-01 train accuracy: 0.866667\n",
      "lr 3.162278e-02 reg 7.742637e-01 train accuracy: 0.666667\n",
      "lr 3.162278e-02 reg 2.782559e+00 train accuracy: 0.653333\n",
      "lr 3.162278e-02 reg 1.000000e+01 train accuracy: 0.693333\n",
      "lr 1.000000e-01 reg 1.000000e-04 train accuracy: 0.893333\n",
      "lr 1.000000e-01 reg 3.593814e-04 train accuracy: 0.893333\n",
      "lr 1.000000e-01 reg 1.291550e-03 train accuracy: 0.893333\n",
      "lr 1.000000e-01 reg 4.641589e-03 train accuracy: 0.893333\n",
      "lr 1.000000e-01 reg 1.668101e-02 train accuracy: 0.880000\n",
      "lr 1.000000e-01 reg 5.994843e-02 train accuracy: 0.880000\n",
      "lr 1.000000e-01 reg 2.154435e-01 train accuracy: 0.853333\n",
      "lr 1.000000e-01 reg 7.742637e-01 train accuracy: 0.653333\n",
      "lr 1.000000e-01 reg 2.782559e+00 train accuracy: 0.666667\n",
      "lr 1.000000e-01 reg 1.000000e+01 train accuracy: 0.333333\n",
      "lr 3.162278e-01 reg 1.000000e-04 train accuracy: 0.893333\n",
      "lr 3.162278e-01 reg 3.593814e-04 train accuracy: 0.893333\n",
      "lr 3.162278e-01 reg 1.291550e-03 train accuracy: 0.893333\n",
      "lr 3.162278e-01 reg 4.641589e-03 train accuracy: 0.893333\n",
      "lr 3.162278e-01 reg 1.668101e-02 train accuracy: 0.893333\n",
      "lr 3.162278e-01 reg 5.994843e-02 train accuracy: 0.893333\n",
      "lr 3.162278e-01 reg 2.154435e-01 train accuracy: 0.853333\n",
      "lr 3.162278e-01 reg 7.742637e-01 train accuracy: 0.680000\n",
      "lr 3.162278e-01 reg 2.782559e+00 train accuracy: 0.333333\n",
      "lr 3.162278e-01 reg 1.000000e+01 train accuracy: 0.333333\n",
      "lr 1.000000e+00 reg 1.000000e-04 train accuracy: 0.893333\n",
      "lr 1.000000e+00 reg 3.593814e-04 train accuracy: 0.880000\n",
      "lr 1.000000e+00 reg 1.291550e-03 train accuracy: 0.893333\n",
      "lr 1.000000e+00 reg 4.641589e-03 train accuracy: 0.893333\n",
      "lr 1.000000e+00 reg 1.668101e-02 train accuracy: 0.853333\n",
      "lr 1.000000e+00 reg 5.994843e-02 train accuracy: 0.866667\n",
      "lr 1.000000e+00 reg 2.154435e-01 train accuracy: 0.746667\n",
      "lr 1.000000e+00 reg 7.742637e-01 train accuracy: 0.333333\n",
      "lr 1.000000e+00 reg 2.782559e+00 train accuracy: 0.333333\n",
      "lr 1.000000e+00 reg 1.000000e+01 train accuracy: 0.333333\n",
      "lr 3.162278e+00 reg 1.000000e-04 train accuracy: 0.893333\n",
      "lr 3.162278e+00 reg 3.593814e-04 train accuracy: 0.866667\n",
      "lr 3.162278e+00 reg 1.291550e-03 train accuracy: 0.880000\n",
      "lr 3.162278e+00 reg 4.641589e-03 train accuracy: 0.800000\n",
      "lr 3.162278e+00 reg 1.668101e-02 train accuracy: 0.706667\n",
      "lr 3.162278e+00 reg 5.994843e-02 train accuracy: 0.533333\n",
      "lr 3.162278e+00 reg 2.154435e-01 train accuracy: 0.333333\n",
      "lr 3.162278e+00 reg 7.742637e-01 train accuracy: 0.333333\n",
      "lr 3.162278e+00 reg 2.782559e+00 train accuracy: 0.333333\n",
      "lr 3.162278e+00 reg 1.000000e+01 train accuracy: 0.333333\n",
      "lr 1.000000e+01 reg 1.000000e-04 train accuracy: 0.853333\n",
      "lr 1.000000e+01 reg 3.593814e-04 train accuracy: 0.840000\n",
      "lr 1.000000e+01 reg 1.291550e-03 train accuracy: 0.893333\n",
      "lr 1.000000e+01 reg 4.641589e-03 train accuracy: 0.666667\n",
      "lr 1.000000e+01 reg 1.668101e-02 train accuracy: 0.600000\n",
      "lr 1.000000e+01 reg 5.994843e-02 train accuracy: 0.333333\n",
      "lr 1.000000e+01 reg 2.154435e-01 train accuracy: 0.333333\n",
      "lr 1.000000e+01 reg 7.742637e-01 train accuracy: 0.333333\n",
      "lr 1.000000e+01 reg 2.782559e+00 train accuracy: 0.333333\n",
      "lr 1.000000e+01 reg 1.000000e+01 train accuracy: 0.333333\n",
      "best training accuracy achieved: 0.906667\n"
     ]
    }
   ],
   "source": [
    "'''后来改用svm loss之后，效果变好了 90.667% 对应68/75'''\n",
    "from cs231n.classifiers import LinearSVM\n",
    "results = {}\n",
    "best_acc = -1\n",
    "best_softmax = None\n",
    "\n",
    "num_tune = 10\n",
    "lr_tune=np.logspace(-3.5,1,num_tune)\n",
    "reg_tune=np.logspace(-4,1,num_tune)\n",
    "np.random.shuffle(reg_tune)\n",
    "tune=[]\n",
    "for lr in lr_tune:\n",
    "    for reg in reg_tune:\n",
    "        tune.append((lr,reg))\n",
    "for lr,reg in tune:\n",
    "    svm = LinearSVM()\n",
    "    loss_hist = svm.train(x_train, y_train, learning_rate=lr, reg=reg,\n",
    "                              num_iters=3000, verbose=True)\n",
    "    y_train_pred = svm.predict(x_train)\n",
    "    train_acc=np.mean(y_train == y_train_pred)\n",
    "    results[(lr,reg)]=train_acc\n",
    "    if train_acc>best_acc:\n",
    "        best_acc=train_acc\n",
    "        best_svm=svm\n",
    "################################################################################\n",
    "#                              END OF YOUR CODE                                #\n",
    "################################################################################\n",
    "    \n",
    "# Print out results.\n",
    "for lr, reg in sorted(results):\n",
    "    train_accuracy = results[(lr, reg)]\n",
    "    print('lr %e reg %e train accuracy: %f' % (\n",
    "                lr, reg, train_accuracy))\n",
    "    \n",
    "print('best training accuracy achieved: %f' % best_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fc1d57eaa20>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Visualize the cross-validation results\n",
    "import math\n",
    "x_scatter = [math.log10(x[0]) for x in results]\n",
    "y_scatter = [math.log10(x[1]) for x in results]\n",
    "\n",
    "# plot training accuracy\n",
    "marker_size = 100\n",
    "colors = [results[x] for x in results]\n",
    "plt.scatter(x_scatter, y_scatter, marker_size, c=colors)\n",
    "plt.colorbar()\n",
    "plt.xlabel('log learning rate')\n",
    "plt.ylabel('log regularization strength')\n",
    "plt.title('CIFAR-10 training accuracy')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.0025947 , -0.00140103,  0.00072284],\n",
       "       [-0.00326898,  0.00029669,  0.00251909],\n",
       "       [-0.00210232,  0.00178517,  0.00064286]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_softmax.W"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.64243845,  0.03786538,  0.60457873],\n",
       "       [-0.82830895, -0.07153973,  0.89978807],\n",
       "       [-0.20251612,  0.4564313 , -0.25393498]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_svm.W"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x7fc1d4a994a8>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fc1d5757518>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "x_test = np.load('x_test.npy')\n",
    "x_test_norm = x_test- x_train_mean\n",
    "x_test_norm /= x_train_std\n",
    "x_test_new = np.hstack([x_test_norm, np.ones((x_test.shape[0], 1))])\n",
    "y_test_hat = np.argmax(np.dot(x_test_new,best_svm.W),axis=1)\n",
    "plt.scatter(x_test[:,0],x_test[:,1],c=y_test_hat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 ... 2 2 2]\n"
     ]
    }
   ],
   "source": [
    "print(y_test_hat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('t_test.npy',y_test_hat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
